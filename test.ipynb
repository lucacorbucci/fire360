{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcorbucci/personalized_explanations/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Letter: (20000, 17)\n",
    "- Covertype: (581012, 55)\n",
    "- House16: (22784, 17)\n",
    "- Shuffle: (43500, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 581012/581012 [00:00<00:00, 924288.77 examples/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"mstz/covertype\", \"covertype\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>horizontal_distance_to_hydrology</th>\n",
       "      <th>vertical_distance_to_hydrology</th>\n",
       "      <th>horizontal_distance_to_roadways</th>\n",
       "      <th>hillshade_9am</th>\n",
       "      <th>hillshade_noon</th>\n",
       "      <th>hillshade_3pm</th>\n",
       "      <th>horizontal_distance_to_fire_points</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_type_id_31</th>\n",
       "      <th>soil_type_id_32</th>\n",
       "      <th>soil_type_id_33</th>\n",
       "      <th>soil_type_id_34</th>\n",
       "      <th>soil_type_id_35</th>\n",
       "      <th>soil_type_id_36</th>\n",
       "      <th>soil_type_id_37</th>\n",
       "      <th>soil_type_id_38</th>\n",
       "      <th>soil_type_id_39</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  aspect  slope  horizontal_distance_to_hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   vertical_distance_to_hydrology  horizontal_distance_to_roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   hillshade_9am  hillshade_noon  hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   horizontal_distance_to_fire_points  ...  soil_type_id_31  soil_type_id_32  \\\n",
       "0                              6279.0  ...            False            False   \n",
       "1                              6225.0  ...            False            False   \n",
       "2                              6121.0  ...            False            False   \n",
       "3                              6211.0  ...            False            False   \n",
       "4                              6172.0  ...            False            False   \n",
       "\n",
       "   soil_type_id_33  soil_type_id_34  soil_type_id_35  soil_type_id_36  \\\n",
       "0            False            False            False            False   \n",
       "1            False            False            False            False   \n",
       "2            False            False            False            False   \n",
       "3            False            False            False            False   \n",
       "4            False            False            False            False   \n",
       "\n",
       "   soil_type_id_37  soil_type_id_38  soil_type_id_39  cover_type  \n",
       "0            False            False            False           4  \n",
       "1            False            False            False           4  \n",
       "2            False            False            False           1  \n",
       "3            False            False            False           1  \n",
       "4            False            False            False           4  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cover_type\n",
       "1    283301\n",
       "0    211840\n",
       "2     35754\n",
       "6     20510\n",
       "5     17367\n",
       "4      9493\n",
       "3      2747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cover_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "\n",
    "X = df.drop(columns=[\"cover_type\"])\n",
    "y = df[\"cover_type\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"saga\"]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model\n",
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "accuracy = (predictions == Y_test).mean()\n",
    "\n",
    "# Majority classifier\n",
    "majority_class = Y_train.mode()[0]\n",
    "majority_accuracy = (Y_test == majority_class).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7063500942316463\n",
      "Majority class accuracy: 0.4876638296773749\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Majority class accuracy: {majority_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : [0.68523252 0.76533327 0.70501181 0.20211161 0.         0.12639571\n",
      " 0.52986927]\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average=None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.43056488503672374\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.7063500942316463\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.6896453632597755\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.69     42389\n",
      "           1       0.72      0.81      0.77     56668\n",
      "           2       0.63      0.79      0.71      7139\n",
      "           3       0.72      0.12      0.20       570\n",
      "           4       0.00      0.00      0.00      1918\n",
      "           5       0.29      0.08      0.13      3494\n",
      "           6       0.79      0.40      0.53      4025\n",
      "\n",
      "    accuracy                           0.71    116203\n",
      "   macro avg       0.55      0.41      0.43    116203\n",
      "weighted avg       0.69      0.71      0.69    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification Report : {classification_report(Y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183286769544912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mstz/house16\", \"house16\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22784, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"saga\"]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model\n",
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "accuracy = (predictions == Y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Majority classifier\n",
    "majority_class = Y_train.mode()[0]\n",
    "majority_accuracy = (Y_test == majority_class).mean()\n",
    "print(f\"Majority class accuracy: {majority_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mstz/shuttle\", \"shuttle\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43500, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"saga\"]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model\n",
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "accuracy = (predictions == Y_test).mean()\n",
    "\n",
    "# Majority classifier\n",
    "majority_class = Y_train.mode()[0]\n",
    "majority_accuracy = (Y_test == majority_class).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Majority class accuracy: {majority_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average=None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification Report : {classification_report(Y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mstz/letter\", \"letter\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "\n",
    "X = df.drop(columns=[\"letter\"])\n",
    "y = df[\"letter\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"saga\"]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model\n",
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "accuracy = (predictions == Y_test).mean()\n",
    "\n",
    "# Majority classifier\n",
    "majority_class = Y_train.mode()[0]\n",
    "majority_accuracy = (Y_test == majority_class).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Majority class accuracy: {majority_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average=None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score : {f1_score(Y_test, predictions, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification Report : {classification_report(Y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
