{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcorbucci/personalized_explanations/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "from train_bb import SimpleModel\n",
    "import random\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48841, 18) (48841,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    29723\n",
       "1     9349\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import prepare_adult\n",
    "from pathlib import Path\n",
    "\n",
    "current_script_path = Path.cwd()\n",
    "\n",
    "_, _, _, _, _, _, real_data = prepare_adult(\n",
    "    sweep=False, seed=42, current_path=current_script_path\n",
    ")\n",
    "\n",
    "real_data[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/pima/pima.csv\")\n",
    "\n",
    "sample = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    26382\n",
       "1    23618\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data = pd.read_csv(\"data/pima/synthetic_daata.csv\")\n",
    "synthetic_data[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 100 closest row in the synthetic data to the sample row\n",
    "# using cosine similarity between the sample row and each row in the synthetic data\n",
    "y_sample = sample[\"Outcome\"]\n",
    "sample = sample.drop(columns=[\"Outcome\"])\n",
    "y_synth = synthetic_data[\"Outcome\"]\n",
    "synthetic_data = synthetic_data.drop(columns=[\"Outcome\"])\n",
    "\n",
    "similarity = cosine_similarity(sample, synthetic_data)\n",
    "similarity = similarity.flatten()\n",
    "\n",
    "top = 5\n",
    "total_top = (len(similarity) * top) // 100\n",
    "top_100 = similarity.argsort()[-total_top:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bb\n",
    "# dataset_name = \"pima\"\n",
    "# model_name = \"pima_bb\"\n",
    "\n",
    "dataset_name = \"pima\"\n",
    "model_name = \"pima_bb\"\n",
    "\n",
    "bb = torch.load(f\"./artifacts/{dataset_name}/bb/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data[\"Outcome\"] = y_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_loader(batch_size, x_train, y_train):\n",
    "    x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "top_100_rows_with_outcome = synthetic_data.iloc[top_100]\n",
    "y = top_100_rows_with_outcome[\"Outcome\"]\n",
    "X = top_100_rows_with_outcome.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1376, 1: 1124})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1376, 1: 1124})\n"
     ]
    }
   ],
   "source": [
    "old_X = copy.deepcopy(X)\n",
    "X = X.values\n",
    "y = y.values\n",
    "print(Counter(y))\n",
    "train_loader = create_torch_loader(batch_size=16, x_train=X, y_train=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(\"cuda\"), target.to(\"cuda\")\n",
    "        outputs = bb(data)\n",
    "        predicted = outputs.argmax(dim=1, keepdim=True)\n",
    "        predictions.extend(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1930, 0: 570})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [item.item() for item in predictions]\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882 - F1: 0.9244558258642765\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "clf = grid_search.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy} - F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision path for the sample row:\n",
      "Node 0: (BloodPressure = 58) <= 58.5\n",
      "Node 1: (Glucose = 98) > 87.5\n",
      "Node 89: (SkinThickness = 33) > 24.5\n",
      "Node 109: (BloodPressure = 58) > 55.5\n",
      "Node 113: (Age = 43) > 29.5\n",
      "Node 125: (Glucose = 98) > 88.5\n",
      "Leaf node 127 reached, prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the sample row in the tree:\n",
    "# Get the prediction for the sample row\n",
    "sample_pred = clf.predict(sample)\n",
    "\n",
    "# Get the decision path for the sample row\n",
    "node_indicator = clf.decision_path(sample)\n",
    "leave_id = clf.apply(sample)\n",
    "\n",
    "# Get the feature and threshold used at each node\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = sample.columns\n",
    "\n",
    "# Print the path from the root to the leaf\n",
    "node_index = node_indicator.indices[node_indicator.indptr[0] : node_indicator.indptr[1]]\n",
    "print(\"Decision path for the sample row:\")\n",
    "for node_id in node_index:\n",
    "    if leave_id[0] == node_id:\n",
    "        print(f\"Leaf node {node_id} reached, prediction: {sample_pred[0]}\")\n",
    "    else:\n",
    "        if sample.iloc[0, feature[node_id]] <= threshold[node_id]:\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "        print(\n",
    "            f\"Node {node_id}: ({feature_names[feature[node_id]]} = {sample.iloc[0, feature[node_id]]}) {threshold_sign} {threshold[node_id]}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Closest path with a different prediction:\n",
      "Leaf node 0 reached, prediction: 0\n",
      "Node 128: (Age = 40) > 34.5\n",
      "Node 228: (BloodPressure = 62) <= 73.5\n",
      "Node 229: (Glucose = 94) <= 104.5\n",
      "Node 230: (Age = 40) <= 45.5\n",
      "Node 231: (BMI = 30.5) > 27.75\n",
      "Node 241: (Glucose = 94) > 73.5\n",
      "Node 243: (Insulin = 185) > 173.0\n",
      "Node 245: (SkinThickness = 29) > 21.5\n",
      "Node 247: (BloodPressure = 62) <= 70.5\n",
      "Node 248: (DiabetesPedigreeFunction = 0.476) > -2.0\n"
     ]
    }
   ],
   "source": [
    "# Find the closest path that gives a different prediction\n",
    "different_pred = 1 - sample_pred[0]\n",
    "for i in range(len(clf.tree_.value)):\n",
    "    if clf.tree_.value[i][0][different_pred] > clf.tree_.value[i][0][sample_pred[0]]:\n",
    "        different_node_id = i\n",
    "        break\n",
    "\n",
    "# Print the path for the different prediction\n",
    "node_indicator_diff = clf.decision_path(old_X.iloc[[different_node_id]])\n",
    "node_index_diff = node_indicator_diff.indices[\n",
    "    node_indicator_diff.indptr[0] : node_indicator_diff.indptr[1]\n",
    "]\n",
    "\n",
    "feature_names = sample.columns\n",
    "\n",
    "print(\"\\nClosest path with a different prediction:\")\n",
    "for node_id in node_index_diff:\n",
    "    if different_node_id == node_id:\n",
    "        print(f\"Leaf node {node_id} reached, prediction: {different_pred}\")\n",
    "    else:\n",
    "        if old_X.iloc[different_node_id, feature[node_id]] <= threshold[node_id]:\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "        print(\n",
    "            f\"Node {node_id}: ({feature_names[feature[node_id]]} = {old_X.iloc[different_node_id, feature[node_id]]}) {threshold_sign} {threshold[node_id]}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
