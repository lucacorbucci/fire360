{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcorbucci/synth_xai/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from synth_xai.utils import (\n",
    "    prepare_dutch,\n",
    ")\n",
    "from pathlib import Path\n",
    "from synth_xai.explanations.explanation_utils import (\n",
    "    load_bb,\n",
    ")\n",
    "import copy\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from synth_xai.explanations.explanation_utils import (\n",
    "    evaluate_bb,\n",
    "    find_top_closest_rows,\n",
    "    get_test_data,\n",
    "    is_explainer_supported,\n",
    "    label_synthetic_data,\n",
    "    load_bb,\n",
    "    load_synthetic_data,\n",
    "    make_predictions,\n",
    "    prepare_neighbours,\n",
    "    setup_wandb,\n",
    "    transform_input_data,\n",
    ")\n",
    "from synth_xai.explanations.explainer_model import ExplainerModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dutch(\n",
    "    sweep: bool,\n",
    "    seed: int,\n",
    "    current_path: Path,\n",
    "    validation_seed: int | None = None,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, pd.DataFrame, pd.DataFrame]:\n",
    "    file_path = current_path\n",
    "    data = arff.loadarff(file_path)\n",
    "    dutch_df = pd.DataFrame(data[0]).astype(\"int32\")\n",
    "\n",
    "    # check the columns with missign values:\n",
    "    missing_values_columns = dutch_df.columns[dutch_df.isna().any()].tolist()\n",
    "    for column in missing_values_columns:\n",
    "        dutch_df[column] = dutch_df[column].fillna(dutch_df[column].mode()[0])\n",
    "\n",
    "    if len(dutch_df.columns[dutch_df.isna().any()].tolist()) != 0:\n",
    "        error_message = \"There are still missing values in the dataset\"\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "    dutch_df[\"sex_binary\"] = np.where(dutch_df[\"sex\"] == 1, 1, 0)\n",
    "    dutch_df[\"occupation_binary\"] = np.where(dutch_df[\"occupation\"] >= 300, 1, 0)\n",
    "\n",
    "    del dutch_df[\"sex\"]\n",
    "    del dutch_df[\"occupation\"]\n",
    "\n",
    "    y = dutch_df[\"occupation_binary\"].astype(int).values\n",
    "    del dutch_df[\"occupation_binary\"]\n",
    "\n",
    "    dutch_df = pd.get_dummies(dutch_df, columns=None, drop_first=False)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dutch_df, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "\n",
    "    train_df = copy.copy(x_train)\n",
    "    train_df[\"occupation_binary\"] = y_train\n",
    "\n",
    "    test_df = copy.copy(x_test)\n",
    "    test_df[\"occupation_binary\"] = y_test\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    if sweep:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            test_size=0.2,\n",
    "            random_state=validation_seed,\n",
    "            stratify=y_train,\n",
    "        )\n",
    "    else:\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test, train_df, test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BB Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (layer1): Linear(in_features=11, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_path = \"./example_bb/dutch_BB.pth\"\n",
    "bb = load_bb(bb_path)\n",
    "\n",
    "bb.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.dataset_name = \"dutch\"\n",
    "        self.seed = 42\n",
    "        self.synthetic_dataset_path = \"./example_synthetic_data/synthetic_data.csv\"\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, outcome_variable = get_test_data(args)\n",
    "x, y, scaler = transform_input_data(train_data=train_data, test_data=test_data, outcome_variable=outcome_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-13 15:58:01.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynth_xai.explanations.explanation_utils\u001b[0m:\u001b[36mevaluate_bb\u001b[0m:\u001b[36m217\u001b[0m - \u001b[1mAccuracy: 0.832092022509103 - F1: 0.8321849875595729\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluate_bb(x, y, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_path = Path(args.synthetic_dataset_path)\n",
    "\n",
    "synthetic_data = load_synthetic_data(synthetic_data_path)\n",
    "\n",
    "synthetic_data_labels = label_synthetic_data(\n",
    "    synthetic_data=synthetic_data, outcome_variable=outcome_variable, bb=bb, scaler=scaler\n",
    ")\n",
    "synthetic_data[outcome_variable] = synthetic_data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the sample we want to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  household_position  household_size  prev_residence_place  \\\n",
      "25279    5                1110             112                     1   \n",
      "\n",
      "       citizenship  country_birth  edu_level  economic_status  \\\n",
      "25279            1              1          2              111   \n",
      "\n",
      "       cur_eco_activity  Marital_status  sex_binary  occupation_binary  \n",
      "25279               131               1           1                  1  \n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "sample = test_data.iloc[[index]]\n",
    "print(sample)\n",
    "x_sample = torch.tensor([x[index]])\n",
    "y_sample = torch.tensor([y[index]])\n",
    "\n",
    "sample_pred_bb = make_predictions(x_sample, y_sample, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 1000\n",
    "top_k_samples = find_top_closest_rows(\n",
    "    synthetic_data=synthetic_data,\n",
    "    sample=sample,\n",
    "    k=top_k,\n",
    "    y_name=outcome_variable,\n",
    ")\n",
    "\n",
    "X, Y, old_x = prepare_neighbours(top_k_samples=top_k_samples, y_name=outcome_variable)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_type = \"dt\"\n",
    "validation_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = ExplainerModel(explainer_type=explanation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model.grid_search(x_train=x_train, y_train=y_train, seed=validation_seed)\n",
    "\n",
    "sample_pred, explanation, threshold, feature = explainer_model.extract_explanation(\n",
    "    clf=explainer_model.best_model, y_name=outcome_variable, sample=sample\n",
    ")\n",
    "\n",
    "y_pred = explainer_model.predict(x_test)\n",
    "accuracy_val = accuracy_score(y_test, y_pred)\n",
    "f1_val = f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity: \", 1 if (y_pred[0] == sample_pred_bb[0]) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1: 1.0\n",
      "Explanation: ['(household_position = 1110) <= 1115.5', '(prev_residence_place = 1) <= 1.5', 'Leaf node 2 reached, prediction: 1']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_val}\")\n",
    "print(f\"F1: {f1_val}\")\n",
    "print(f\"Explanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_type = \"logistic\"\n",
    "validation_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = ExplainerModel(explainer_type=explanation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model.grid_search(x_train=x_train, y_train=y_train, seed=validation_seed)\n",
    "\n",
    "sample_pred, explanation, threshold, feature = explainer_model.extract_explanation(\n",
    "    clf=explainer_model.best_model, y_name=outcome_variable, sample=sample\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = explainer_model.predict(x_test)\n",
    "accuracy_val = accuracy_score(y_test, y_pred)\n",
    "f1_val = f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:  1\n",
      "Accuracy: 0.995\n",
      "F1: 0.9950129672006102\n",
      "Explanation: ['Marital_status: coefficient=-7.647274793987985, value=1', 'age: coefficient=-5.314648352877113, value=5', 'prev_residence_place: coefficient=-2.4425235761689956, value=1', 'edu_level: coefficient=-1.6403407080407693, value=2', 'household_size: coefficient=0.12280868684771122, value=112', 'economic_status: coefficient=0.12168432610281686, value=111', 'cur_eco_activity: coefficient=0.1039957805705147, value=131', 'household_position: coefficient=0.007978501769350919, value=1110', 'citizenship: coefficient=0.0, value=1', 'country_birth: coefficient=0.0, value=1', 'sex_binary: coefficient=0.0, value=1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity: \", 1 if (y_pred[0] == sample_pred_bb[0]) else 0)\n",
    "print(f\"Accuracy: {accuracy_val}\")\n",
    "print(f\"F1: {f1_val}\")\n",
    "print(f\"Explanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'household_position', 'household_size', 'prev_residence_place',\n",
       "       'citizenship', 'country_birth', 'edu_level', 'economic_status',\n",
       "       'cur_eco_activity', 'Marital_status', 'sex_binary',\n",
       "       'occupation_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_type = \"svm\"\n",
    "validation_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = ExplainerModel(explainer_type=explanation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model.grid_search(x_train=x_train, y_train=y_train, seed=validation_seed)\n",
    "\n",
    "sample_pred, explanation, threshold, feature = explainer_model.extract_explanation(\n",
    "    clf=explainer_model.best_model, y_name=outcome_variable, sample=sample\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = explainer_model.predict(x_test)\n",
    "accuracy_val = accuracy_score(y_test, y_pred)\n",
    "f1_val = f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:  1\n",
      "Accuracy: 1.0\n",
      "F1: 1.0\n",
      "Explanation: ['prev_residence_place: coefficient=-1.3115770976584527, value=1', 'age: coefficient=-1.3115600558866127, value=5', 'edu_level: coefficient=-1.311551535022013, value=2', 'Marital_status: coefficient=-0.5302355040847307, value=1', 'household_size: coefficient=-0.15822148192455643, value=112', 'cur_eco_activity: coefficient=-0.15820444018793867, value=131', 'household_position: coefficient=-0.14808844333992965, value=1110', 'sex_binary: coefficient=6.38378239159465e-16, value=1', 'citizenship: coefficient=0.0, value=1', 'country_birth: coefficient=0.0, value=1', 'economic_status: coefficient=0.0, value=111']\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity: \", 1 if (y_pred[0] == sample_pred_bb[0]) else 0)\n",
    "print(f\"Accuracy: {accuracy_val}\")\n",
    "print(f\"F1: {f1_val}\")\n",
    "print(f\"Explanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_type = \"knn\"\n",
    "validation_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = ExplainerModel(explainer_type=explanation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model.grid_search(x_train=x_train, y_train=y_train, seed=validation_seed)\n",
    "\n",
    "sample_pred, explanation, threshold, feature = explainer_model.extract_explanation(\n",
    "    clf=explainer_model.best_model, y_name=outcome_variable, sample=sample\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = explainer_model.predict(x_test)\n",
    "accuracy_val = accuracy_score(y_test, y_pred)\n",
    "f1_val = f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:  1\n",
      "Accuracy: 1.0\n",
      "F1: 1.0\n",
      "Explanation: ['KNN prediction: 1', 'Nearest neighbors (index, distance, label):', 'Index: 25, distance: 0.0000, label: 1, sample: [   5 1110  112    1    1    1    2  111  131    1    1]', 'Index: 134, distance: 0.0000, label: 1, sample: [   5 1110  112    1    1    1    2  111  131    1    1]', 'Index: 59, distance: 0.0000, label: 1, sample: [   5 1110  112    1    1    1    2  111  131    1    1]']\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity: \", 1 if (y_pred[0] == sample_pred_bb[0]) else 0)\n",
    "print(f\"Accuracy: {accuracy_val}\")\n",
    "print(f\"F1: {f1_val}\")\n",
    "print(f\"Explanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  household_position  household_size  prev_residence_place  \\\n",
      "8720    8                1122             114                     1   \n",
      "\n",
      "      citizenship  country_birth  edu_level  economic_status  \\\n",
      "8720            1              1          3              111   \n",
      "\n",
      "      cur_eco_activity  Marital_status  sex_binary  occupation_binary  \n",
      "8720               132               2           0                  1  \n"
     ]
    }
   ],
   "source": [
    "similar_1 = test_data.iloc[[25]]\n",
    "print(similar_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  household_position  household_size  prev_residence_place  \\\n",
      "781   11                1121             112                     1   \n",
      "\n",
      "     citizenship  country_birth  edu_level  economic_status  cur_eco_activity  \\\n",
      "781            1              1          3              111               135   \n",
      "\n",
      "     Marital_status  sex_binary  occupation_binary  \n",
      "781               2           0                  1  \n"
     ]
    }
   ],
   "source": [
    "similar_2 = test_data.iloc[[134]]\n",
    "print(similar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  household_position  household_size  prev_residence_place  \\\n",
      "13364   12                1121             112                     1   \n",
      "\n",
      "       citizenship  country_birth  edu_level  economic_status  \\\n",
      "13364            1              1          2              111   \n",
      "\n",
      "       cur_eco_activity  Marital_status  sex_binary  occupation_binary  \n",
      "13364               131               2           0                  1  \n"
     ]
    }
   ],
   "source": [
    "similar_3 = test_data.iloc[[59]]\n",
    "print(similar_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
