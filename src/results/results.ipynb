{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "import dill\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_runs(project_name):\n",
    "    if not os.path.exists(\n",
    "        f\"./results_data/data_{project_name}.pkl\"\n",
    "    ):\n",
    "        project_details = wandb.Api().runs(f\"lucacorbucci/{project_name}\")\n",
    "        project_data = {}\n",
    "        for run in project_details:\n",
    "            print(\"Downloading run \", run.id)\n",
    "            run_df = pd.DataFrame(\n",
    "                wandb.Api().run(f\"lucacorbucci/{project_name}/{run.id}\").scan_history()\n",
    "            )\n",
    "            if run.name not in project_data:\n",
    "                project_data[run.name] = []\n",
    "            project_data[run.name].append(run_df)\n",
    "        with open(\n",
    "            f\"./results_data/data_{project_name}.pkl\", \"wb\"\n",
    "        ) as f:\n",
    "            dill.dump(project_data, f)\n",
    "    else:\n",
    "        with open(\n",
    "            f\"./results_data/data_{project_name}.pkl\", \"rb\"\n",
    "        ) as f:\n",
    "            project_data = dill.load(f)\n",
    "    return project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = download_runs(project_name=\"tango_explanation_metrics\")\n",
    "project_name = \"tango_explanation_metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"dt\", \"svm\", \"logistic\", \"lime\", \"shap\", \"lore\", \"lore_genetic\"]\n",
    "datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "top_k = [3, 5, 8, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1837723/183406378.py:14: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  stability = round(float(results[\"stability\"]), 3)\n",
      "/tmp/ipykernel_1837723/183406378.py:15: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  stability_std = round(float(results[\"stability_std\"]), 3)\n",
      "/tmp/ipykernel_1837723/183406378.py:19: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  robustness = round(float(results[f\"robustness_top_{k}\"]), 3)\n",
      "/tmp/ipykernel_1837723/183406378.py:20: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  robustness_std = round(float(results[f\"robustness_std_top_{k}\"]), 3)\n",
      "/tmp/ipykernel_1837723/183406378.py:10: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  faithfulness = round(float(results[\"faithfulness\"]), 3)\n",
      "/tmp/ipykernel_1837723/183406378.py:11: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  faithfulness_std = round(float(results[\"faithfulness_std\"]), 3)\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}   \n",
    "    for method in methods: \n",
    "        metrics[dataset][method] = {}\n",
    "        if f\"{method}_{dataset}\" in project_data:\n",
    "            results = project_data[f\"{method}_{dataset}\"][0]\n",
    "            if \"faithfulness\" in results.columns:\n",
    "                faithfulness = round(float(results[\"faithfulness\"]), 3)\n",
    "                faithfulness_std = round(float(results[\"faithfulness_std\"]), 3)\n",
    "                metrics[dataset][method][\"Faithfulness\"] = f\"{faithfulness} $\\pm$ {faithfulness_std}\"\n",
    "            if \"stability\" in results.columns:\n",
    "                stability = round(float(results[\"stability\"]), 3)\n",
    "                stability_std = round(float(results[\"stability_std\"]), 3)\n",
    "                metrics[dataset][method][\"stability\"] = f\"{stability} $\\pm$ {stability_std}\"\n",
    "            for k in top_k:\n",
    "                if f\"robustness_top_{k}\" in results.columns:\n",
    "                    robustness = round(float(results[f\"robustness_top_{k}\"]), 3)\n",
    "                    robustness_std = round(float(results[f\"robustness_std_top_{k}\"]), 3)\n",
    "                    metrics[dataset][method][f\"robustness_top_{k}\"] = f\"{robustness} $\\pm$ {robustness_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.876 $\\pm$ 0.193</td>\n",
       "      <td>-</td>\n",
       "      <td>0.542 $\\pm$ 0.154</td>\n",
       "      <td>0.529 $\\pm$ 0.139</td>\n",
       "      <td>0.512 $\\pm$ 0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.856 $\\pm$ 0.263</td>\n",
       "      <td>0.009 $\\pm$ 0.112</td>\n",
       "      <td>0.295 $\\pm$ 0.108</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.409 $\\pm$ 0.284</td>\n",
       "      <td>-0.025 $\\pm$ 0.214</td>\n",
       "      <td>0.224 $\\pm$ 0.137</td>\n",
       "      <td>0.219 $\\pm$ 0.126</td>\n",
       "      <td>0.214 $\\pm$ 0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.056 $\\pm$ 0.021</td>\n",
       "      <td>0.063 $\\pm$ 0.178</td>\n",
       "      <td>0.054 $\\pm$ 0.009</td>\n",
       "      <td>0.054 $\\pm$ 0.007</td>\n",
       "      <td>0.054 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>0.408 $\\pm$ 0.195</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.264 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.31 $\\pm$ 0.218</td>\n",
       "      <td>-</td>\n",
       "      <td>0.309 $\\pm$ 0.175</td>\n",
       "      <td>0.314 $\\pm$ 0.171</td>\n",
       "      <td>0.314 $\\pm$ 0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.548 $\\pm$ 0.172</td>\n",
       "      <td>-</td>\n",
       "      <td>0.253 $\\pm$ 0.104</td>\n",
       "      <td>0.252 $\\pm$ 0.084</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.903 $\\pm$ 0.156</td>\n",
       "      <td>-</td>\n",
       "      <td>0.572 $\\pm$ 0.117</td>\n",
       "      <td>0.558 $\\pm$ 0.104</td>\n",
       "      <td>0.545 $\\pm$ 0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.586 $\\pm$ 0.355</td>\n",
       "      <td>-0.033 $\\pm$ 0.241</td>\n",
       "      <td>0.187 $\\pm$ 0.089</td>\n",
       "      <td>0.18 $\\pm$ 0.078</td>\n",
       "      <td>0.173 $\\pm$ 0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset          Method          Stability        Faithfulness  \\\n",
       "0       Adult   Decision Tree  0.876 $\\pm$ 0.193                   -   \n",
       "1       Adult             SVM  0.856 $\\pm$ 0.263   0.009 $\\pm$ 0.112   \n",
       "2       Adult  Logistic Regr.  0.409 $\\pm$ 0.284  -0.025 $\\pm$ 0.214   \n",
       "3       Adult            LIME  0.056 $\\pm$ 0.021   0.063 $\\pm$ 0.178   \n",
       "4       Adult            SHAP  0.408 $\\pm$ 0.195    0.515 $\\pm$ 0.16   \n",
       "5       Adult   Lore (Random)   0.31 $\\pm$ 0.218                   -   \n",
       "6       Adult  Lore (Genetic)  0.548 $\\pm$ 0.172                   -   \n",
       "28  Covertype   Decision Tree  0.903 $\\pm$ 0.156                   -   \n",
       "29  Covertype             SVM  0.586 $\\pm$ 0.355  -0.033 $\\pm$ 0.241   \n",
       "\n",
       "       Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "0   0.542 $\\pm$ 0.154  0.529 $\\pm$ 0.139   0.512 $\\pm$ 0.13  \n",
       "1   0.295 $\\pm$ 0.108  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "2   0.224 $\\pm$ 0.137  0.219 $\\pm$ 0.126   0.214 $\\pm$ 0.12  \n",
       "3   0.054 $\\pm$ 0.009  0.054 $\\pm$ 0.007  0.054 $\\pm$ 0.005  \n",
       "4   0.264 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.086  \n",
       "5   0.309 $\\pm$ 0.175  0.314 $\\pm$ 0.171  0.314 $\\pm$ 0.171  \n",
       "6   0.253 $\\pm$ 0.104  0.252 $\\pm$ 0.084  0.252 $\\pm$ 0.071  \n",
       "28  0.572 $\\pm$ 0.117  0.558 $\\pm$ 0.104  0.545 $\\pm$ 0.095  \n",
       "29  0.187 $\\pm$ 0.089   0.18 $\\pm$ 0.078   0.173 $\\pm$ 0.07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "top_k_table = [5,10,20]\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        row = {\n",
    "            'Dataset': dataset,\n",
    "            'Method': method,\n",
    "            'Stability': metrics[dataset][method].get('stability', '-'),\n",
    "            'Faithfulness': metrics[dataset][method].get('Faithfulness', '-')\n",
    "        }\n",
    "        for k in top_k_table:\n",
    "            row[f\"Robustness K={k}\"] = metrics[dataset][method].get(f'robustness_top_{k}', '-')\n",
    "        rows.append(row)\n",
    "\n",
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': 'Decision Tree',\n",
    "    'svm': 'SVM',\n",
    "    'logistic': 'Logistic Regr.',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Method\"] = df_metrics[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    'Decision Tree': 1, \n",
    "    'SVM': 2, \n",
    "    'Logistic Regr.': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics['method_order'] = df_metrics['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics = df_metrics.drop(columns=['method_order'])\n",
    "\n",
    "df_metrics.head(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Stability & Faithfulness & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & Decision Tree & 0.876 $\\pm$ 0.193 & - & 0.542 $\\pm$ 0.154 & 0.529 $\\pm$ 0.139 & 0.512 $\\pm$ 0.13 \\\\\n",
      "Adult & SVM & 0.856 $\\pm$ 0.263 & 0.009 $\\pm$ 0.112 & 0.295 $\\pm$ 0.108 & 0.292 $\\pm$ 0.099 & 0.288 $\\pm$ 0.093 \\\\\n",
      "Adult & Logistic Regr. & 0.409 $\\pm$ 0.284 & -0.025 $\\pm$ 0.214 & 0.224 $\\pm$ 0.137 & 0.219 $\\pm$ 0.126 & 0.214 $\\pm$ 0.12 \\\\\n",
      "Adult & LIME & 0.056 $\\pm$ 0.021 & 0.063 $\\pm$ 0.178 & 0.054 $\\pm$ 0.009 & 0.054 $\\pm$ 0.007 & 0.054 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 0.408 $\\pm$ 0.195 & 0.515 $\\pm$ 0.16 & 0.264 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.086 \\\\\n",
      "Adult & Lore (Random) & 0.31 $\\pm$ 0.218 & - & 0.309 $\\pm$ 0.175 & 0.314 $\\pm$ 0.171 & 0.314 $\\pm$ 0.171 \\\\\n",
      "Adult & Lore (Genetic) & 0.548 $\\pm$ 0.172 & - & 0.253 $\\pm$ 0.104 & 0.252 $\\pm$ 0.084 & 0.252 $\\pm$ 0.071 \\\\\n",
      "Covertype & Decision Tree & 0.903 $\\pm$ 0.156 & - & 0.572 $\\pm$ 0.117 & 0.558 $\\pm$ 0.104 & 0.545 $\\pm$ 0.095 \\\\\n",
      "Covertype & SVM & 0.586 $\\pm$ 0.355 & -0.033 $\\pm$ 0.241 & 0.187 $\\pm$ 0.089 & 0.18 $\\pm$ 0.078 & 0.173 $\\pm$ 0.07 \\\\\n",
      "Covertype & Logistic Regr. & 0.579 $\\pm$ 0.412 & -0.046 $\\pm$ 0.321 & 0.18 $\\pm$ 0.116 & 0.171 $\\pm$ 0.104 & 0.163 $\\pm$ 0.094 \\\\\n",
      "Covertype & LIME & 0.611 $\\pm$ 0.046 & -0.104 $\\pm$ 0.284 & 0.605 $\\pm$ 0.024 & 0.604 $\\pm$ 0.02 & 0.603 $\\pm$ 0.018 \\\\\n",
      "Covertype & SHAP & 0.181 $\\pm$ 0.067 & 0.519 $\\pm$ 0.314 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.424 $\\pm$ 0.12 & - & 0.41 $\\pm$ 0.071 & 0.41 $\\pm$ 0.062 & 0.409 $\\pm$ 0.057 \\\\\n",
      "Covertype & Lore (Genetic) & 0.743 $\\pm$ 0.104 & - & 0.44 $\\pm$ 0.068 & 0.44 $\\pm$ 0.059 & 0.44 $\\pm$ 0.053 \\\\\n",
      "Dutch & Decision Tree & 0.972 $\\pm$ 0.097 & - & 0.9 $\\pm$ 0.152 & 0.873 $\\pm$ 0.161 & 0.841 $\\pm$ 0.169 \\\\\n",
      "Dutch & SVM & 0.843 $\\pm$ 0.261 & 0.036 $\\pm$ 0.317 & 0.677 $\\pm$ 0.296 & 0.594 $\\pm$ 0.275 & 0.501 $\\pm$ 0.231 \\\\\n",
      "Dutch & Logistic Regr. & 0.77 $\\pm$ 0.291 & 0.042 $\\pm$ 0.297 & 0.702 $\\pm$ 0.295 & 0.624 $\\pm$ 0.282 & 0.535 $\\pm$ 0.25 \\\\\n",
      "Dutch & LIME & 0.484 $\\pm$ 0.166 & 0.059 $\\pm$ 0.258 & 0.466 $\\pm$ 0.11 & 0.459 $\\pm$ 0.101 & 0.447 $\\pm$ 0.096 \\\\\n",
      "Dutch & SHAP & 1.0 $\\pm$ 0.0 & 0.461 $\\pm$ 0.358 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.71 $\\pm$ 0.122 & - & 0.682 $\\pm$ 0.077 & 0.682 $\\pm$ 0.069 & 0.682 $\\pm$ 0.064 \\\\\n",
      "Dutch & Lore (Genetic) & 0.806 $\\pm$ 0.197 & - & 0.602 $\\pm$ 0.123 & 0.601 $\\pm$ 0.108 & 0.601 $\\pm$ 0.1 \\\\\n",
      "House 16 & Decision Tree & 0.888 $\\pm$ 0.152 & - & 0.621 $\\pm$ 0.107 & 0.615 $\\pm$ 0.098 & 0.608 $\\pm$ 0.095 \\\\\n",
      "House 16 & SVM & 0.625 $\\pm$ 0.391 & 0.006 $\\pm$ 0.217 & 0.247 $\\pm$ 0.131 & 0.238 $\\pm$ 0.118 & 0.228 $\\pm$ 0.108 \\\\\n",
      "House 16 & Logistic Regr. & 0.669 $\\pm$ 0.256 & 0.099 $\\pm$ 0.238 & 0.389 $\\pm$ 0.097 & 0.38 $\\pm$ 0.086 & 0.371 $\\pm$ 0.078 \\\\\n",
      "House 16 & LIME & 0.577 $\\pm$ 0.133 & 0.073 $\\pm$ 0.256 & 0.473 $\\pm$ 0.06 & 0.469 $\\pm$ 0.047 & 0.466 $\\pm$ 0.038 \\\\\n",
      "House 16 & SHAP & 0.749 $\\pm$ 0.147 & 0.319 $\\pm$ 0.384 & 0.189 $\\pm$ 0.063 & 0.182 $\\pm$ 0.051 & 0.174 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.512 $\\pm$ 0.15 & - & 0.507 $\\pm$ 0.084 & 0.507 $\\pm$ 0.072 & 0.507 $\\pm$ 0.065 \\\\\n",
      "House 16 & Lore (Genetic) & 0.774 $\\pm$ 0.139 & - & 0.554 $\\pm$ 0.101 & 0.554 $\\pm$ 0.086 & 0.553 $\\pm$ 0.078 \\\\\n",
      "Letter & Decision Tree & 0.944 $\\pm$ 0.116 & - & 0.586 $\\pm$ 0.118 & 0.569 $\\pm$ 0.105 & 0.55 $\\pm$ 0.096 \\\\\n",
      "Letter & SVM & 0.853 $\\pm$ 0.3 & 0.035 $\\pm$ 0.216 & 0.126 $\\pm$ 0.093 & 0.114 $\\pm$ 0.064 & 0.104 $\\pm$ 0.048 \\\\\n",
      "Letter & Logistic Regr. & 0.634 $\\pm$ 0.321 & 0.012 $\\pm$ 0.189 & 0.143 $\\pm$ 0.093 & 0.129 $\\pm$ 0.067 & 0.117 $\\pm$ 0.053 \\\\\n",
      "Letter & LIME & 0.227 $\\pm$ 0.104 & 0.041 $\\pm$ 0.201 & 0.187 $\\pm$ 0.069 & 0.18 $\\pm$ 0.062 & 0.171 $\\pm$ 0.056 \\\\\n",
      "Letter & SHAP & 0.524 $\\pm$ 0.152 & 0.566 $\\pm$ 0.223 & 0.24 $\\pm$ 0.103 & 0.22 $\\pm$ 0.09 & 0.199 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.621 $\\pm$ 0.101 & - & 0.608 $\\pm$ 0.06 & 0.608 $\\pm$ 0.052 & 0.608 $\\pm$ 0.047 \\\\\n",
      "Letter & Lore (Genetic) & 0.901 $\\pm$ 0.06 & - & 0.774 $\\pm$ 0.048 & 0.774 $\\pm$ 0.042 & 0.773 $\\pm$ 0.039 \\\\\n",
      "Shuttle & Decision Tree & 0.913 $\\pm$ 0.19 & - & 0.781 $\\pm$ 0.181 & 0.772 $\\pm$ 0.174 & 0.76 $\\pm$ 0.171 \\\\\n",
      "Shuttle & SVM & 0.809 $\\pm$ 0.278 & 0.261 $\\pm$ 0.615 & 0.436 $\\pm$ 0.155 & 0.423 $\\pm$ 0.141 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & Logistic Regr. & 0.79 $\\pm$ 0.287 & 0.108 $\\pm$ 0.665 & 0.486 $\\pm$ 0.194 & 0.47 $\\pm$ 0.179 & 0.453 $\\pm$ 0.167 \\\\\n",
      "Shuttle & LIME & 0.423 $\\pm$ 0.195 & 0.01 $\\pm$ 0.668 & 0.328 $\\pm$ 0.144 & 0.32 $\\pm$ 0.132 & 0.312 $\\pm$ 0.125 \\\\\n",
      "Shuttle & SHAP & 1.0 $\\pm$ 0.0 & 0.57 $\\pm$ 0.551 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.713 $\\pm$ 0.115 & - & 0.699 $\\pm$ 0.073 & 0.699 $\\pm$ 0.065 & 0.699 $\\pm$ 0.06 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.866 $\\pm$ 0.119 & - & 0.752 $\\pm$ 0.078 & 0.752 $\\pm$ 0.069 & 0.752 $\\pm$ 0.064 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Stability & Faithfulness & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & Decision Tree & 0.876 $\\pm$ 0.193 & - & 0.542 $\\pm$ 0.154 & 0.529 $\\pm$ 0.139 & 0.512 $\\pm$ 0.13 \\\\\n",
      "Adult & SVM & 0.856 $\\pm$ 0.263 & 0.009 $\\pm$ 0.112 & 0.295 $\\pm$ 0.108 & 0.292 $\\pm$ 0.099 & 0.288 $\\pm$ 0.093 \\\\\n",
      "Adult & Logistic Regr. & 0.409 $\\pm$ 0.284 & -0.025 $\\pm$ 0.214 & 0.224 $\\pm$ 0.137 & 0.219 $\\pm$ 0.126 & 0.214 $\\pm$ 0.12 \\\\\n",
      "Adult & LIME & 0.056 $\\pm$ 0.021 & 0.063 $\\pm$ 0.178 & 0.054 $\\pm$ 0.009 & 0.054 $\\pm$ 0.007 & 0.054 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 0.408 $\\pm$ 0.195 & 0.515 $\\pm$ 0.16 & 0.264 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.086 \\\\\n",
      "Adult & Lore (Random) & 0.31 $\\pm$ 0.218 & - & 0.309 $\\pm$ 0.175 & 0.314 $\\pm$ 0.171 & 0.314 $\\pm$ 0.171 \\\\\n",
      "Adult & Lore (Genetic) & 0.548 $\\pm$ 0.172 & - & 0.253 $\\pm$ 0.104 & 0.252 $\\pm$ 0.084 & 0.252 $\\pm$ 0.071 \\\\\\midrule\n",
      "Covertype & Decision Tree & 0.903 $\\pm$ 0.156 & - & 0.572 $\\pm$ 0.117 & 0.558 $\\pm$ 0.104 & 0.545 $\\pm$ 0.095 \\\\\n",
      "Covertype & SVM & 0.586 $\\pm$ 0.355 & -0.033 $\\pm$ 0.241 & 0.187 $\\pm$ 0.089 & 0.18 $\\pm$ 0.078 & 0.173 $\\pm$ 0.07 \\\\\n",
      "Covertype & Logistic Regr. & 0.579 $\\pm$ 0.412 & -0.046 $\\pm$ 0.321 & 0.18 $\\pm$ 0.116 & 0.171 $\\pm$ 0.104 & 0.163 $\\pm$ 0.094 \\\\\n",
      "Covertype & LIME & 0.611 $\\pm$ 0.046 & -0.104 $\\pm$ 0.284 & 0.605 $\\pm$ 0.024 & 0.604 $\\pm$ 0.02 & 0.603 $\\pm$ 0.018 \\\\\n",
      "Covertype & SHAP & 0.181 $\\pm$ 0.067 & 0.519 $\\pm$ 0.314 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.424 $\\pm$ 0.12 & - & 0.41 $\\pm$ 0.071 & 0.41 $\\pm$ 0.062 & 0.409 $\\pm$ 0.057 \\\\\n",
      "Covertype & Lore (Genetic) & 0.743 $\\pm$ 0.104 & - & 0.44 $\\pm$ 0.068 & 0.44 $\\pm$ 0.059 & 0.44 $\\pm$ 0.053 \\\\\\midrule\n",
      "Dutch & Decision Tree & 0.972 $\\pm$ 0.097 & - & 0.9 $\\pm$ 0.152 & 0.873 $\\pm$ 0.161 & 0.841 $\\pm$ 0.169 \\\\\n",
      "Dutch & SVM & 0.843 $\\pm$ 0.261 & 0.036 $\\pm$ 0.317 & 0.677 $\\pm$ 0.296 & 0.594 $\\pm$ 0.275 & 0.501 $\\pm$ 0.231 \\\\\n",
      "Dutch & Logistic Regr. & 0.77 $\\pm$ 0.291 & 0.042 $\\pm$ 0.297 & 0.702 $\\pm$ 0.295 & 0.624 $\\pm$ 0.282 & 0.535 $\\pm$ 0.25 \\\\\n",
      "Dutch & LIME & 0.484 $\\pm$ 0.166 & 0.059 $\\pm$ 0.258 & 0.466 $\\pm$ 0.11 & 0.459 $\\pm$ 0.101 & 0.447 $\\pm$ 0.096 \\\\\n",
      "Dutch & SHAP & 1.0 $\\pm$ 0.0 & 0.461 $\\pm$ 0.358 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.71 $\\pm$ 0.122 & - & 0.682 $\\pm$ 0.077 & 0.682 $\\pm$ 0.069 & 0.682 $\\pm$ 0.064 \\\\\n",
      "Dutch & Lore (Genetic) & 0.806 $\\pm$ 0.197 & - & 0.602 $\\pm$ 0.123 & 0.601 $\\pm$ 0.108 & 0.601 $\\pm$ 0.1 \\\\\\midrule\n",
      "House 16 & Decision Tree & 0.888 $\\pm$ 0.152 & - & 0.621 $\\pm$ 0.107 & 0.615 $\\pm$ 0.098 & 0.608 $\\pm$ 0.095 \\\\\n",
      "House 16 & SVM & 0.625 $\\pm$ 0.391 & 0.006 $\\pm$ 0.217 & 0.247 $\\pm$ 0.131 & 0.238 $\\pm$ 0.118 & 0.228 $\\pm$ 0.108 \\\\\n",
      "House 16 & Logistic Regr. & 0.669 $\\pm$ 0.256 & 0.099 $\\pm$ 0.238 & 0.389 $\\pm$ 0.097 & 0.38 $\\pm$ 0.086 & 0.371 $\\pm$ 0.078 \\\\\n",
      "House 16 & LIME & 0.577 $\\pm$ 0.133 & 0.073 $\\pm$ 0.256 & 0.473 $\\pm$ 0.06 & 0.469 $\\pm$ 0.047 & 0.466 $\\pm$ 0.038 \\\\\n",
      "House 16 & SHAP & 0.749 $\\pm$ 0.147 & 0.319 $\\pm$ 0.384 & 0.189 $\\pm$ 0.063 & 0.182 $\\pm$ 0.051 & 0.174 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.512 $\\pm$ 0.15 & - & 0.507 $\\pm$ 0.084 & 0.507 $\\pm$ 0.072 & 0.507 $\\pm$ 0.065 \\\\\n",
      "House 16 & Lore (Genetic) & 0.774 $\\pm$ 0.139 & - & 0.554 $\\pm$ 0.101 & 0.554 $\\pm$ 0.086 & 0.553 $\\pm$ 0.078 \\\\\\midrule\n",
      "Letter & Decision Tree & 0.944 $\\pm$ 0.116 & - & 0.586 $\\pm$ 0.118 & 0.569 $\\pm$ 0.105 & 0.55 $\\pm$ 0.096 \\\\\n",
      "Letter & SVM & 0.853 $\\pm$ 0.3 & 0.035 $\\pm$ 0.216 & 0.126 $\\pm$ 0.093 & 0.114 $\\pm$ 0.064 & 0.104 $\\pm$ 0.048 \\\\\n",
      "Letter & Logistic Regr. & 0.634 $\\pm$ 0.321 & 0.012 $\\pm$ 0.189 & 0.143 $\\pm$ 0.093 & 0.129 $\\pm$ 0.067 & 0.117 $\\pm$ 0.053 \\\\\n",
      "Letter & LIME & 0.227 $\\pm$ 0.104 & 0.041 $\\pm$ 0.201 & 0.187 $\\pm$ 0.069 & 0.18 $\\pm$ 0.062 & 0.171 $\\pm$ 0.056 \\\\\n",
      "Letter & SHAP & 0.524 $\\pm$ 0.152 & 0.566 $\\pm$ 0.223 & 0.24 $\\pm$ 0.103 & 0.22 $\\pm$ 0.09 & 0.199 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.621 $\\pm$ 0.101 & - & 0.608 $\\pm$ 0.06 & 0.608 $\\pm$ 0.052 & 0.608 $\\pm$ 0.047 \\\\\n",
      "Letter & Lore (Genetic) & 0.901 $\\pm$ 0.06 & - & 0.774 $\\pm$ 0.048 & 0.774 $\\pm$ 0.042 & 0.773 $\\pm$ 0.039 \\\\\\midrule\n",
      "Shuttle & Decision Tree & 0.913 $\\pm$ 0.19 & - & 0.781 $\\pm$ 0.181 & 0.772 $\\pm$ 0.174 & 0.76 $\\pm$ 0.171 \\\\\n",
      "Shuttle & SVM & 0.809 $\\pm$ 0.278 & 0.261 $\\pm$ 0.615 & 0.436 $\\pm$ 0.155 & 0.423 $\\pm$ 0.141 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & Logistic Regr. & 0.79 $\\pm$ 0.287 & 0.108 $\\pm$ 0.665 & 0.486 $\\pm$ 0.194 & 0.47 $\\pm$ 0.179 & 0.453 $\\pm$ 0.167 \\\\\n",
      "Shuttle & LIME & 0.423 $\\pm$ 0.195 & 0.01 $\\pm$ 0.668 & 0.328 $\\pm$ 0.144 & 0.32 $\\pm$ 0.132 & 0.312 $\\pm$ 0.125 \\\\\n",
      "Shuttle & SHAP & 1.0 $\\pm$ 0.0 & 0.57 $\\pm$ 0.551 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.713 $\\pm$ 0.115 & - & 0.699 $\\pm$ 0.073 & 0.699 $\\pm$ 0.065 & 0.699 $\\pm$ 0.06 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.866 $\\pm$ 0.119 & - & 0.752 $\\pm$ 0.078 & 0.752 $\\pm$ 0.069 & 0.752 $\\pm$ 0.064 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for custom LaTeX output\n",
    "df_grouped = df_metrics.groupby('Dataset')\n",
    "\n",
    "# Start building the LaTeX table\n",
    "latex_output = \"\\\\begin{tabular}{\" + \"l\" * len(df_metrics.columns) + \"}\\n\"\n",
    "latex_output += \"\\\\toprule\\n\"\n",
    "\n",
    "# Add headers\n",
    "latex_output += \" & \".join(df_metrics.columns) + \" \\\\\\\\\\n\"\n",
    "latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "# Add rows with midrules between datasets\n",
    "datasets = df_metrics['Dataset'].unique()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    group = df_grouped.get_group(dataset)\n",
    "    \n",
    "    # Convert group dataframe to LaTeX rows\n",
    "    rows_latex = group.to_latex(index=False, header=False)\n",
    "    \n",
    "    # Extract just the rows part (not headers or table structure)\n",
    "    rows_only = \"\\n\".join(rows_latex.split(\"\\n\")[3:-3])\n",
    "    \n",
    "    latex_output += rows_only\n",
    "    \n",
    "    # Add midrule if not the last dataset\n",
    "    if i < len(datasets) - 1:\n",
    "        latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "latex_output += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Robustness\\\\_top\\\\_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/synth_xai/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Robustness\\\\_top\\\\_3'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Call the function to plot the robustness per dataset\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mplot_robustness_per_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_metrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mplot_robustness_per_dataset\u001b[0;34m(df_metrics)\u001b[0m\n\u001b[1;32m     19\u001b[0m robustness_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m top_k:\n\u001b[0;32m---> 21\u001b[0m     robustness_value \u001b[38;5;241m=\u001b[39m \u001b[43msubset\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRobustness\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m_top\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m     robustness_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(robustness_value\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(top_k, robustness_values, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, label\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[0;32m~/synth_xai/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/synth_xai/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Robustness\\\\_top\\\\_3'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_robustness_per_dataset(df_metrics):\n",
    "    # Create the plots directory if it doesn't exist\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    \n",
    "    # Get the unique datasets\n",
    "    datasets = df_metrics['Dataset'].unique()\n",
    "    top_k = [3, 5, 8, 10, 20]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        subset = df_metrics[df_metrics['Dataset'] == dataset]\n",
    "        \n",
    "        for method in subset['Method'].unique():\n",
    "            robustness_values = []\n",
    "            for k in top_k:\n",
    "                robustness_value = subset[subset['Method'] == method][f'Robustness\\\\_top\\\\_{k}'].values[0]\n",
    "                robustness_values.append(float(robustness_value.split(' ')[0]))\n",
    "            \n",
    "            plt.plot(top_k, robustness_values, marker='o', markersize=10, label=method)\n",
    "        \n",
    "        plt.title(f'Robustness per K for {dataset}', fontsize=25)\n",
    "        plt.xlabel('K', fontsize=25)\n",
    "        plt.ylabel('Robustness', fontsize=25)\n",
    "        plt.xticks(top_k, fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3, fontsize=20)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig(f'plots/robustness_{dataset}.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Call the function to plot the robustness per dataset\n",
    "plot_robustness_per_dataset(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = download_runs(project_name=\"tango_eval\")\n",
    "project_name = \"tango_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading run  atw9xiir\n",
      "Downloading run  fqhezqc6\n",
      "Downloading run  zro78ljz\n",
      "Downloading run  pqhq8893\n",
      "Downloading run  jfyrc466\n",
      "Downloading run  ew09kxhc\n",
      "Downloading run  ow7abfwn\n",
      "Downloading run  w970mb4d\n",
      "Downloading run  ashjhyxu\n",
      "Downloading run  coj85sk5\n",
      "Downloading run  6l8ingce\n",
      "Downloading run  s9cuiccy\n",
      "Downloading run  rxc8lhce\n",
      "Downloading run  s067qrl9\n",
      "Downloading run  kktf0dw2\n",
      "Downloading run  azpa5w6i\n",
      "Downloading run  tby0gao2\n",
      "Downloading run  e8q3p408\n",
      "Downloading run  sx8gjzeq\n",
      "Downloading run  ka1gffmv\n",
      "Downloading run  66ti7ajw\n",
      "Downloading run  vps9w5h0\n",
      "Downloading run  iurmhuh9\n",
      "Downloading run  vuy3wdbc\n",
      "Downloading run  jhhmlzkc\n",
      "Downloading run  2t9mifpk\n",
      "Downloading run  7m6kfd3j\n",
      "Downloading run  c8wei8fz\n",
      "Downloading run  26bojefp\n",
      "Downloading run  j6olyyp0\n",
      "Downloading run  i7de0qa9\n",
      "Downloading run  7ltu9s3i\n",
      "Downloading run  xf9z8ml0\n",
      "Downloading run  9sdp0bdq\n",
      "Downloading run  h62sp4yz\n",
      "Downloading run  gm6caoms\n",
      "Downloading run  mgw1jr72\n",
      "Downloading run  lukwrutc\n",
      "Downloading run  ry5dsqtj\n",
      "Downloading run  363b62tn\n",
      "Downloading run  p9k39orh\n",
      "Downloading run  j7bmoxpb\n",
      "Downloading run  k7bjwr8q\n",
      "Downloading run  y8u6yyg5\n",
      "Downloading run  h5uqmak1\n",
      "Downloading run  w20wduva\n",
      "Downloading run  p1833n1z\n",
      "Downloading run  7ycei1nz\n",
      "Downloading run  m7g1omus\n",
      "Downloading run  7jadw3wl\n",
      "Downloading run  qtfdsz0f\n",
      "Downloading run  8z2lr2r1\n",
      "Downloading run  ihzafzjq\n",
      "Downloading run  yetzamew\n",
      "Downloading run  4lbcw0rg\n",
      "Downloading run  4va1wt5i\n",
      "Downloading run  jnvwqn8z\n",
      "Downloading run  y31wggud\n",
      "Downloading run  3lz84tg1\n",
      "Downloading run  0bppvp40\n",
      "Downloading run  pl8itrj9\n",
      "Downloading run  a92ajw08\n",
      "Downloading run  i9unylzc\n",
      "Downloading run  1dm6x8sz\n",
      "Downloading run  lhmc248x\n",
      "Downloading run  15ejkeah\n",
      "Downloading run  bhvk55az\n",
      "Downloading run  wgihchsj\n",
      "Downloading run  ezh7cwai\n",
      "Downloading run  dngvx9bt\n",
      "Downloading run  www2xg5f\n",
      "Downloading run  l0byb1g7\n",
      "Downloading run  7b3hrsv5\n",
      "Downloading run  bj0ec43s\n"
     ]
    }
   ],
   "source": [
    "project_data_comparison = download_runs(project_name=\"comparison_tango\")\n",
    "project_name = \"comparison_tango\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"dt\", \"svm\", \"logistic\"]\n",
    "datasets = [\"house16\", \"letter\", \"dutch\", \"adult\", \"covertype\", \"shuttle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}   \n",
    "    for method in methods: \n",
    "        metrics[dataset][method] = {}\n",
    "        results = project_data[f\"{method}_{dataset}\"][0]\n",
    "        fidelity_list = []\n",
    "        if \"Fidelity\" in results.columns:\n",
    "            fidelity_list = [float(f) for f in results[\"Fidelity\"].values]\n",
    "        \n",
    "        fidelity = round(np.mean(fidelity_list), 3)\n",
    "        fidelity_std = round(np.std(fidelity_list), 3)\n",
    "        metrics[dataset][method][\"Fidelity\"] = f\"{fidelity} $\\pm$ {fidelity_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        row = {\n",
    "            'Dataset': dataset,\n",
    "            'Method': method,\n",
    "            'Fidelity': metrics[dataset][method].get('Fidelity', '-'),\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"lime\", \"lore\", \"lore_genetic\"]\n",
    "datasets = [\"house16\", \"letter\", \"dutch\", \"adult\", \"covertype\", \"shuttle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime house16\n",
      "0.874 0.001\n",
      "lore house16\n",
      "0.533 0.0\n",
      "lore_genetic house16\n",
      "0.61 0.0\n",
      "lime letter\n",
      "0.04 0.0\n",
      "lore letter\n",
      "0.04 0.001\n",
      "lore_genetic letter\n",
      "0.044 0.0\n",
      "lime dutch\n",
      "0.896 0.001\n",
      "lore dutch\n",
      "0.498 0.001\n",
      "lore_genetic dutch\n",
      "0.501 0.0\n",
      "lime adult\n",
      "0.901 0.0\n",
      "lore adult\n",
      "0.668 0.001\n",
      "lore_genetic adult\n",
      "0.636 0.0\n",
      "lime covertype\n",
      "0.711 0.001\n",
      "lore covertype\n",
      "0.36 0.001\n",
      "lore_genetic covertype\n",
      "0.394 0.0\n",
      "lime shuttle\n",
      "0.801 0.0\n",
      "lore shuttle\n",
      "0.659 0.0\n",
      "lore_genetic shuttle\n",
      "0.663 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1837723/815475273.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_list.append(float(result[\"fidelity\"]))\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    for method in methods: \n",
    "        print(method, dataset)\n",
    "        metrics[dataset][method] = {}\n",
    "        results = project_data_comparison[f\"{method}_{dataset}\"]\n",
    "        fidelity_list = []\n",
    "        for result in results: \n",
    "            if \"fidelity\" in result.columns:\n",
    "                fidelity_list.append(float(result[\"fidelity\"]))\n",
    "            \n",
    "        \n",
    "        fidelity = round(np.mean(fidelity_list), 3)\n",
    "        fidelity_std = round(np.std(fidelity_list), 3)\n",
    "        metrics[dataset][method][\"Fidelity\"] = f\"{fidelity} $\\pm$ {fidelity_std}\"\n",
    "        print(fidelity, fidelity_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'house16': {'dt': {'Fidelity': '0.896 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.743 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.962 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.874 $\\\\pm$ 0.001'},\n",
       "  'lore': {'Fidelity': '0.533 $\\\\pm$ 0.0'},\n",
       "  'lore_genetic': {'Fidelity': '0.61 $\\\\pm$ 0.0'}},\n",
       " 'letter': {'dt': {'Fidelity': '0.708 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.861 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.843 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.04 $\\\\pm$ 0.0'},\n",
       "  'lore': {'Fidelity': '0.04 $\\\\pm$ 0.001'},\n",
       "  'lore_genetic': {'Fidelity': '0.044 $\\\\pm$ 0.0'}},\n",
       " 'dutch': {'dt': {'Fidelity': '0.995 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.996 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.997 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.896 $\\\\pm$ 0.001'},\n",
       "  'lore': {'Fidelity': '0.498 $\\\\pm$ 0.001'},\n",
       "  'lore_genetic': {'Fidelity': '0.501 $\\\\pm$ 0.0'}},\n",
       " 'adult': {'dt': {'Fidelity': '0.95 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.522 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.894 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.901 $\\\\pm$ 0.0'},\n",
       "  'lore': {'Fidelity': '0.668 $\\\\pm$ 0.001'},\n",
       "  'lore_genetic': {'Fidelity': '0.636 $\\\\pm$ 0.0'}},\n",
       " 'covertype': {'dt': {'Fidelity': '0.834 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.6 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.872 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.711 $\\\\pm$ 0.001'},\n",
       "  'lore': {'Fidelity': '0.36 $\\\\pm$ 0.001'},\n",
       "  'lore_genetic': {'Fidelity': '0.394 $\\\\pm$ 0.0'}},\n",
       " 'shuttle': {'dt': {'Fidelity': '0.985 $\\\\pm$ 0.0'},\n",
       "  'svm': {'Fidelity': '0.983 $\\\\pm$ 0.0'},\n",
       "  'logistic': {'Fidelity': '0.993 $\\\\pm$ 0.0'},\n",
       "  'lime': {'Fidelity': '0.801 $\\\\pm$ 0.0'},\n",
       "  'lore': {'Fidelity': '0.659 $\\\\pm$ 0.0'},\n",
       "  'lore_genetic': {'Fidelity': '0.663 $\\\\pm$ 0.0'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        row = {\n",
    "            'Dataset': dataset,\n",
    "            'Method': method,\n",
    "            'Fidelity': metrics[dataset][method].get('Fidelity', '-'),\n",
    "        }\n",
    "        rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fidelity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.95 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adult</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.522 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.894 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.901 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.668 $\\pm$ 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.636 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.834 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.872 $\\pm$ 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset          Method           Fidelity\n",
       "9       Adult   Decision Tree     0.95 $\\pm$ 0.0\n",
       "10      Adult             SVM    0.522 $\\pm$ 0.0\n",
       "11      Adult  Logistic Regr.    0.894 $\\pm$ 0.0\n",
       "27      Adult            LIME    0.901 $\\pm$ 0.0\n",
       "28      Adult   Lore (Random)  0.668 $\\pm$ 0.001\n",
       "29      Adult  Lore (Genetic)    0.636 $\\pm$ 0.0\n",
       "12  Covertype   Decision Tree    0.834 $\\pm$ 0.0\n",
       "13  Covertype             SVM      0.6 $\\pm$ 0.0\n",
       "14  Covertype  Logistic Regr.    0.872 $\\pm$ 0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "df_metrics.head(10)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': 'Decision Tree',\n",
    "    'svm': 'SVM',\n",
    "    'logistic': 'Logistic Regr.',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Method\"] = df_metrics[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    'Decision Tree': 1, \n",
    "    'SVM': 2, \n",
    "    'Logistic Regr.': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics['method_order'] = df_metrics['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics = df_metrics.drop(columns=['method_order'])\n",
    "\n",
    "df_metrics.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df_metrics by dataset name\n",
    "\n",
    "# remove index \n",
    "df_metrics = df_metrics.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "Dataset & Method & Fidelity \\\\\n",
      "\\midrule\n",
      "Adult & Decision Tree & 0.95 $\\pm$ 0.0 \\\\\n",
      "Adult & SVM & 0.522 $\\pm$ 0.0 \\\\\n",
      "Adult & Logistic Regr. & 0.894 $\\pm$ 0.0 \\\\\n",
      "Adult & LIME & 0.901 $\\pm$ 0.0 \\\\\n",
      "Adult & Lore (Random) & 0.668 $\\pm$ 0.001 \\\\\n",
      "Adult & Lore (Genetic) & 0.636 $\\pm$ 0.0 \\\\\\midrule\n",
      "Covertype & Decision Tree & 0.834 $\\pm$ 0.0 \\\\\n",
      "Covertype & SVM & 0.6 $\\pm$ 0.0 \\\\\n",
      "Covertype & Logistic Regr. & 0.872 $\\pm$ 0.0 \\\\\n",
      "Covertype & LIME & 0.711 $\\pm$ 0.001 \\\\\n",
      "Covertype & Lore (Random) & 0.36 $\\pm$ 0.001 \\\\\n",
      "Covertype & Lore (Genetic) & 0.394 $\\pm$ 0.0 \\\\\\midrule\n",
      "Dutch & Decision Tree & 0.995 $\\pm$ 0.0 \\\\\n",
      "Dutch & SVM & 0.996 $\\pm$ 0.0 \\\\\n",
      "Dutch & Logistic Regr. & 0.997 $\\pm$ 0.0 \\\\\n",
      "Dutch & LIME & 0.896 $\\pm$ 0.001 \\\\\n",
      "Dutch & Lore (Random) & 0.498 $\\pm$ 0.001 \\\\\n",
      "Dutch & Lore (Genetic) & 0.501 $\\pm$ 0.0 \\\\\\midrule\n",
      "House 16 & Decision Tree & 0.896 $\\pm$ 0.0 \\\\\n",
      "House 16 & SVM & 0.743 $\\pm$ 0.0 \\\\\n",
      "House 16 & Logistic Regr. & 0.962 $\\pm$ 0.0 \\\\\n",
      "House 16 & LIME & 0.874 $\\pm$ 0.001 \\\\\n",
      "House 16 & Lore (Random) & 0.533 $\\pm$ 0.0 \\\\\n",
      "House 16 & Lore (Genetic) & 0.61 $\\pm$ 0.0 \\\\\\midrule\n",
      "Letter & Decision Tree & 0.708 $\\pm$ 0.0 \\\\\n",
      "Letter & SVM & 0.861 $\\pm$ 0.0 \\\\\n",
      "Letter & Logistic Regr. & 0.843 $\\pm$ 0.0 \\\\\n",
      "Letter & LIME & 0.04 $\\pm$ 0.0 \\\\\n",
      "Letter & Lore (Random) & 0.04 $\\pm$ 0.001 \\\\\n",
      "Letter & Lore (Genetic) & 0.044 $\\pm$ 0.0 \\\\\\midrule\n",
      "Shuttle & Decision Tree & 0.985 $\\pm$ 0.0 \\\\\n",
      "Shuttle & SVM & 0.983 $\\pm$ 0.0 \\\\\n",
      "Shuttle & Logistic Regr. & 0.993 $\\pm$ 0.0 \\\\\n",
      "Shuttle & LIME & 0.801 $\\pm$ 0.0 \\\\\n",
      "Shuttle & Lore (Random) & 0.659 $\\pm$ 0.0 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.663 $\\pm$ 0.0 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for custom LaTeX output\n",
    "df_grouped = df_metrics.groupby('Dataset')\n",
    "\n",
    "# Start building the LaTeX table\n",
    "latex_output = \"\\\\begin{tabular}{\" + \"l\" * len(df_metrics.columns) + \"}\\n\"\n",
    "latex_output += \"\\\\toprule\\n\"\n",
    "\n",
    "# Add headers\n",
    "latex_output += \" & \".join(df_metrics.columns) + \" \\\\\\\\\\n\"\n",
    "latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "# Add rows with midrules between datasets\n",
    "datasets = df_metrics['Dataset'].unique()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    group = df_grouped.get_group(dataset)\n",
    "    \n",
    "    # Convert group dataframe to LaTeX rows\n",
    "    rows_latex = group.to_latex(index=False, header=False)\n",
    "    \n",
    "    # Extract just the rows part (not headers or table structure)\n",
    "    rows_only = \"\\n\".join(rows_latex.split(\"\\n\")[3:-3])\n",
    "    \n",
    "    latex_output += rows_only\n",
    "    \n",
    "    # Add midrule if not the last dataset\n",
    "    if i < len(datasets) - 1:\n",
    "        latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "latex_output += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "\n",
    "print(latex_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
