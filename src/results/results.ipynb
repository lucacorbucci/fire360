{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "import dill\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_runs(project_name):\n",
    "    if not os.path.exists(\n",
    "        f\"./results_data/data_{project_name}.pkl\"\n",
    "    ):\n",
    "        project_details = wandb.Api().runs(f\"lucacorbucci/{project_name}\")\n",
    "        project_data = {}\n",
    "        for run in project_details:\n",
    "            print(\"Downloading run \", run.id)\n",
    "            try:\n",
    "                run_df = pd.DataFrame(\n",
    "                    wandb.Api().run(f\"lucacorbucci/{project_name}/{run.id}\").scan_history()\n",
    "                )\n",
    "                if run.name not in project_data:\n",
    "                    project_data[run.name] = []\n",
    "                project_data[run.name].append(run_df)\n",
    "            except Exception as e:\n",
    "                print(\"Error downloading run \", run.id, e)\n",
    "        with open(\n",
    "            f\"./results_data/data_{project_name}.pkl\", \"wb\"\n",
    "        ) as f:\n",
    "            dill.dump(project_data, f)\n",
    "    else:\n",
    "        with open(\n",
    "            f\"./results_data/data_{project_name}.pkl\", \"rb\"\n",
    "        ) as f:\n",
    "            project_data = dill.load(f)\n",
    "    return project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = download_runs(project_name=\"new_metrics_computation\")\n",
    "project_name = \"new_metrics_computation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"dt\", \"svm\", \"logistic\", \"lime\", \"shap\", \"lore\", \"lore_genetic\"]\n",
    "datasets = [\"house16\", \"letter\", \"shuttle\", \"adult\", \"dutch\", \"covertype\"]\n",
    "top_k = [3, 5, 8, 10, 15, 20]\n",
    "neigh_sizes = [1000, 2500, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1303545/2203470197.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  stability = round(float(result[\"stability\"]), 3)\n",
      "/tmp/ipykernel_1303545/2203470197.py:19: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  stability_std = round(float(result[\"stability_std\"]), 3)\n",
      "/tmp/ipykernel_1303545/2203470197.py:23: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  robustness = round(float(result[f\"robustness_top_{k}\"]), 3)\n",
      "/tmp/ipykernel_1303545/2203470197.py:24: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  robustness_std = round(float(result[f\"robustness_std_top_{k}\"]), 3)\n",
      "/tmp/ipykernel_1303545/2203470197.py:14: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  faithfulness = round(float(result[\"faithfulness\"]), 3)\n",
      "/tmp/ipykernel_1303545/2203470197.py:15: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  faithfulness_std = round(float(result[\"faithfulness_std\"]), 3)\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}\n",
    "    for method in methods:\n",
    "        metrics[dataset][method] = {}\n",
    "        for neigh_size in neigh_sizes:\n",
    "            metrics[dataset][method][neigh_size] = {}\n",
    "            if f\"{method}_{dataset}\" in project_data:\n",
    "                results = project_data[f\"{method}_{dataset}\"]\n",
    "                for result in results:\n",
    "                    if \"neigh_size\" in result and (result[\"neigh_size\"][0] == neigh_size or result[\"neigh_size\"][0] == -1):\n",
    "                        if \"faithfulness\" in result.columns:\n",
    "                            faithfulness = round(float(result[\"faithfulness\"]), 3)\n",
    "                            faithfulness_std = round(float(result[\"faithfulness_std\"]), 3)\n",
    "                            metrics[dataset][method][neigh_size][\"Faithfulness\"] = f\"{faithfulness} $\\pm$ {faithfulness_std}\"\n",
    "                        if \"stability\" in result.columns:\n",
    "                            stability = round(float(result[\"stability\"]), 3)\n",
    "                            stability_std = round(float(result[\"stability_std\"]), 3)\n",
    "                            metrics[dataset][method][neigh_size][\"stability\"] = f\"{stability} $\\pm$ {stability_std}\"\n",
    "                        for k in top_k:\n",
    "                            if f\"robustness_top_{k}\" in result.columns:\n",
    "                                robustness = round(float(result[f\"robustness_top_{k}\"]), 3)\n",
    "                                robustness_std = round(float(result[f\"robustness_std_top_{k}\"]), 3)\n",
    "                                metrics[dataset][method][neigh_size][f\"robustness_top_{k}\"] = f\"{robustness} $\\pm$ {robustness_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: {'stability': '0.377 $\\\\pm$ 0.153',\n",
       "  'robustness_top_3': '0.225 $\\\\pm$ 0.129',\n",
       "  'robustness_top_5': '0.225 $\\\\pm$ 0.112',\n",
       "  'robustness_top_8': '0.224 $\\\\pm$ 0.102',\n",
       "  'robustness_top_10': '0.224 $\\\\pm$ 0.098',\n",
       "  'robustness_top_15': '0.224 $\\\\pm$ 0.093',\n",
       "  'robustness_top_20': '0.224 $\\\\pm$ 0.091'},\n",
       " 2500: {'stability': '0.469 $\\\\pm$ 0.154',\n",
       "  'robustness_top_3': '0.235 $\\\\pm$ 0.124',\n",
       "  'robustness_top_5': '0.235 $\\\\pm$ 0.104',\n",
       "  'robustness_top_8': '0.235 $\\\\pm$ 0.092',\n",
       "  'robustness_top_10': '0.235 $\\\\pm$ 0.088',\n",
       "  'robustness_top_15': '0.235 $\\\\pm$ 0.081',\n",
       "  'robustness_top_20': '0.235 $\\\\pm$ 0.077'},\n",
       " 5000: {'stability': '0.339 $\\\\pm$ 0.223',\n",
       "  'robustness_top_3': '0.341 $\\\\pm$ 0.155',\n",
       "  'robustness_top_5': '0.342 $\\\\pm$ 0.137',\n",
       "  'robustness_top_8': '0.341 $\\\\pm$ 0.126',\n",
       "  'robustness_top_10': '0.341 $\\\\pm$ 0.122',\n",
       "  'robustness_top_15': '0.342 $\\\\pm$ 0.116',\n",
       "  'robustness_top_20': '0.341 $\\\\pm$ 0.113'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"adult\"][\"lore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=3</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=8</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>-</td>\n",
       "      <td>0.417 $\\pm$ 0.147</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.38 $\\pm$ 0.106</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>-</td>\n",
       "      <td>0.593 $\\pm$ 0.141</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.579 $\\pm$ 0.116</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>-</td>\n",
       "      <td>0.616 $\\pm$ 0.136</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.603 $\\pm$ 0.111</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.265 $\\pm$ 0.111</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.26 $\\pm$ 0.086</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.298 $\\pm$ 0.117</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.294 $\\pm$ 0.101</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.727 $\\pm$ 0.34</td>\n",
       "      <td>0.012 $\\pm$ 0.122</td>\n",
       "      <td>0.244 $\\pm$ 0.114</td>\n",
       "      <td>0.242 $\\pm$ 0.103</td>\n",
       "      <td>0.241 $\\pm$ 0.096</td>\n",
       "      <td>0.24 $\\pm$ 0.094</td>\n",
       "      <td>0.238 $\\pm$ 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.384 $\\pm$ 0.279</td>\n",
       "      <td>-0.013 $\\pm$ 0.211</td>\n",
       "      <td>0.178 $\\pm$ 0.121</td>\n",
       "      <td>0.177 $\\pm$ 0.125</td>\n",
       "      <td>0.162 $\\pm$ 0.103</td>\n",
       "      <td>0.155 $\\pm$ 0.088</td>\n",
       "      <td>0.137 $\\pm$ 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.5 $\\pm$ 0.28</td>\n",
       "      <td>0.012 $\\pm$ 0.212</td>\n",
       "      <td>0.276 $\\pm$ 0.147</td>\n",
       "      <td>0.274 $\\pm$ 0.133</td>\n",
       "      <td>0.271 $\\pm$ 0.125</td>\n",
       "      <td>0.27 $\\pm$ 0.122</td>\n",
       "      <td>0.265 $\\pm$ 0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.469 $\\pm$ 0.224</td>\n",
       "      <td>0.003 $\\pm$ 0.211</td>\n",
       "      <td>0.249 $\\pm$ 0.104</td>\n",
       "      <td>0.247 $\\pm$ 0.092</td>\n",
       "      <td>0.245 $\\pm$ 0.084</td>\n",
       "      <td>0.244 $\\pm$ 0.081</td>\n",
       "      <td>0.24 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Neighborhood Size          Method          Stability  \\\n",
       "63   Adult               1000   Decision Tree   0.845 $\\pm$ 0.23   \n",
       "64   Adult               2500   Decision Tree  0.898 $\\pm$ 0.167   \n",
       "65   Adult               5000   Decision Tree   0.92 $\\pm$ 0.148   \n",
       "66   Adult               1000             SVM  0.861 $\\pm$ 0.267   \n",
       "67   Adult               2500             SVM  0.859 $\\pm$ 0.258   \n",
       "68   Adult               5000             SVM   0.727 $\\pm$ 0.34   \n",
       "69   Adult               1000  Logistic Regr.  0.384 $\\pm$ 0.279   \n",
       "70   Adult               2500  Logistic Regr.     0.5 $\\pm$ 0.28   \n",
       "71   Adult               5000  Logistic Regr.  0.469 $\\pm$ 0.224   \n",
       "\n",
       "          Faithfulness     Robustness K=3     Robustness K=5  \\\n",
       "63                   -  0.417 $\\pm$ 0.147  0.397 $\\pm$ 0.122   \n",
       "64                   -  0.593 $\\pm$ 0.141  0.586 $\\pm$ 0.126   \n",
       "65                   -  0.616 $\\pm$ 0.136  0.609 $\\pm$ 0.121   \n",
       "66   0.019 $\\pm$ 0.117  0.265 $\\pm$ 0.111  0.261 $\\pm$ 0.097   \n",
       "67    0.01 $\\pm$ 0.112  0.298 $\\pm$ 0.117  0.296 $\\pm$ 0.107   \n",
       "68   0.012 $\\pm$ 0.122  0.244 $\\pm$ 0.114  0.242 $\\pm$ 0.103   \n",
       "69  -0.013 $\\pm$ 0.211  0.178 $\\pm$ 0.121  0.177 $\\pm$ 0.125   \n",
       "70   0.012 $\\pm$ 0.212  0.276 $\\pm$ 0.147  0.274 $\\pm$ 0.133   \n",
       "71   0.003 $\\pm$ 0.211  0.249 $\\pm$ 0.104  0.247 $\\pm$ 0.092   \n",
       "\n",
       "       Robustness K=8    Robustness K=10    Robustness K=20  \n",
       "63   0.38 $\\pm$ 0.106  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "64  0.579 $\\pm$ 0.116  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "65  0.603 $\\pm$ 0.111    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "66   0.26 $\\pm$ 0.086  0.259 $\\pm$ 0.084  0.257 $\\pm$ 0.081  \n",
       "67  0.294 $\\pm$ 0.101  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "68  0.241 $\\pm$ 0.096   0.24 $\\pm$ 0.094  0.238 $\\pm$ 0.088  \n",
       "69  0.162 $\\pm$ 0.103  0.155 $\\pm$ 0.088  0.137 $\\pm$ 0.059  \n",
       "70  0.271 $\\pm$ 0.125   0.27 $\\pm$ 0.122  0.265 $\\pm$ 0.114  \n",
       "71  0.245 $\\pm$ 0.084  0.244 $\\pm$ 0.081   0.24 $\\pm$ 0.075  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "top_k_table = [3, 5, 8, 10,20]\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for neigh_size in neigh_sizes:\n",
    "            row = {\n",
    "                'Dataset': dataset,\n",
    "                'Neighborhood Size': neigh_size,\n",
    "                'Method': method,\n",
    "                'Stability': metrics[dataset][method][neigh_size].get('stability', '-'),\n",
    "                'Faithfulness': metrics[dataset][method][neigh_size].get('Faithfulness', '-')\n",
    "            }\n",
    "            for k in top_k_table:\n",
    "                row[f\"Robustness K={k}\"] = metrics[dataset][method][neigh_size].get(f'robustness_top_{k}', '-')\n",
    "            rows.append(row)\n",
    "\n",
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': 'Decision Tree',\n",
    "    'svm': 'SVM',\n",
    "    'logistic': 'Logistic Regr.',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Method\"] = df_metrics[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    'Decision Tree': 1, \n",
    "    'SVM': 2, \n",
    "    'Logistic Regr.': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics['method_order'] = df_metrics['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics = df_metrics.drop(columns=['method_order'])\n",
    "df_metrics_all_the_robustness = df_metrics.copy()\n",
    "df_metrics.head(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>-</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>-</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.727 $\\pm$ 0.34</td>\n",
       "      <td>0.012 $\\pm$ 0.122</td>\n",
       "      <td>0.242 $\\pm$ 0.103</td>\n",
       "      <td>0.24 $\\pm$ 0.094</td>\n",
       "      <td>0.238 $\\pm$ 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.384 $\\pm$ 0.279</td>\n",
       "      <td>-0.013 $\\pm$ 0.211</td>\n",
       "      <td>0.177 $\\pm$ 0.125</td>\n",
       "      <td>0.155 $\\pm$ 0.088</td>\n",
       "      <td>0.137 $\\pm$ 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.5 $\\pm$ 0.28</td>\n",
       "      <td>0.012 $\\pm$ 0.212</td>\n",
       "      <td>0.274 $\\pm$ 0.133</td>\n",
       "      <td>0.27 $\\pm$ 0.122</td>\n",
       "      <td>0.265 $\\pm$ 0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.469 $\\pm$ 0.224</td>\n",
       "      <td>0.003 $\\pm$ 0.211</td>\n",
       "      <td>0.247 $\\pm$ 0.092</td>\n",
       "      <td>0.244 $\\pm$ 0.081</td>\n",
       "      <td>0.24 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Neighborhood Size       Method          Stability  \\\n",
       "63   Adult               1000   \\fire (DT)   0.845 $\\pm$ 0.23   \n",
       "64   Adult               2500   \\fire (DT)  0.898 $\\pm$ 0.167   \n",
       "65   Adult               5000   \\fire (DT)   0.92 $\\pm$ 0.148   \n",
       "66   Adult               1000  \\fire (SVM)  0.861 $\\pm$ 0.267   \n",
       "67   Adult               2500  \\fire (SVM)  0.859 $\\pm$ 0.258   \n",
       "68   Adult               5000  \\fire (SVM)   0.727 $\\pm$ 0.34   \n",
       "69   Adult               1000   \\fire (LR)  0.384 $\\pm$ 0.279   \n",
       "70   Adult               2500   \\fire (LR)     0.5 $\\pm$ 0.28   \n",
       "71   Adult               5000   \\fire (LR)  0.469 $\\pm$ 0.224   \n",
       "\n",
       "          Faithfulness     Robustness K=5    Robustness K=10  \\\n",
       "63                   -  0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104   \n",
       "64                   -  0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111   \n",
       "65                   -  0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   \n",
       "66   0.019 $\\pm$ 0.117  0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084   \n",
       "67    0.01 $\\pm$ 0.112  0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099   \n",
       "68   0.012 $\\pm$ 0.122  0.242 $\\pm$ 0.103   0.24 $\\pm$ 0.094   \n",
       "69  -0.013 $\\pm$ 0.211  0.177 $\\pm$ 0.125  0.155 $\\pm$ 0.088   \n",
       "70   0.012 $\\pm$ 0.212  0.274 $\\pm$ 0.133   0.27 $\\pm$ 0.122   \n",
       "71   0.003 $\\pm$ 0.211  0.247 $\\pm$ 0.092  0.244 $\\pm$ 0.081   \n",
       "\n",
       "      Robustness K=20  \n",
       "63  0.358 $\\pm$ 0.098  \n",
       "64  0.564 $\\pm$ 0.102  \n",
       "65   0.59 $\\pm$ 0.097  \n",
       "66  0.257 $\\pm$ 0.081  \n",
       "67  0.288 $\\pm$ 0.093  \n",
       "68  0.238 $\\pm$ 0.088  \n",
       "69  0.137 $\\pm$ 0.059  \n",
       "70  0.265 $\\pm$ 0.114  \n",
       "71   0.24 $\\pm$ 0.075  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "top_k_table = [5,10,20]\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for neigh_size in neigh_sizes:\n",
    "\n",
    "            row = {\n",
    "                'Dataset': dataset,\n",
    "                'Neighborhood Size': neigh_size,\n",
    "                'Method': method,\n",
    "                'Stability': metrics[dataset][method][neigh_size].get('stability', '-'),\n",
    "                'Faithfulness': metrics[dataset][method][neigh_size].get('Faithfulness', '-'),\n",
    "            }\n",
    "            for k in top_k_table:\n",
    "                row[f\"Robustness K={k}\"] = metrics[dataset][method][neigh_size].get(f'robustness_top_{k}', '-')\n",
    "            rows.append(row)\n",
    "\n",
    "# Create a dataframe from the rows\n",
    "df_metrics_complete = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': r'\\fire (DT)',\n",
    "    'svm': r'\\fire (SVM)',\n",
    "    'logistic': r'\\fire (LR)',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics_complete[\"Method\"] = df_metrics_complete[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics_complete[\"Dataset\"] = df_metrics_complete[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics_complete = df_metrics_complete.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    r'\\fire (DT)': 1, \n",
    "    r'\\fire (SVM)': 2, \n",
    "    r'\\fire (LR)': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics_complete['method_order'] = df_metrics_complete['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics_complete = df_metrics_complete.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics_complete = df_metrics_complete.drop(columns=['method_order'])\n",
    "\n",
    "df_metrics_complete.head(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fancy_table(df):\n",
    "    # Prepare dataframe for custom LaTeX output\n",
    "    df_grouped = df.groupby('Dataset')\n",
    "\n",
    "    # Start building the LaTeX table\n",
    "    latex_output = \"\\\\begin{tabular}{\" + \"l\" * len(df.columns) + \"}\\n\"\n",
    "    latex_output += \"\\\\toprule\\n\"\n",
    "\n",
    "    # Add headers\n",
    "    latex_output += \" & \".join(df.columns) + \" \\\\\\\\\\n\"\n",
    "    latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "    # Add rows with midrules between datasets\n",
    "    datasets = df['Dataset'].unique()\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        group = df_grouped.get_group(dataset)\n",
    "        \n",
    "        # Convert group dataframe to LaTeX rows\n",
    "        rows_latex = group.to_latex(index=False, header=False)\n",
    "        \n",
    "        # Extract just the rows part (not headers or table structure)\n",
    "        rows_only = \"\\n\".join(rows_latex.split(\"\\n\")[3:-3])\n",
    "        \n",
    "        latex_output += rows_only\n",
    "        \n",
    "        # Add midrule if not the last dataset\n",
    "        if i < len(datasets) - 1:\n",
    "            latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "    latex_output += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "\n",
    "    print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Stability & Faithfulness & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.845 $\\pm$ 0.23 & - & 0.397 $\\pm$ 0.122 & 0.375 $\\pm$ 0.104 & 0.358 $\\pm$ 0.098 \\\\\n",
      "Adult & \\fire (SVM) & 0.861 $\\pm$ 0.267 & 0.019 $\\pm$ 0.117 & 0.261 $\\pm$ 0.097 & 0.259 $\\pm$ 0.084 & 0.257 $\\pm$ 0.081 \\\\\n",
      "Adult & \\fire (LR) & 0.384 $\\pm$ 0.279 & -0.013 $\\pm$ 0.211 & 0.177 $\\pm$ 0.125 & 0.155 $\\pm$ 0.088 & 0.137 $\\pm$ 0.059 \\\\\n",
      "Adult & LIME & 0.04 $\\pm$ 0.017 & 0.066 $\\pm$ 0.18 & 0.04 $\\pm$ 0.008 & 0.04 $\\pm$ 0.006 & 0.04 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 0.406 $\\pm$ 0.196 & 0.515 $\\pm$ 0.16 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 0.377 $\\pm$ 0.153 & - & 0.225 $\\pm$ 0.112 & 0.224 $\\pm$ 0.098 & 0.224 $\\pm$ 0.091 \\\\\n",
      "Adult & Lore (Genetic) & 0.222 $\\pm$ 0.252 & - & 0.221 $\\pm$ 0.143 & 0.221 $\\pm$ 0.124 & 0.222 $\\pm$ 0.112 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.902 $\\pm$ 0.154 & - & 0.464 $\\pm$ 0.102 & 0.453 $\\pm$ 0.087 & 0.438 $\\pm$ 0.082 \\\\\n",
      "Covertype & \\fire (SVM) & 0.57 $\\pm$ 0.343 & -0.078 $\\pm$ 0.262 & 0.127 $\\pm$ 0.046 & 0.121 $\\pm$ 0.041 & 0.114 $\\pm$ 0.04 \\\\\n",
      "Covertype & \\fire (LR) & 0.696 $\\pm$ 0.365 & -0.039 $\\pm$ 0.328 & 0.101 $\\pm$ 0.063 & 0.093 $\\pm$ 0.043 & 0.085 $\\pm$ 0.03 \\\\\n",
      "Covertype & LIME & 0.597 $\\pm$ 0.04 & -0.101 $\\pm$ 0.274 & 0.592 $\\pm$ 0.022 & 0.591 $\\pm$ 0.018 & 0.591 $\\pm$ 0.016 \\\\\n",
      "Covertype & SHAP & 0.182 $\\pm$ 0.067 & 0.519 $\\pm$ 0.313 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.536 $\\pm$ 0.12 & - & 0.308 $\\pm$ 0.061 & 0.308 $\\pm$ 0.05 & 0.308 $\\pm$ 0.043 \\\\\n",
      "Covertype & Lore (Genetic) & 0.364 $\\pm$ 0.132 & - & 0.356 $\\pm$ 0.075 & 0.357 $\\pm$ 0.064 & 0.357 $\\pm$ 0.059 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.965 $\\pm$ 0.114 & - & 0.628 $\\pm$ 0.24 & 0.597 $\\pm$ 0.215 & 0.551 $\\pm$ 0.186 \\\\\n",
      "Dutch & \\fire (SVM) & 0.796 $\\pm$ 0.283 & 0.073 $\\pm$ 0.315 & 0.25 $\\pm$ 0.097 & 0.219 $\\pm$ 0.065 & 0.201 $\\pm$ 0.05 \\\\\n",
      "Dutch & \\fire (LR) & 0.769 $\\pm$ 0.292 & 0.063 $\\pm$ 0.257 & 0.267 $\\pm$ 0.122 & 0.233 $\\pm$ 0.085 & 0.208 $\\pm$ 0.066 \\\\\n",
      "Dutch & LIME & 0.34 $\\pm$ 0.133 & 0.058 $\\pm$ 0.254 & 0.328 $\\pm$ 0.081 & 0.323 $\\pm$ 0.073 & 0.316 $\\pm$ 0.069 \\\\\n",
      "Dutch & SHAP & 1.0 $\\pm$ 0.0 & 0.461 $\\pm$ 0.358 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.733 $\\pm$ 0.255 & - & 0.5 $\\pm$ 0.151 & 0.499 $\\pm$ 0.132 & 0.5 $\\pm$ 0.12 \\\\\n",
      "Dutch & Lore (Genetic) & 0.641 $\\pm$ 0.157 & - & 0.625 $\\pm$ 0.098 & 0.625 $\\pm$ 0.087 & 0.625 $\\pm$ 0.082 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.916 $\\pm$ 0.129 & - & 0.572 $\\pm$ 0.104 & 0.563 $\\pm$ 0.09 & 0.553 $\\pm$ 0.082 \\\\\n",
      "House 16 & \\fire (SVM) & 0.531 $\\pm$ 0.393 & 0.005 $\\pm$ 0.196 & 0.175 $\\pm$ 0.079 & 0.166 $\\pm$ 0.074 & 0.155 $\\pm$ 0.063 \\\\\n",
      "House 16 & \\fire (LR) & 0.68 $\\pm$ 0.244 & 0.091 $\\pm$ 0.236 & 0.35 $\\pm$ 0.111 & 0.33 $\\pm$ 0.094 & 0.309 $\\pm$ 0.078 \\\\\n",
      "House 16 & LIME & 0.498 $\\pm$ 0.119 & 0.07 $\\pm$ 0.255 & 0.452 $\\pm$ 0.054 & 0.45 $\\pm$ 0.041 & 0.449 $\\pm$ 0.032 \\\\\n",
      "House 16 & SHAP & 0.746 $\\pm$ 0.146 & 0.319 $\\pm$ 0.384 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.655 $\\pm$ 0.161 & - & 0.425 $\\pm$ 0.119 & 0.425 $\\pm$ 0.099 & 0.425 $\\pm$ 0.088 \\\\\n",
      "House 16 & Lore (Genetic) & 0.472 $\\pm$ 0.154 & - & 0.472 $\\pm$ 0.086 & 0.472 $\\pm$ 0.073 & 0.472 $\\pm$ 0.064 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.927 $\\pm$ 0.135 & - & 0.478 $\\pm$ 0.125 & 0.471 $\\pm$ 0.116 & 0.47 $\\pm$ 0.116 \\\\\n",
      "Letter & \\fire (SVM) & 0.859 $\\pm$ 0.283 & 0.02 $\\pm$ 0.241 & 0.083 $\\pm$ 0.052 & 0.083 $\\pm$ 0.05 & 0.083 $\\pm$ 0.05 \\\\\n",
      "Letter & \\fire (LR) & 0.629 $\\pm$ 0.313 & 0.0 $\\pm$ 0.188 & 0.089 $\\pm$ 0.048 & 0.087 $\\pm$ 0.046 & 0.087 $\\pm$ 0.046 \\\\\n",
      "Letter & LIME & 0.143 $\\pm$ 0.09 & 0.023 $\\pm$ 0.206 & 0.128 $\\pm$ 0.048 & 0.126 $\\pm$ 0.04 & 0.122 $\\pm$ 0.035 \\\\\n",
      "Letter & SHAP & 0.522 $\\pm$ 0.153 & 0.567 $\\pm$ 0.223 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.764 $\\pm$ 0.085 & - & 0.669 $\\pm$ 0.06 & 0.668 $\\pm$ 0.053 & 0.668 $\\pm$ 0.05 \\\\\n",
      "Letter & Lore (Genetic) & 0.521 $\\pm$ 0.126 & - & 0.516 $\\pm$ 0.074 & 0.517 $\\pm$ 0.065 & 0.517 $\\pm$ 0.059 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.913 $\\pm$ 0.19 & - & 0.781 $\\pm$ 0.181 & 0.772 $\\pm$ 0.174 & 0.76 $\\pm$ 0.171 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.809 $\\pm$ 0.278 & 0.261 $\\pm$ 0.615 & 0.436 $\\pm$ 0.155 & 0.423 $\\pm$ 0.141 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 0.839 $\\pm$ 0.26 & 0.049 $\\pm$ 0.659 & 0.507 $\\pm$ 0.185 & 0.487 $\\pm$ 0.166 & 0.466 $\\pm$ 0.155 \\\\\n",
      "Shuttle & LIME & 0.276 $\\pm$ 0.17 & 0.024 $\\pm$ 0.653 & 0.235 $\\pm$ 0.103 & 0.232 $\\pm$ 0.091 & 0.228 $\\pm$ 0.083 \\\\\n",
      "Shuttle & SHAP & 1.0 $\\pm$ 0.008 & 0.57 $\\pm$ 0.551 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.755 $\\pm$ 0.172 & - & 0.627 $\\pm$ 0.096 & 0.627 $\\pm$ 0.082 & 0.627 $\\pm$ 0.075 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.626 $\\pm$ 0.135 & - & 0.621 $\\pm$ 0.072 & 0.621 $\\pm$ 0.06 & 0.621 $\\pm$ 0.052 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_metrics_complete[df_metrics_complete[\"Neighborhood Size\"] == 1000].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Stability & Faithfulness & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.898 $\\pm$ 0.167 & - & 0.586 $\\pm$ 0.126 & 0.575 $\\pm$ 0.111 & 0.564 $\\pm$ 0.102 \\\\\n",
      "Adult & \\fire (SVM) & 0.859 $\\pm$ 0.258 & 0.01 $\\pm$ 0.112 & 0.296 $\\pm$ 0.107 & 0.292 $\\pm$ 0.099 & 0.288 $\\pm$ 0.093 \\\\\n",
      "Adult & \\fire (LR) & 0.5 $\\pm$ 0.28 & 0.012 $\\pm$ 0.212 & 0.274 $\\pm$ 0.133 & 0.27 $\\pm$ 0.122 & 0.265 $\\pm$ 0.114 \\\\\n",
      "Adult & LIME & 0.046 $\\pm$ 0.018 & 0.064 $\\pm$ 0.18 & 0.046 $\\pm$ 0.009 & 0.046 $\\pm$ 0.006 & 0.046 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 0.406 $\\pm$ 0.196 & 0.515 $\\pm$ 0.16 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 0.469 $\\pm$ 0.154 & - & 0.235 $\\pm$ 0.104 & 0.235 $\\pm$ 0.088 & 0.235 $\\pm$ 0.077 \\\\\n",
      "Adult & Lore (Genetic) & 0.301 $\\pm$ 0.235 & - & 0.299 $\\pm$ 0.143 & 0.299 $\\pm$ 0.127 & 0.299 $\\pm$ 0.118 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.925 $\\pm$ 0.133 & - & 0.598 $\\pm$ 0.113 & 0.584 $\\pm$ 0.101 & 0.57 $\\pm$ 0.093 \\\\\n",
      "Covertype & \\fire (SVM) & 0.554 $\\pm$ 0.369 & -0.025 $\\pm$ 0.216 & 0.176 $\\pm$ 0.074 & 0.171 $\\pm$ 0.063 & 0.165 $\\pm$ 0.056 \\\\\n",
      "Covertype & \\fire (LR) & 0.946 $\\pm$ 0.188 & -0.069 $\\pm$ 0.308 & 0.243 $\\pm$ 0.122 & 0.233 $\\pm$ 0.109 & 0.221 $\\pm$ 0.099 \\\\\n",
      "Covertype & LIME & 0.603 $\\pm$ 0.043 & -0.099 $\\pm$ 0.278 & 0.598 $\\pm$ 0.023 & 0.597 $\\pm$ 0.019 & 0.596 $\\pm$ 0.017 \\\\\n",
      "Covertype & SHAP & 0.182 $\\pm$ 0.067 & 0.519 $\\pm$ 0.313 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.68 $\\pm$ 0.116 & - & 0.388 $\\pm$ 0.065 & 0.388 $\\pm$ 0.056 & 0.388 $\\pm$ 0.05 \\\\\n",
      "Covertype & Lore (Genetic) & 0.4 $\\pm$ 0.125 & - & 0.388 $\\pm$ 0.072 & 0.388 $\\pm$ 0.062 & 0.388 $\\pm$ 0.058 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.967 $\\pm$ 0.099 & - & 0.903 $\\pm$ 0.144 & 0.876 $\\pm$ 0.149 & 0.845 $\\pm$ 0.151 \\\\\n",
      "Dutch & \\fire (SVM) & 0.799 $\\pm$ 0.272 & 0.054 $\\pm$ 0.284 & 0.697 $\\pm$ 0.278 & 0.615 $\\pm$ 0.26 & 0.525 $\\pm$ 0.218 \\\\\n",
      "Dutch & \\fire (LR) & 0.81 $\\pm$ 0.268 & 0.053 $\\pm$ 0.298 & 0.728 $\\pm$ 0.266 & 0.654 $\\pm$ 0.254 & 0.575 $\\pm$ 0.226 \\\\\n",
      "Dutch & LIME & 0.404 $\\pm$ 0.146 & 0.06 $\\pm$ 0.257 & 0.394 $\\pm$ 0.091 & 0.387 $\\pm$ 0.082 & 0.378 $\\pm$ 0.078 \\\\\n",
      "Dutch & SHAP & 1.0 $\\pm$ 0.0 & 0.461 $\\pm$ 0.358 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.771 $\\pm$ 0.224 & - & 0.561 $\\pm$ 0.134 & 0.56 $\\pm$ 0.118 & 0.561 $\\pm$ 0.108 \\\\\n",
      "Dutch & Lore (Genetic) & 0.692 $\\pm$ 0.131 & - & 0.667 $\\pm$ 0.082 & 0.668 $\\pm$ 0.074 & 0.668 $\\pm$ 0.069 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.91 $\\pm$ 0.134 & - & 0.66 $\\pm$ 0.09 & 0.656 $\\pm$ 0.082 & 0.65 $\\pm$ 0.079 \\\\\n",
      "House 16 & \\fire (SVM) & 0.557 $\\pm$ 0.396 & 0.023 $\\pm$ 0.215 & 0.246 $\\pm$ 0.135 & 0.24 $\\pm$ 0.126 & 0.232 $\\pm$ 0.118 \\\\\n",
      "House 16 & \\fire (LR) & 0.788 $\\pm$ 0.204 & -0.141 $\\pm$ 0.261 & 0.536 $\\pm$ 0.132 & 0.522 $\\pm$ 0.12 & 0.504 $\\pm$ 0.113 \\\\\n",
      "House 16 & LIME & 0.534 $\\pm$ 0.124 & 0.071 $\\pm$ 0.257 & 0.463 $\\pm$ 0.058 & 0.46 $\\pm$ 0.044 & 0.458 $\\pm$ 0.035 \\\\\n",
      "House 16 & SHAP & 0.746 $\\pm$ 0.146 & 0.319 $\\pm$ 0.384 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.731 $\\pm$ 0.15 & - & 0.5 $\\pm$ 0.105 & 0.5 $\\pm$ 0.09 & 0.5 $\\pm$ 0.08 \\\\\n",
      "House 16 & Lore (Genetic) & 0.443 $\\pm$ 0.16 & - & 0.439 $\\pm$ 0.084 & 0.438 $\\pm$ 0.068 & 0.438 $\\pm$ 0.059 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.963 $\\pm$ 0.091 & - & 0.63 $\\pm$ 0.105 & 0.617 $\\pm$ 0.096 & 0.601 $\\pm$ 0.087 \\\\\n",
      "Letter & \\fire (SVM) & 0.86 $\\pm$ 0.297 & 0.044 $\\pm$ 0.208 & 0.135 $\\pm$ 0.093 & 0.122 $\\pm$ 0.066 & 0.111 $\\pm$ 0.049 \\\\\n",
      "Letter & \\fire (LR) & 0.87 $\\pm$ 0.249 & 0.021 $\\pm$ 0.189 & 0.177 $\\pm$ 0.106 & 0.16 $\\pm$ 0.082 & 0.143 $\\pm$ 0.067 \\\\\n",
      "Letter & LIME & 0.195 $\\pm$ 0.1 & 0.035 $\\pm$ 0.204 & 0.163 $\\pm$ 0.062 & 0.157 $\\pm$ 0.055 & 0.151 $\\pm$ 0.049 \\\\\n",
      "Letter & SHAP & 0.522 $\\pm$ 0.153 & 0.567 $\\pm$ 0.223 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.864 $\\pm$ 0.067 & - & 0.746 $\\pm$ 0.051 & 0.746 $\\pm$ 0.045 & 0.745 $\\pm$ 0.042 \\\\\n",
      "Letter & Lore (Genetic) & 0.58 $\\pm$ 0.11 & - & 0.574 $\\pm$ 0.064 & 0.575 $\\pm$ 0.056 & 0.575 $\\pm$ 0.051 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.925 $\\pm$ 0.151 & - & 0.756 $\\pm$ 0.154 & 0.747 $\\pm$ 0.144 & 0.737 $\\pm$ 0.14 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.805 $\\pm$ 0.283 & 0.262 $\\pm$ 0.616 & 0.435 $\\pm$ 0.156 & 0.423 $\\pm$ 0.142 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 0.835 $\\pm$ 0.262 & 0.054 $\\pm$ 0.657 & 0.51 $\\pm$ 0.185 & 0.49 $\\pm$ 0.167 & 0.468 $\\pm$ 0.155 \\\\\n",
      "Shuttle & LIME & 0.37 $\\pm$ 0.193 & -0.004 $\\pm$ 0.663 & 0.294 $\\pm$ 0.131 & 0.288 $\\pm$ 0.119 & 0.281 $\\pm$ 0.112 \\\\\n",
      "Shuttle & SHAP & 1.0 $\\pm$ 0.008 & 0.57 $\\pm$ 0.551 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.834 $\\pm$ 0.141 & - & 0.708 $\\pm$ 0.084 & 0.707 $\\pm$ 0.072 & 0.707 $\\pm$ 0.066 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.674 $\\pm$ 0.125 & - & 0.663 $\\pm$ 0.074 & 0.663 $\\pm$ 0.064 & 0.663 $\\pm$ 0.058 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_metrics_complete[df_metrics_complete[\"Neighborhood Size\"] == 2500].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Stability & Faithfulness & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.92 $\\pm$ 0.148 & - & 0.609 $\\pm$ 0.121 & 0.6 $\\pm$ 0.106 & 0.59 $\\pm$ 0.097 \\\\\n",
      "Adult & \\fire (SVM) & 0.727 $\\pm$ 0.34 & 0.012 $\\pm$ 0.122 & 0.242 $\\pm$ 0.103 & 0.24 $\\pm$ 0.094 & 0.238 $\\pm$ 0.088 \\\\\n",
      "Adult & \\fire (LR) & 0.469 $\\pm$ 0.224 & 0.003 $\\pm$ 0.211 & 0.247 $\\pm$ 0.092 & 0.244 $\\pm$ 0.081 & 0.24 $\\pm$ 0.075 \\\\\n",
      "Adult & LIME & 0.055 $\\pm$ 0.02 & 0.064 $\\pm$ 0.177 & 0.054 $\\pm$ 0.009 & 0.054 $\\pm$ 0.007 & 0.054 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 0.406 $\\pm$ 0.196 & 0.515 $\\pm$ 0.16 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 0.339 $\\pm$ 0.223 & - & 0.342 $\\pm$ 0.137 & 0.341 $\\pm$ 0.122 & 0.341 $\\pm$ 0.113 \\\\\n",
      "Adult & Lore (Genetic) & 0.546 $\\pm$ 0.175 & - & 0.251 $\\pm$ 0.103 & 0.251 $\\pm$ 0.083 & 0.252 $\\pm$ 0.071 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.94 $\\pm$ 0.114 & - & 0.618 $\\pm$ 0.115 & 0.602 $\\pm$ 0.104 & 0.588 $\\pm$ 0.096 \\\\\n",
      "Covertype & \\fire (SVM) & 0.547 $\\pm$ 0.381 & -0.023 $\\pm$ 0.195 & 0.167 $\\pm$ 0.067 & 0.164 $\\pm$ 0.057 & 0.159 $\\pm$ 0.051 \\\\\n",
      "Covertype & \\fire (LR) & 0.944 $\\pm$ 0.19 & -0.071 $\\pm$ 0.297 & 0.244 $\\pm$ 0.112 & 0.235 $\\pm$ 0.098 & 0.224 $\\pm$ 0.089 \\\\\n",
      "Covertype & LIME & 0.612 $\\pm$ 0.046 & -0.109 $\\pm$ 0.281 & 0.605 $\\pm$ 0.024 & 0.604 $\\pm$ 0.02 & 0.603 $\\pm$ 0.017 \\\\\n",
      "Covertype & SHAP & 0.182 $\\pm$ 0.067 & 0.519 $\\pm$ 0.313 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.425 $\\pm$ 0.119 & - & 0.409 $\\pm$ 0.071 & 0.409 $\\pm$ 0.062 & 0.409 $\\pm$ 0.057 \\\\\n",
      "Covertype & Lore (Genetic) & 0.742 $\\pm$ 0.105 & - & 0.44 $\\pm$ 0.067 & 0.441 $\\pm$ 0.058 & 0.44 $\\pm$ 0.053 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.955 $\\pm$ 0.113 & - & 0.901 $\\pm$ 0.141 & 0.874 $\\pm$ 0.144 & 0.842 $\\pm$ 0.144 \\\\\n",
      "Dutch & \\fire (SVM) & 0.806 $\\pm$ 0.263 & 0.056 $\\pm$ 0.272 & 0.736 $\\pm$ 0.25 & 0.664 $\\pm$ 0.235 & 0.587 $\\pm$ 0.203 \\\\\n",
      "Dutch & \\fire (LR) & 0.827 $\\pm$ 0.25 & 0.061 $\\pm$ 0.286 & 0.757 $\\pm$ 0.236 & 0.691 $\\pm$ 0.223 & 0.619 $\\pm$ 0.197 \\\\\n",
      "Dutch & LIME & 0.478 $\\pm$ 0.164 & 0.06 $\\pm$ 0.256 & 0.461 $\\pm$ 0.108 & 0.454 $\\pm$ 0.098 & 0.443 $\\pm$ 0.094 \\\\\n",
      "Dutch & SHAP & 1.0 $\\pm$ 0.0 & 0.461 $\\pm$ 0.358 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.713 $\\pm$ 0.123 & - & 0.682 $\\pm$ 0.077 & 0.682 $\\pm$ 0.068 & 0.682 $\\pm$ 0.063 \\\\\n",
      "Dutch & Lore (Genetic) & 0.808 $\\pm$ 0.197 & - & 0.598 $\\pm$ 0.123 & 0.598 $\\pm$ 0.107 & 0.598 $\\pm$ 0.1 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.93 $\\pm$ 0.117 & - & 0.687 $\\pm$ 0.089 & 0.683 $\\pm$ 0.082 & 0.679 $\\pm$ 0.079 \\\\\n",
      "House 16 & \\fire (SVM) & 0.525 $\\pm$ 0.398 & 0.023 $\\pm$ 0.215 & 0.229 $\\pm$ 0.119 & 0.224 $\\pm$ 0.108 & 0.217 $\\pm$ 0.101 \\\\\n",
      "House 16 & \\fire (LR) & 0.749 $\\pm$ 0.209 & -0.133 $\\pm$ 0.268 & 0.526 $\\pm$ 0.129 & 0.512 $\\pm$ 0.12 & 0.497 $\\pm$ 0.115 \\\\\n",
      "House 16 & LIME & 0.579 $\\pm$ 0.128 & 0.077 $\\pm$ 0.255 & 0.47 $\\pm$ 0.06 & 0.467 $\\pm$ 0.045 & 0.464 $\\pm$ 0.036 \\\\\n",
      "House 16 & SHAP & 0.746 $\\pm$ 0.146 & 0.319 $\\pm$ 0.384 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.513 $\\pm$ 0.147 & - & 0.51 $\\pm$ 0.084 & 0.51 $\\pm$ 0.072 & 0.51 $\\pm$ 0.065 \\\\\n",
      "House 16 & Lore (Genetic) & 0.772 $\\pm$ 0.144 & - & 0.553 $\\pm$ 0.1 & 0.553 $\\pm$ 0.085 & 0.553 $\\pm$ 0.077 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.977 $\\pm$ 0.071 & - & 0.666 $\\pm$ 0.101 & 0.655 $\\pm$ 0.092 & 0.64 $\\pm$ 0.084 \\\\\n",
      "Letter & \\fire (SVM) & 0.887 $\\pm$ 0.272 & 0.047 $\\pm$ 0.203 & 0.146 $\\pm$ 0.091 & 0.133 $\\pm$ 0.065 & 0.121 $\\pm$ 0.05 \\\\\n",
      "Letter & \\fire (LR) & 0.919 $\\pm$ 0.198 & 0.026 $\\pm$ 0.194 & 0.192 $\\pm$ 0.113 & 0.174 $\\pm$ 0.091 & 0.156 $\\pm$ 0.075 \\\\\n",
      "Letter & LIME & 0.232 $\\pm$ 0.107 & 0.041 $\\pm$ 0.201 & 0.186 $\\pm$ 0.071 & 0.179 $\\pm$ 0.064 & 0.169 $\\pm$ 0.057 \\\\\n",
      "Letter & SHAP & 0.522 $\\pm$ 0.153 & 0.567 $\\pm$ 0.223 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.619 $\\pm$ 0.1 & - & 0.61 $\\pm$ 0.058 & 0.609 $\\pm$ 0.051 & 0.609 $\\pm$ 0.046 \\\\\n",
      "Letter & Lore (Genetic) & 0.9 $\\pm$ 0.059 & - & 0.773 $\\pm$ 0.047 & 0.773 $\\pm$ 0.041 & 0.773 $\\pm$ 0.038 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.926 $\\pm$ 0.151 & - & 0.739 $\\pm$ 0.147 & 0.731 $\\pm$ 0.136 & 0.721 $\\pm$ 0.129 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.806 $\\pm$ 0.282 & 0.268 $\\pm$ 0.612 & 0.433 $\\pm$ 0.154 & 0.421 $\\pm$ 0.141 & 0.408 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 0.841 $\\pm$ 0.258 & 0.05 $\\pm$ 0.658 & 0.506 $\\pm$ 0.184 & 0.487 $\\pm$ 0.167 & 0.466 $\\pm$ 0.156 \\\\\n",
      "Shuttle & LIME & 0.423 $\\pm$ 0.195 & 0.01 $\\pm$ 0.668 & 0.328 $\\pm$ 0.144 & 0.32 $\\pm$ 0.132 & 0.312 $\\pm$ 0.125 \\\\\n",
      "Shuttle & SHAP & 1.0 $\\pm$ 0.008 & 0.57 $\\pm$ 0.551 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.713 $\\pm$ 0.115 & - & 0.7 $\\pm$ 0.073 & 0.7 $\\pm$ 0.065 & 0.7 $\\pm$ 0.06 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.868 $\\pm$ 0.117 & - & 0.751 $\\pm$ 0.079 & 0.75 $\\pm$ 0.069 & 0.75 $\\pm$ 0.064 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_metrics_complete[df_metrics_complete[\"Neighborhood Size\"] == 5000].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000, 2500, 5000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_complete[\"Neighborhood Size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.append(df_metrics_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>-</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>-</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.834 $\\pm$ 0.141</td>\n",
       "      <td>-</td>\n",
       "      <td>0.708 $\\pm$ 0.084</td>\n",
       "      <td>0.707 $\\pm$ 0.072</td>\n",
       "      <td>0.707 $\\pm$ 0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.713 $\\pm$ 0.115</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7 $\\pm$ 0.073</td>\n",
       "      <td>0.7 $\\pm$ 0.065</td>\n",
       "      <td>0.7 $\\pm$ 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>1000</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.626 $\\pm$ 0.135</td>\n",
       "      <td>-</td>\n",
       "      <td>0.621 $\\pm$ 0.072</td>\n",
       "      <td>0.621 $\\pm$ 0.06</td>\n",
       "      <td>0.621 $\\pm$ 0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.674 $\\pm$ 0.125</td>\n",
       "      <td>-</td>\n",
       "      <td>0.663 $\\pm$ 0.074</td>\n",
       "      <td>0.663 $\\pm$ 0.064</td>\n",
       "      <td>0.663 $\\pm$ 0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.868 $\\pm$ 0.117</td>\n",
       "      <td>-</td>\n",
       "      <td>0.751 $\\pm$ 0.079</td>\n",
       "      <td>0.75 $\\pm$ 0.069</td>\n",
       "      <td>0.75 $\\pm$ 0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Neighborhood Size          Method          Stability  \\\n",
       "63    Adult               1000      \\fire (DT)   0.845 $\\pm$ 0.23   \n",
       "64    Adult               2500      \\fire (DT)  0.898 $\\pm$ 0.167   \n",
       "65    Adult               5000      \\fire (DT)   0.92 $\\pm$ 0.148   \n",
       "66    Adult               1000     \\fire (SVM)  0.861 $\\pm$ 0.267   \n",
       "67    Adult               2500     \\fire (SVM)  0.859 $\\pm$ 0.258   \n",
       "..      ...                ...             ...                ...   \n",
       "58  Shuttle               2500   Lore (Random)  0.834 $\\pm$ 0.141   \n",
       "59  Shuttle               5000   Lore (Random)  0.713 $\\pm$ 0.115   \n",
       "60  Shuttle               1000  Lore (Genetic)  0.626 $\\pm$ 0.135   \n",
       "61  Shuttle               2500  Lore (Genetic)  0.674 $\\pm$ 0.125   \n",
       "62  Shuttle               5000  Lore (Genetic)  0.868 $\\pm$ 0.117   \n",
       "\n",
       "         Faithfulness     Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "63                  -  0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "64                  -  0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "65                  -  0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "66  0.019 $\\pm$ 0.117  0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084  0.257 $\\pm$ 0.081  \n",
       "67   0.01 $\\pm$ 0.112  0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "..                ...                ...                ...                ...  \n",
       "58                  -  0.708 $\\pm$ 0.084  0.707 $\\pm$ 0.072  0.707 $\\pm$ 0.066  \n",
       "59                  -    0.7 $\\pm$ 0.073    0.7 $\\pm$ 0.065     0.7 $\\pm$ 0.06  \n",
       "60                  -  0.621 $\\pm$ 0.072   0.621 $\\pm$ 0.06  0.621 $\\pm$ 0.052  \n",
       "61                  -  0.663 $\\pm$ 0.074  0.663 $\\pm$ 0.064  0.663 $\\pm$ 0.058  \n",
       "62                  -  0.751 $\\pm$ 0.079   0.75 $\\pm$ 0.069   0.75 $\\pm$ 0.064  \n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "\n",
    "# def plot_robustness_per_dataset(df_metrics):\n",
    "#     # Create the plots directory if it doesn't exist\n",
    "#     os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "#     # Get the unique datasets and define top_k values\n",
    "#     datasets = df_metrics['Dataset'].unique()\n",
    "#     top_k = [3, 5, 8, 10, 20]\n",
    "    \n",
    "#     # Define a color-blind-friendly palette and markers\n",
    "#     colors = [\"#FF774E\", \"#7c7787\", \"#53C4FE\", \"#70DDA8\", \"#dc68e4\", \"#755c51\", \"gray\"]\n",
    "#     edge_colors = [\"#E45D22\", \"#5a5255\", \"#009EFF\", \"#00B977\", \"fuchsia\", \"#ae5a41\", \"black\"]\n",
    "#     markers = ['o', 'd', 'v', 'h', 's', 'P', 'p']\n",
    "# #     'D', '^', 'v', 'P', '*', 'X', 'p', 'h']  # Different markers\n",
    "    \n",
    "#     # Create a single figure with subplots\n",
    "#     fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 15), sharex=True, sharey=True)\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     handles, labels = [], []\n",
    "    \n",
    "#     for idx, dataset in enumerate(datasets):\n",
    "#         ax = axes[idx]\n",
    "#         subset = df_metrics[df_metrics['Dataset'] == dataset]\n",
    "        \n",
    "#         for i, method in enumerate(subset['Method'].unique()):\n",
    "#             method_subset = subset[subset['Method'] == method]\n",
    "#             robustness_values = []\n",
    "            \n",
    "#             for k in top_k:\n",
    "#                 value = method_subset[f'Robustness K={k}'].values[0]\n",
    "#                 robustness_value = float(str(value).split(' ')[0])  # Ensure extraction is robust\n",
    "#                 robustness_values.append(robustness_value)\n",
    "            \n",
    "#             line, = ax.plot(top_k, \n",
    "#                             robustness_values,\n",
    "#                             marker=markers[i % len(markers)],\n",
    "#                             markersize=20, \n",
    "#                             linewidth=3, \n",
    "#                             linestyle=\"--\",\n",
    "#                             color=colors[i % len(colors)],\n",
    "#                             markerfacecolor=colors[i % len(colors)], \n",
    "#                             markeredgecolor=edge_colors[i % len(colors)], \n",
    "#                             markeredgewidth=2,\n",
    "#                             alpha=0.8, zorder=3)\n",
    "#             if idx == 0:  # Collect legend elements only once\n",
    "#                 handles.append(line)\n",
    "#                 labels.append(method)\n",
    "        \n",
    "#         ax.set_title(f'{dataset}', fontsize=25, fontweight='bold')\n",
    "#         ax.set_xlabel('K', fontsize=25)\n",
    "#         ax.set_ylabel('Robustness', fontsize=25)\n",
    "#         ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "#         ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "#     # Adjust layout\n",
    "#     plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "    \n",
    "#     # Add external legend below plots\n",
    "#     fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.02), ncol=3, fontsize=20, frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "#     # Save the plot\n",
    "#     plt.savefig('plots/robustness_all_datasets.png', bbox_inches='tight', dpi=300)\n",
    "#     plt.close()\n",
    "\n",
    "# # Call the function with df_metrics_complete\n",
    "# plot_robustness_per_dataset(df_metrics_complete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = download_runs(project_name=\"tango_eval\")\n",
    "project_name = \"tango_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data_comparison = download_runs(project_name=\"comparison_tango\")\n",
    "project_name = \"comparison_tango\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"dt\", \"svm\", \"logistic\"]\n",
    "datasets = [\"house16\", \"letter\", \"dutch\", \"adult\", \"covertype\", \"shuttle\"]\n",
    "neigh_sizes = [1000, 2500, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1303545/1842178429.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_list.append(float(result[\"Fidelity\"]))\n",
      "/tmp/ipykernel_1303545/1842178429.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_method_list.append(float(result[\"Tree Accuracy\"]))\n",
      "/tmp/ipykernel_1303545/1842178429.py:19: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_method_std_list.append(float(result[\"Tree Accuracy Std\"]))\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}   \n",
    "    for method in methods: \n",
    "        metrics[dataset][method] = {}\n",
    "        for neigh_size in neigh_sizes:\n",
    "            metrics[dataset][method][neigh_size] = {}\n",
    "            results = project_data[f\"{method}_{dataset}\"]\n",
    "            fidelity_list = []\n",
    "            fidelity_method_std_list = []\n",
    "            fidelity_method_list = []\n",
    "            for result in results:\n",
    "                if \"top_k\" in result and result[\"top_k\"][0] == neigh_size:\n",
    "                    if \"Fidelity\" in result.columns:\n",
    "                        fidelity_list.append(float(result[\"Fidelity\"]))\n",
    "                    if \"Tree Accuracy\" in result.columns:\n",
    "                        fidelity_method_list.append(float(result[\"Tree Accuracy\"]))\n",
    "                        fidelity_method_std_list.append(float(result[\"Tree Accuracy Std\"]))\n",
    "            if len(fidelity_list) > 0:\n",
    "                fidelity = round(np.mean(fidelity_list), 3)\n",
    "                metrics[dataset][method][neigh_size][\"Fidelity\"] = fidelity\n",
    "\n",
    "            if len(fidelity_method_list) > 0:\n",
    "                fidelity_method = round(np.mean(fidelity_method_list), 3)\n",
    "                fidelity_method_std = round(np.mean(fidelity_method_std_list), 3)\n",
    "                metrics[dataset][method][neigh_size][\"Fidelity_neigh\"] = f\"{fidelity_method} $\\pm$ {fidelity_method_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': {1000: {'Fidelity': 0.899, 'Fidelity_neigh': '0.864 $\\\\pm$ 0.043'},\n",
       "  2500: {'Fidelity': 0.9, 'Fidelity_neigh': '0.876 $\\\\pm$ 0.031'},\n",
       "  5000: {'Fidelity': 0.908, 'Fidelity_neigh': '0.886 $\\\\pm$ 0.028'}},\n",
       " 'svm': {1000: {'Fidelity': 0.745, 'Fidelity_neigh': '0.631 $\\\\pm$ 0.12'},\n",
       "  2500: {'Fidelity': 0.711, 'Fidelity_neigh': '0.61 $\\\\pm$ 0.126'},\n",
       "  5000: {'Fidelity': 0.678, 'Fidelity_neigh': '0.608 $\\\\pm$ 0.135'}},\n",
       " 'logistic': {1000: {'Fidelity': 0.962,\n",
       "   'Fidelity_neigh': '0.947 $\\\\pm$ 0.026'},\n",
       "  2500: {'Fidelity': 0.939, 'Fidelity_neigh': '0.916 $\\\\pm$ 0.021'},\n",
       "  5000: {'Fidelity': 0.936, 'Fidelity_neigh': '0.916 $\\\\pm$ 0.019'}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"house16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for neigh_size in neigh_sizes:\n",
    "            row = {\n",
    "                'Dataset': dataset,\n",
    "                \"Neighborhood Size\": neigh_size,\n",
    "                'Method': method,\n",
    "                'Fidelity': metrics[dataset][method][neigh_size].get('Fidelity', '-'),\n",
    "                'Fid. Neigh.': metrics[dataset][method][neigh_size].get('Fidelity_neigh', '-'),\n",
    "            }\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"lime\", \"lore\", \"lore_genetic\"]\n",
    "datasets = [\"house16\", \"letter\", \"dutch\", \"adult\", \"covertype\", \"shuttle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1303545/2945851877.py:15: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_list.append(float(result[\"fidelity\"]))\n",
      "/tmp/ipykernel_1303545/2945851877.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_neigh_list.append(float(result[\"fidelity_method\"]))\n",
      "/tmp/ipykernel_1303545/2945851877.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_neigh_std_list.append(float(result[\"fidelity_method_std\"]))\n",
      "/tmp/ipykernel_1303545/2945851877.py:23: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_list.append(float(result[\"fidelity\"]))\n",
      "/tmp/ipykernel_1303545/2945851877.py:24: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_neigh_list.append(float(result[\"fidelity_method\"]))\n",
      "/tmp/ipykernel_1303545/2945851877.py:25: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  fidelity_neigh_std_list.append(float(result[\"fidelity_method_std\"]))\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}\n",
    "    for method in methods:\n",
    "        metrics[dataset][method] = {}\n",
    "        for neigh_size in neigh_sizes:\n",
    "            metrics[dataset][method][neigh_size] = {}\n",
    "            results = project_data_comparison[f\"{method}_{dataset}\"]\n",
    "            fidelity_list = []\n",
    "            fidelity_neigh_list = []\n",
    "            fidelity_neigh_std_list = []\n",
    "            for result in results:\n",
    "                if \"neigh_size\" in result and result[\"neigh_size\"][0] == neigh_size:\n",
    "                    if \"fidelity\" in result.columns :\n",
    "                        fidelity_list.append(float(result[\"fidelity\"])) \n",
    "                        fidelity_neigh_list.append(float(result[\"fidelity_method\"]))\n",
    "                        fidelity_neigh_std_list.append(float(result[\"fidelity_method_std\"]))\n",
    "                elif \"neigh_size\" not in result and neigh_size == 5000:\n",
    "                    \n",
    "                    if \"fidelity\" in result.columns and \"fidelity_method\" in result.columns:\n",
    "                        if isinstance(result[\"fidelity_method\"][0], np.float64) or isinstance(result[\"fidelity_method\"][0], np.int64) or isinstance(result[\"fidelity_method\"][0], np.float32):\n",
    "                            metrics[dataset][method][neigh_size] = {}\n",
    "                            fidelity_list.append(float(result[\"fidelity\"])) \n",
    "                            fidelity_neigh_list.append(float(result[\"fidelity_method\"]))\n",
    "                            fidelity_neigh_std_list.append(float(result[\"fidelity_method_std\"]))\n",
    "\n",
    "            if len(fidelity_list) > 0:\n",
    "                fidelity = round(np.mean(fidelity_list), 3)\n",
    "                metrics[dataset][method][neigh_size][\"Fidelity\"] = f\"{fidelity}\"\n",
    "            if len(fidelity_neigh_list) > 0:\n",
    "                fid_neigh = round(np.mean(fidelity_neigh_list), 3)\n",
    "                std = round(np.mean(fidelity_neigh_std_list), 3)\n",
    "                metrics[dataset][method][neigh_size][\"Fidelity_neigh\"] = f\"{fid_neigh} $\\pm$ {std}\"\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: {'Fidelity': '0.039', 'Fidelity_neigh': '1.0 $\\\\pm$ 0.0'},\n",
       " 2500: {'Fidelity': '0.04', 'Fidelity_neigh': '1.0 $\\\\pm$ 0.0'},\n",
       " 5000: {}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"letter\"][\"lore_genetic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for n in neigh_sizes:\n",
    "            row = {\n",
    "                'Dataset': dataset,\n",
    "                'Neighborhood Size': n,\n",
    "                'Method': method,\n",
    "                'Fidelity': metrics[dataset][method][n].get('Fidelity', '-'),\n",
    "                'Fid. Neigh.': metrics[dataset][method][neigh_size].get('Fidelity_neigh', '-'),\n",
    "            }\n",
    "            rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.918 $\\pm$ 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.931 $\\pm$ 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.514 $\\pm$ 0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.518 $\\pm$ 0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.969 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.974 $\\pm$ 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98 $\\pm$ 0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Neighborhood Size       Method Fidelity        Fid. Neigh.\n",
       "27   Adult               1000   \\fire (DT)    0.907   0.918 $\\pm$ 0.04\n",
       "28   Adult               2500   \\fire (DT)    0.897  0.931 $\\pm$ 0.037\n",
       "29   Adult               5000   \\fire (DT)    0.897   0.94 $\\pm$ 0.032\n",
       "30   Adult               1000  \\fire (SVM)    0.522  0.514 $\\pm$ 0.175\n",
       "31   Adult               2500  \\fire (SVM)        -                  -\n",
       "32   Adult               5000  \\fire (SVM)    0.529  0.518 $\\pm$ 0.177\n",
       "33   Adult               1000   \\fire (LR)    0.895  0.969 $\\pm$ 0.019\n",
       "34   Adult               2500   \\fire (LR)    0.846  0.974 $\\pm$ 0.014\n",
       "35   Adult               5000   \\fire (LR)      0.9    0.98 $\\pm$ 0.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "df_metrics.head(10)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': r'\\fire (DT)',\n",
    "    'svm': r'\\fire (SVM)',\n",
    "    'logistic': r'\\fire (LR)',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Method\"] = df_metrics[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    r'\\fire (DT)': 1, \n",
    "    r'\\fire (SVM)': 2, \n",
    "    r'\\fire (LR)': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics['method_order'] = df_metrics['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics = df_metrics.drop(columns=['method_order'])\n",
    "\n",
    "df_metrics.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>House 16</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>House 16</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>House 16</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Letter</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Letter</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  Neighborhood Size Method Fidelity        Fid. Neigh.\n",
       "81       Adult               1000   LIME    0.908  0.729 $\\pm$ 0.017\n",
       "82       Adult               2500   LIME    0.903  0.729 $\\pm$ 0.017\n",
       "83       Adult               5000   LIME    0.926  0.729 $\\pm$ 0.017\n",
       "90   Covertype               1000   LIME    0.714  0.261 $\\pm$ 0.107\n",
       "91   Covertype               2500   LIME    0.712  0.261 $\\pm$ 0.107\n",
       "92   Covertype               5000   LIME    0.709  0.261 $\\pm$ 0.107\n",
       "72       Dutch               1000   LIME    0.893  0.516 $\\pm$ 0.193\n",
       "73       Dutch               2500   LIME    0.896  0.516 $\\pm$ 0.193\n",
       "74       Dutch               5000   LIME    0.896  0.516 $\\pm$ 0.193\n",
       "54    House 16               1000   LIME    0.882  0.245 $\\pm$ 0.145\n",
       "55    House 16               2500   LIME    0.875  0.245 $\\pm$ 0.145\n",
       "56    House 16               5000   LIME    0.872  0.245 $\\pm$ 0.145\n",
       "63      Letter               1000   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "64      Letter               2500   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "65      Letter               5000   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "99     Shuttle               1000   LIME    0.801  0.078 $\\pm$ 0.047\n",
       "100    Shuttle               2500   LIME    0.801  0.078 $\\pm$ 0.047\n",
       "101    Shuttle               5000   LIME    0.801  0.078 $\\pm$ 0.047"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics[df_metrics[\"Method\"] == \"LIME\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df_metrics by dataset name\n",
    "\n",
    "# remove index \n",
    "df_metrics = df_metrics.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.append(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Dataset & Method & Fidelity & Fid. Neigh. \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.897000 & 0.94 $\\pm$ 0.032 \\\\\n",
      "Adult & \\fire (SVM) & 0.529000 & 0.518 $\\pm$ 0.177 \\\\\n",
      "Adult & \\fire (LR) & 0.900000 & 0.98 $\\pm$ 0.01 \\\\\n",
      "Adult & LIME & 0.926 & 0.729 $\\pm$ 0.017 \\\\\n",
      "Adult & Lore (Random) & 0.652 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Adult & Lore (Genetic) & - & - \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.842000 & 0.854 $\\pm$ 0.028 \\\\\n",
      "Covertype & \\fire (SVM) & 0.562000 & 0.525 $\\pm$ 0.096 \\\\\n",
      "Covertype & \\fire (LR) & 0.854000 & 0.865 $\\pm$ 0.029 \\\\\n",
      "Covertype & LIME & 0.709 & 0.261 $\\pm$ 0.107 \\\\\n",
      "Covertype & Lore (Random) & 0.377 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Covertype & Lore (Genetic) & - & - \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.996000 & 0.997 $\\pm$ 0.003 \\\\\n",
      "Dutch & \\fire (SVM) & 0.989000 & 0.985 $\\pm$ 0.02 \\\\\n",
      "Dutch & \\fire (LR) & 0.992000 & 0.988 $\\pm$ 0.012 \\\\\n",
      "Dutch & LIME & 0.896 & 0.516 $\\pm$ 0.193 \\\\\n",
      "Dutch & Lore (Random) & 0.501 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Dutch & Lore (Genetic) & - & - \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.908000 & 0.886 $\\pm$ 0.028 \\\\\n",
      "House 16 & \\fire (SVM) & 0.678000 & 0.608 $\\pm$ 0.135 \\\\\n",
      "House 16 & \\fire (LR) & 0.936000 & 0.916 $\\pm$ 0.019 \\\\\n",
      "House 16 & LIME & 0.872 & 0.245 $\\pm$ 0.145 \\\\\n",
      "House 16 & Lore (Random) & 0.57 & 1.0 $\\pm$ 0.0 \\\\\n",
      "House 16 & Lore (Genetic) & - & - \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.674000 & 0.611 $\\pm$ 0.083 \\\\\n",
      "Letter & \\fire (SVM) & 0.820000 & 0.77 $\\pm$ 0.067 \\\\\n",
      "Letter & \\fire (LR) & 0.778000 & 0.715 $\\pm$ 0.07 \\\\\n",
      "Letter & LIME & 0.04 & 0.053 $\\pm$ 0.019 \\\\\n",
      "Letter & Lore (Random) & 0.043 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Letter & Lore (Genetic) & - & - \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.991000 & 0.985 $\\pm$ 0.017 \\\\\n",
      "Shuttle & \\fire (SVM) & - & - \\\\\n",
      "Shuttle & \\fire (LR) & - & - \\\\\n",
      "Shuttle & LIME & 0.801 & 0.078 $\\pm$ 0.047 \\\\\n",
      "Shuttle & Lore (Random) & 0.66 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Shuttle & Lore (Genetic) & - & - \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_metrics[df_metrics[\"Neighborhood Size\"] == 5000].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Dataset & Method & Fidelity & Fid. Neigh. \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.897000 & 0.931 $\\pm$ 0.037 \\\\\n",
      "Adult & \\fire (SVM) & - & - \\\\\n",
      "Adult & \\fire (LR) & 0.846000 & 0.974 $\\pm$ 0.014 \\\\\n",
      "Adult & LIME & 0.903 & 0.729 $\\pm$ 0.017 \\\\\n",
      "Adult & Lore (Random) & 0.636 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Adult & Lore (Genetic) & 0.669 & - \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.840000 & 0.847 $\\pm$ 0.034 \\\\\n",
      "Covertype & \\fire (SVM) & 0.578000 & 0.546 $\\pm$ 0.104 \\\\\n",
      "Covertype & \\fire (LR) & 0.861000 & 0.866 $\\pm$ 0.033 \\\\\n",
      "Covertype & LIME & 0.712 & 0.261 $\\pm$ 0.107 \\\\\n",
      "Covertype & Lore (Random) & 0.394 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Covertype & Lore (Genetic) & 0.366 & - \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.997000 & 0.997 $\\pm$ 0.004 \\\\\n",
      "Dutch & \\fire (SVM) & 0.994000 & 0.992 $\\pm$ 0.014 \\\\\n",
      "Dutch & \\fire (LR) & 0.994000 & 0.993 $\\pm$ 0.01 \\\\\n",
      "Dutch & LIME & 0.896 & 0.516 $\\pm$ 0.193 \\\\\n",
      "Dutch & Lore (Random) & 0.501 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Dutch & Lore (Genetic) & 0.502 & - \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.900000 & 0.876 $\\pm$ 0.031 \\\\\n",
      "House 16 & \\fire (SVM) & 0.711000 & 0.61 $\\pm$ 0.126 \\\\\n",
      "House 16 & \\fire (LR) & 0.939000 & 0.916 $\\pm$ 0.021 \\\\\n",
      "House 16 & LIME & 0.875 & 0.245 $\\pm$ 0.145 \\\\\n",
      "House 16 & Lore (Random) & 0.61 & 1.0 $\\pm$ 0.0 \\\\\n",
      "House 16 & Lore (Genetic) & 0.539 & - \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.699000 & 0.61 $\\pm$ 0.098 \\\\\n",
      "Letter & \\fire (SVM) & 0.841000 & 0.774 $\\pm$ 0.074 \\\\\n",
      "Letter & \\fire (LR) & 0.817000 & 0.731 $\\pm$ 0.079 \\\\\n",
      "Letter & LIME & 0.04 & 0.053 $\\pm$ 0.019 \\\\\n",
      "Letter & Lore (Random) & 0.044 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Letter & Lore (Genetic) & 0.04 & - \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.987000 & 0.984 $\\pm$ 0.021 \\\\\n",
      "Shuttle & \\fire (SVM) & - & - \\\\\n",
      "Shuttle & \\fire (LR) & - & - \\\\\n",
      "Shuttle & LIME & 0.801 & 0.078 $\\pm$ 0.047 \\\\\n",
      "Shuttle & Lore (Random) & 0.663 & 1.0 $\\pm$ 0.0 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.659 & - \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_metrics[df_metrics[\"Neighborhood Size\"] == 2500].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000, 2500, 5000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics[\"Neighborhood Size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data_time = download_runs(project_name=\"time_computation\")\n",
    "project_name = \"time_computation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"dt\", \"svm\", \"logistic\", \"lime\", \"shap\", \"lore\"]\n",
    "datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "top_k = [3, 5, 8, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1303545/1924254159.py:10: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_time = round(float(results[\"Total Time (sec)\"]), 3)\n",
      "/tmp/ipykernel_1303545/1924254159.py:11: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_time_std = round(float(results[\"Total Time Std (sec)\"]), 3)\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}   \n",
    "    for method in methods: \n",
    "        metrics[dataset][method] = {}\n",
    "        if f\"{method}_{dataset}\" in project_data_time:\n",
    "            results = project_data_time[f\"{method}_{dataset}\"][0]\n",
    "            if \"Total Time (sec)\" in results.columns:\n",
    "                total_time = round(float(results[\"Total Time (sec)\"]), 3)\n",
    "                total_time_std = round(float(results[\"Total Time Std (sec)\"]), 3)\n",
    "                metrics[dataset][method][\"Total Time\"] = f\"{total_time} $\\pm$ {total_time_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.112 $\\pm$ 0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>2.054 $\\pm$ 0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.081 $\\pm$ 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.445 $\\pm$ 0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>13.242 $\\pm$ 0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.348 $\\pm$ 0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.199 $\\pm$ 0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>17.707 $\\pm$ 9.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset         Method          Total Time\n",
       "0       Adult     \\fire (DT)   2.137 $\\pm$ 0.177\n",
       "1       Adult    \\fire (SVM)   1.112 $\\pm$ 0.212\n",
       "2       Adult     \\fire (LR)   2.054 $\\pm$ 0.629\n",
       "3       Adult           LIME   0.081 $\\pm$ 0.006\n",
       "4       Adult           SHAP   2.445 $\\pm$ 0.065\n",
       "5       Adult  Lore (Random)  13.242 $\\pm$ 0.564\n",
       "24  Covertype     \\fire (DT)   2.348 $\\pm$ 0.579\n",
       "25  Covertype    \\fire (SVM)   1.199 $\\pm$ 0.602\n",
       "26  Covertype     \\fire (LR)  17.707 $\\pm$ 9.385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "# Iterate over the datasets and methods to extract the metrics\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        row = {\n",
    "            'Dataset': dataset,\n",
    "            'Method': method,\n",
    "            'Total Time': metrics[dataset][method].get('Total Time', '-'),\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "df_metrics.head(10)\n",
    "\n",
    "\n",
    "# Map method names to their display names\n",
    "method_mapping = {\n",
    "    'dt': r'\\fire (DT)',\n",
    "    'svm': r'\\fire (SVM)',\n",
    "    'logistic': r'\\fire (LR)',\n",
    "    'lime': 'LIME',\n",
    "    'shap': 'SHAP',\n",
    "    'lore': 'Lore (Random)',\n",
    "    'lore_genetic': 'Lore (Genetic)'\n",
    "}\n",
    "\n",
    "# Map method names to their display names\n",
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House 16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Method\"] = df_metrics[\"Method\"].map(method_mapping)\n",
    "\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)\n",
    "\n",
    "# Sort the DataFrame by Dataset and Method\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'Method'])\n",
    "\n",
    "# Create custom method order for better visualization\n",
    "method_order = {\n",
    "    r'\\fire (DT)': 1, \n",
    "    r'\\fire (SVM)': 2, \n",
    "    r'\\fire (LR)': 3, \n",
    "    'LIME': 4, \n",
    "    'SHAP': 5, \n",
    "    'Lore (Random)': 6, \n",
    "    'Lore (Genetic)': 7\n",
    "}\n",
    "\n",
    "# Create a new column for sorting by custom method order\n",
    "df_metrics['method_order'] = df_metrics['Method'].map(method_order)\n",
    "\n",
    "# Sort by Dataset first, then by the custom method order\n",
    "df_metrics = df_metrics.sort_values(by=['Dataset', 'method_order'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_metrics = df_metrics.drop(columns=['method_order'])\n",
    "\n",
    "df_metrics.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort df_metrics by dataset name\n",
    "\n",
    "# # remove index \n",
    "df_metrics = df_metrics.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[\"Neighborhood Size\"] = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Dataset & Method & Total Time & Neighborhood Size \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 2.137 $\\pm$ 0.177 & 5000 \\\\\n",
      "Adult & \\fire (SVM) & 1.112 $\\pm$ 0.212 & 5000 \\\\\n",
      "Adult & \\fire (LR) & 2.054 $\\pm$ 0.629 & 5000 \\\\\n",
      "Adult & LIME & 0.081 $\\pm$ 0.006 & 5000 \\\\\n",
      "Adult & SHAP & 2.445 $\\pm$ 0.065 & 5000 \\\\\n",
      "Adult & Lore (Random) & 13.242 $\\pm$ 0.564 & 5000 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 2.348 $\\pm$ 0.579 & 5000 \\\\\n",
      "Covertype & \\fire (SVM) & 1.199 $\\pm$ 0.602 & 5000 \\\\\n",
      "Covertype & \\fire (LR) & 17.707 $\\pm$ 9.385 & 5000 \\\\\n",
      "Covertype & LIME & 0.112 $\\pm$ 0.11 & 5000 \\\\\n",
      "Covertype & SHAP & 18.637 $\\pm$ 0.447 & 5000 \\\\\n",
      "Covertype & Lore (Random) & 5.071 $\\pm$ 0.404 & 5000 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.927 $\\pm$ 0.032 & 5000 \\\\\n",
      "Dutch & \\fire (SVM) & 0.351 $\\pm$ 0.033 & 5000 \\\\\n",
      "Dutch & \\fire (LR) & 6.553 $\\pm$ 6.838 & 5000 \\\\\n",
      "Dutch & LIME & 0.091 $\\pm$ 0.125 & 5000 \\\\\n",
      "Dutch & SHAP & 1.724 $\\pm$ 0.077 & 5000 \\\\\n",
      "Dutch & Lore (Random) & 2.137 $\\pm$ 0.131 & 5000 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 2.255 $\\pm$ 0.083 & 5000 \\\\\n",
      "House 16 & \\fire (SVM) & 0.416 $\\pm$ 0.051 & 5000 \\\\\n",
      "House 16 & \\fire (LR) & 1.111 $\\pm$ 0.334 & 5000 \\\\\n",
      "House 16 & LIME & 0.066 $\\pm$ 0.079 & 5000 \\\\\n",
      "House 16 & SHAP & 1.64 $\\pm$ 0.049 & 5000 \\\\\n",
      "House 16 & Lore (Random) & 2.279 $\\pm$ 0.1 & 5000 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 1.216 $\\pm$ 0.084 & 5000 \\\\\n",
      "Letter & \\fire (SVM) & 0.872 $\\pm$ 0.213 & 5000 \\\\\n",
      "Letter & \\fire (LR) & 4.402 $\\pm$ 1.141 & 5000 \\\\\n",
      "Letter & LIME & 0.103 $\\pm$ 0.124 & 5000 \\\\\n",
      "Letter & SHAP & 2.433 $\\pm$ 0.121 & 5000 \\\\\n",
      "Letter & Lore (Random) & 2.754 $\\pm$ 0.078 & 5000 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 1.186 $\\pm$ 0.405 & 5000 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.474 $\\pm$ 0.406 & 5000 \\\\\n",
      "Shuttle & \\fire (LR) & 1.994 $\\pm$ 1.839 & 5000 \\\\\n",
      "Shuttle & LIME & 0.069 $\\pm$ 0.096 & 5000 \\\\\n",
      "Shuttle & SHAP & 1.095 $\\pm$ 0.051 & 5000 \\\\\n",
      "Shuttle & Lore (Random) & 1.823 $\\pm$ 0.181 & 5000 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for custom LaTeX output\n",
    "df_grouped = df_metrics.groupby('Dataset')\n",
    "\n",
    "# Start building the LaTeX table\n",
    "latex_output = \"\\\\begin{tabular}{\" + \"l\" * len(df_metrics.columns) + \"}\\n\"\n",
    "latex_output += \"\\\\toprule\\n\"\n",
    "\n",
    "# Add headers\n",
    "latex_output += \" & \".join(df_metrics.columns) + \" \\\\\\\\\\n\"\n",
    "latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "# Add rows with midrules between datasets\n",
    "datasets = df_metrics['Dataset'].unique()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    group = df_grouped.get_group(dataset)\n",
    "    \n",
    "    # Convert group dataframe to LaTeX rows\n",
    "    rows_latex = group.to_latex(index=False, header=False)\n",
    "    \n",
    "    # Extract just the rows part (not headers or table structure)\n",
    "    rows_only = \"\\n\".join(rows_latex.split(\"\\n\")[3:-3])\n",
    "    \n",
    "    latex_output += rows_only\n",
    "    \n",
    "    # Add midrule if not the last dataset\n",
    "    if i < len(datasets) - 1:\n",
    "        latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "latex_output += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.append(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>-</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>-</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Neighborhood Size       Method          Stability  \\\n",
       "63   Adult               1000   \\fire (DT)   0.845 $\\pm$ 0.23   \n",
       "64   Adult               2500   \\fire (DT)  0.898 $\\pm$ 0.167   \n",
       "65   Adult               5000   \\fire (DT)   0.92 $\\pm$ 0.148   \n",
       "66   Adult               1000  \\fire (SVM)  0.861 $\\pm$ 0.267   \n",
       "67   Adult               2500  \\fire (SVM)  0.859 $\\pm$ 0.258   \n",
       "\n",
       "         Faithfulness     Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "63                  -  0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "64                  -  0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "65                  -  0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "66  0.019 $\\pm$ 0.117  0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084  0.257 $\\pm$ 0.081  \n",
       "67   0.01 $\\pm$ 0.112  0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.918 $\\pm$ 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.931 $\\pm$ 0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.514 $\\pm$ 0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Neighborhood Size       Method Fidelity        Fid. Neigh.\n",
       "0   Adult               1000   \\fire (DT)    0.907   0.918 $\\pm$ 0.04\n",
       "1   Adult               2500   \\fire (DT)    0.897  0.931 $\\pm$ 0.037\n",
       "2   Adult               5000   \\fire (DT)    0.897   0.94 $\\pm$ 0.032\n",
       "3   Adult               1000  \\fire (SVM)    0.522  0.514 $\\pm$ 0.175\n",
       "4   Adult               2500  \\fire (SVM)        -                  -"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\\\fire (DT)', '\\\\fire (SVM)', '\\\\fire (LR)', 'LIME',\n",
       "       'Lore (Random)', 'Lore (Genetic)'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[1][\"Method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>House 16</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>House 16</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>House 16</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Letter</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Letter</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>1000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  Neighborhood Size Method Fidelity        Fid. Neigh.\n",
       "9        Adult               1000   LIME    0.908  0.729 $\\pm$ 0.017\n",
       "10       Adult               2500   LIME    0.903  0.729 $\\pm$ 0.017\n",
       "11       Adult               5000   LIME    0.926  0.729 $\\pm$ 0.017\n",
       "27   Covertype               1000   LIME    0.714  0.261 $\\pm$ 0.107\n",
       "28   Covertype               2500   LIME    0.712  0.261 $\\pm$ 0.107\n",
       "29   Covertype               5000   LIME    0.709  0.261 $\\pm$ 0.107\n",
       "45       Dutch               1000   LIME    0.893  0.516 $\\pm$ 0.193\n",
       "46       Dutch               2500   LIME    0.896  0.516 $\\pm$ 0.193\n",
       "47       Dutch               5000   LIME    0.896  0.516 $\\pm$ 0.193\n",
       "63    House 16               1000   LIME    0.882  0.245 $\\pm$ 0.145\n",
       "64    House 16               2500   LIME    0.875  0.245 $\\pm$ 0.145\n",
       "65    House 16               5000   LIME    0.872  0.245 $\\pm$ 0.145\n",
       "81      Letter               1000   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "82      Letter               2500   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "83      Letter               5000   LIME     0.04  0.053 $\\pm$ 0.019\n",
       "99     Shuttle               1000   LIME    0.801  0.078 $\\pm$ 0.047\n",
       "100    Shuttle               2500   LIME    0.801  0.078 $\\pm$ 0.047\n",
       "101    Shuttle               5000   LIME    0.801  0.078 $\\pm$ 0.047"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[1][merged_df[1][\"Method\"] == \"LIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.112 $\\pm$ 0.212</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>2.054 $\\pm$ 0.629</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.081 $\\pm$ 0.006</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.445 $\\pm$ 0.065</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset       Method         Total Time  Neighborhood Size\n",
       "0   Adult   \\fire (DT)  2.137 $\\pm$ 0.177               5000\n",
       "1   Adult  \\fire (SVM)  1.112 $\\pm$ 0.212               5000\n",
       "2   Adult   \\fire (LR)  2.054 $\\pm$ 0.629               5000\n",
       "3   Adult         LIME  0.081 $\\pm$ 0.006               5000\n",
       "4   Adult         SHAP  2.445 $\\pm$ 0.065               5000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.918 $\\pm$ 0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.931 $\\pm$ 0.037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.514 $\\pm$ 0.175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Letter</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.041 $\\pm$ 0.201</td>\n",
       "      <td>0.232 $\\pm$ 0.107</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "      <td>0.103 $\\pm$ 0.124</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.186 $\\pm$ 0.071</td>\n",
       "      <td>0.179 $\\pm$ 0.064</td>\n",
       "      <td>0.169 $\\pm$ 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Letter</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>0.567 $\\pm$ 0.223</td>\n",
       "      <td>0.522 $\\pm$ 0.153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.24 $\\pm$ 0.101</td>\n",
       "      <td>0.22 $\\pm$ 0.089</td>\n",
       "      <td>0.198 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Letter</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>0.567 $\\pm$ 0.223</td>\n",
       "      <td>0.522 $\\pm$ 0.153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.24 $\\pm$ 0.101</td>\n",
       "      <td>0.22 $\\pm$ 0.089</td>\n",
       "      <td>0.198 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Letter</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>0.567 $\\pm$ 0.223</td>\n",
       "      <td>0.522 $\\pm$ 0.153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.433 $\\pm$ 0.121</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.24 $\\pm$ 0.101</td>\n",
       "      <td>0.22 $\\pm$ 0.089</td>\n",
       "      <td>0.198 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Letter</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.764 $\\pm$ 0.085</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.669 $\\pm$ 0.06</td>\n",
       "      <td>0.668 $\\pm$ 0.053</td>\n",
       "      <td>0.668 $\\pm$ 0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset         Method       Faithfulness          Stability Fidelity  \\\n",
       "0    Adult     \\fire (DT)                  -   0.845 $\\pm$ 0.23    0.907   \n",
       "1    Adult     \\fire (DT)                  -  0.898 $\\pm$ 0.167    0.897   \n",
       "2    Adult     \\fire (DT)                  -   0.92 $\\pm$ 0.148    0.897   \n",
       "3    Adult    \\fire (SVM)  0.019 $\\pm$ 0.117  0.861 $\\pm$ 0.267    0.522   \n",
       "4    Adult    \\fire (SVM)   0.01 $\\pm$ 0.112  0.859 $\\pm$ 0.258        -   \n",
       "..     ...            ...                ...                ...      ...   \n",
       "95  Letter           LIME  0.041 $\\pm$ 0.201  0.232 $\\pm$ 0.107     0.04   \n",
       "96  Letter           SHAP  0.567 $\\pm$ 0.223  0.522 $\\pm$ 0.153      NaN   \n",
       "97  Letter           SHAP  0.567 $\\pm$ 0.223  0.522 $\\pm$ 0.153      NaN   \n",
       "98  Letter           SHAP  0.567 $\\pm$ 0.223  0.522 $\\pm$ 0.153      NaN   \n",
       "99  Letter  Lore (Random)                  -  0.764 $\\pm$ 0.085    0.044   \n",
       "\n",
       "          Fid. Neigh.         Total Time  Neighborhood Size  \\\n",
       "0    0.918 $\\pm$ 0.04                NaN               1000   \n",
       "1   0.931 $\\pm$ 0.037                NaN               2500   \n",
       "2    0.94 $\\pm$ 0.032  2.137 $\\pm$ 0.177               5000   \n",
       "3   0.514 $\\pm$ 0.175                NaN               1000   \n",
       "4                   -                NaN               2500   \n",
       "..                ...                ...                ...   \n",
       "95  0.053 $\\pm$ 0.019  0.103 $\\pm$ 0.124               5000   \n",
       "96                NaN                NaN               1000   \n",
       "97                NaN                NaN               2500   \n",
       "98                NaN  2.433 $\\pm$ 0.121               5000   \n",
       "99      1.0 $\\pm$ 0.0                NaN               1000   \n",
       "\n",
       "       Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "0   0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "1   0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "2   0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "3   0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084  0.257 $\\pm$ 0.081  \n",
       "4   0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "..                ...                ...                ...  \n",
       "95  0.186 $\\pm$ 0.071  0.179 $\\pm$ 0.064  0.169 $\\pm$ 0.057  \n",
       "96   0.24 $\\pm$ 0.101   0.22 $\\pm$ 0.089  0.198 $\\pm$ 0.077  \n",
       "97   0.24 $\\pm$ 0.101   0.22 $\\pm$ 0.089  0.198 $\\pm$ 0.077  \n",
       "98   0.24 $\\pm$ 0.101   0.22 $\\pm$ 0.089  0.198 $\\pm$ 0.077  \n",
       "99   0.669 $\\pm$ 0.06  0.668 $\\pm$ 0.053   0.668 $\\pm$ 0.05  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the three dataframes from merged_df\n",
    "df_explanation_metrics = merged_df[0]  # First dataframe with explanation metrics\n",
    "df_fidelity = merged_df[1]            # Second dataframe with fidelity\n",
    "df_time = merged_df[2]                # Third dataframe with time metrics\n",
    "\n",
    "# Create a unique identifier for each row to merge on\n",
    "for df in [df_explanation_metrics, df_fidelity, df_time]:\n",
    "    df['id'] = df['Dataset'] + '_' + df['Method'] + df[\"Neighborhood Size\"].astype(str)\n",
    "\n",
    "# Merge all dataframes into a single one\n",
    "df_merged = df_explanation_metrics.merge(\n",
    "    df_fidelity[['id', 'Fidelity', \"Fid. Neigh.\"]], \n",
    "    on='id', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "df_merged = df_merged.merge(\n",
    "    df_time[['id', 'Total Time']], \n",
    "    on='id', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Drop the temporary id column\n",
    "df_merged = df_merged.drop(columns=['id'])\n",
    "\n",
    "# Reorganize columns to have a more logical order\n",
    "columns_order = ['Dataset', 'Method', 'Faithfulness', 'Stability', 'Fidelity', \"Fid. Neigh.\", 'Total Time', \"Neighborhood Size\"] + \\\n",
    "                [col for col in df_merged.columns if 'Robustness' in col]\n",
    "\n",
    "# Apply the column order (only for columns that exist in the dataframe)\n",
    "available_columns = [col for col in columns_order if col in df_merged.columns]\n",
    "df_merged = df_merged[available_columns]\n",
    "\n",
    "# Sort by Dataset and Method using the method_order dictionary\n",
    "df_merged['method_order'] = df_merged['Method'].map(method_order)\n",
    "df_merged = df_merged.sort_values(by=['Dataset', 'method_order'])\n",
    "df_merged = df_merged.drop(columns=['method_order'])\n",
    "\n",
    "# Reset index\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "# df_merged[\"Total Time\"] = [\"-\"] * len(df_merged)\n",
    "\n",
    "# Display the first few rows\n",
    "df_merged.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows  where Neighborhood Sizet ish not \n",
    "df_merged = df_merged[~df_merged[\"Neighborhood Size\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize columns to have a more logical order\n",
    "columns_order = [\"Neighborhood Size\", 'Dataset', 'Method', 'Total Time', 'Fidelity', \"Fid. Neigh.\", 'Faithfulness', 'Stability'] + \\\n",
    "                [col for col in df_merged.columns if 'Robustness' in col]\n",
    "\n",
    "# Apply the column order (only for columns that exist in the dataframe)\n",
    "available_columns = [col for col in columns_order if col in df_merged.columns]\n",
    "df_merged = df_merged[available_columns]\n",
    "\n",
    "# Sort by Dataset and Method using the method_order dictionary\n",
    "df_merged['method_order'] = df_merged['Method'].map(method_order)\n",
    "df_merged = df_merged.sort_values(by=['Dataset', 'method_order'])\n",
    "df_merged = df_merged.drop(columns=['method_order'])\n",
    "\n",
    "# Reset index\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "# Display the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.918 $\\pm$ 0.04</td>\n",
       "      <td>-</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.931 $\\pm$ 0.037</td>\n",
       "      <td>-</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.514 $\\pm$ 0.175</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.112 $\\pm$ 0.212</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.518 $\\pm$ 0.177</td>\n",
       "      <td>0.012 $\\pm$ 0.122</td>\n",
       "      <td>0.727 $\\pm$ 0.34</td>\n",
       "      <td>0.242 $\\pm$ 0.103</td>\n",
       "      <td>0.24 $\\pm$ 0.094</td>\n",
       "      <td>0.238 $\\pm$ 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.969 $\\pm$ 0.019</td>\n",
       "      <td>-0.013 $\\pm$ 0.211</td>\n",
       "      <td>0.384 $\\pm$ 0.279</td>\n",
       "      <td>0.177 $\\pm$ 0.125</td>\n",
       "      <td>0.155 $\\pm$ 0.088</td>\n",
       "      <td>0.137 $\\pm$ 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.974 $\\pm$ 0.014</td>\n",
       "      <td>0.012 $\\pm$ 0.212</td>\n",
       "      <td>0.5 $\\pm$ 0.28</td>\n",
       "      <td>0.274 $\\pm$ 0.133</td>\n",
       "      <td>0.27 $\\pm$ 0.122</td>\n",
       "      <td>0.265 $\\pm$ 0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>2.054 $\\pm$ 0.629</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98 $\\pm$ 0.01</td>\n",
       "      <td>0.003 $\\pm$ 0.211</td>\n",
       "      <td>0.469 $\\pm$ 0.224</td>\n",
       "      <td>0.247 $\\pm$ 0.092</td>\n",
       "      <td>0.244 $\\pm$ 0.081</td>\n",
       "      <td>0.24 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "      <td>0.066 $\\pm$ 0.18</td>\n",
       "      <td>0.04 $\\pm$ 0.017</td>\n",
       "      <td>0.04 $\\pm$ 0.008</td>\n",
       "      <td>0.04 $\\pm$ 0.006</td>\n",
       "      <td>0.04 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "      <td>0.064 $\\pm$ 0.18</td>\n",
       "      <td>0.046 $\\pm$ 0.018</td>\n",
       "      <td>0.046 $\\pm$ 0.009</td>\n",
       "      <td>0.046 $\\pm$ 0.006</td>\n",
       "      <td>0.046 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.081 $\\pm$ 0.006</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "      <td>0.064 $\\pm$ 0.177</td>\n",
       "      <td>0.055 $\\pm$ 0.02</td>\n",
       "      <td>0.054 $\\pm$ 0.009</td>\n",
       "      <td>0.054 $\\pm$ 0.007</td>\n",
       "      <td>0.054 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.406 $\\pm$ 0.196</td>\n",
       "      <td>0.263 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.406 $\\pm$ 0.196</td>\n",
       "      <td>0.263 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.445 $\\pm$ 0.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.406 $\\pm$ 0.196</td>\n",
       "      <td>0.263 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.377 $\\pm$ 0.153</td>\n",
       "      <td>0.225 $\\pm$ 0.112</td>\n",
       "      <td>0.224 $\\pm$ 0.098</td>\n",
       "      <td>0.224 $\\pm$ 0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.469 $\\pm$ 0.154</td>\n",
       "      <td>0.235 $\\pm$ 0.104</td>\n",
       "      <td>0.235 $\\pm$ 0.088</td>\n",
       "      <td>0.235 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>13.242 $\\pm$ 0.564</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.339 $\\pm$ 0.223</td>\n",
       "      <td>0.342 $\\pm$ 0.137</td>\n",
       "      <td>0.341 $\\pm$ 0.122</td>\n",
       "      <td>0.341 $\\pm$ 0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.222 $\\pm$ 0.252</td>\n",
       "      <td>0.221 $\\pm$ 0.143</td>\n",
       "      <td>0.221 $\\pm$ 0.124</td>\n",
       "      <td>0.222 $\\pm$ 0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.301 $\\pm$ 0.235</td>\n",
       "      <td>0.299 $\\pm$ 0.143</td>\n",
       "      <td>0.299 $\\pm$ 0.127</td>\n",
       "      <td>0.299 $\\pm$ 0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.546 $\\pm$ 0.175</td>\n",
       "      <td>0.251 $\\pm$ 0.103</td>\n",
       "      <td>0.251 $\\pm$ 0.083</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.831 $\\pm$ 0.044</td>\n",
       "      <td>-</td>\n",
       "      <td>0.902 $\\pm$ 0.154</td>\n",
       "      <td>0.464 $\\pm$ 0.102</td>\n",
       "      <td>0.453 $\\pm$ 0.087</td>\n",
       "      <td>0.438 $\\pm$ 0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.847 $\\pm$ 0.034</td>\n",
       "      <td>-</td>\n",
       "      <td>0.925 $\\pm$ 0.133</td>\n",
       "      <td>0.598 $\\pm$ 0.113</td>\n",
       "      <td>0.584 $\\pm$ 0.101</td>\n",
       "      <td>0.57 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.348 $\\pm$ 0.579</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.854 $\\pm$ 0.028</td>\n",
       "      <td>-</td>\n",
       "      <td>0.94 $\\pm$ 0.114</td>\n",
       "      <td>0.618 $\\pm$ 0.115</td>\n",
       "      <td>0.602 $\\pm$ 0.104</td>\n",
       "      <td>0.588 $\\pm$ 0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.571 $\\pm$ 0.12</td>\n",
       "      <td>-0.078 $\\pm$ 0.262</td>\n",
       "      <td>0.57 $\\pm$ 0.343</td>\n",
       "      <td>0.127 $\\pm$ 0.046</td>\n",
       "      <td>0.121 $\\pm$ 0.041</td>\n",
       "      <td>0.114 $\\pm$ 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.546 $\\pm$ 0.104</td>\n",
       "      <td>-0.025 $\\pm$ 0.216</td>\n",
       "      <td>0.554 $\\pm$ 0.369</td>\n",
       "      <td>0.176 $\\pm$ 0.074</td>\n",
       "      <td>0.171 $\\pm$ 0.063</td>\n",
       "      <td>0.165 $\\pm$ 0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.199 $\\pm$ 0.602</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.525 $\\pm$ 0.096</td>\n",
       "      <td>-0.023 $\\pm$ 0.195</td>\n",
       "      <td>0.547 $\\pm$ 0.381</td>\n",
       "      <td>0.167 $\\pm$ 0.067</td>\n",
       "      <td>0.164 $\\pm$ 0.057</td>\n",
       "      <td>0.159 $\\pm$ 0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.867 $\\pm$ 0.041</td>\n",
       "      <td>-0.039 $\\pm$ 0.328</td>\n",
       "      <td>0.696 $\\pm$ 0.365</td>\n",
       "      <td>0.101 $\\pm$ 0.063</td>\n",
       "      <td>0.093 $\\pm$ 0.043</td>\n",
       "      <td>0.085 $\\pm$ 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.866 $\\pm$ 0.033</td>\n",
       "      <td>-0.069 $\\pm$ 0.308</td>\n",
       "      <td>0.946 $\\pm$ 0.188</td>\n",
       "      <td>0.243 $\\pm$ 0.122</td>\n",
       "      <td>0.233 $\\pm$ 0.109</td>\n",
       "      <td>0.221 $\\pm$ 0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>17.707 $\\pm$ 9.385</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.865 $\\pm$ 0.029</td>\n",
       "      <td>-0.071 $\\pm$ 0.297</td>\n",
       "      <td>0.944 $\\pm$ 0.19</td>\n",
       "      <td>0.244 $\\pm$ 0.112</td>\n",
       "      <td>0.235 $\\pm$ 0.098</td>\n",
       "      <td>0.224 $\\pm$ 0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>LIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "      <td>-0.101 $\\pm$ 0.274</td>\n",
       "      <td>0.597 $\\pm$ 0.04</td>\n",
       "      <td>0.592 $\\pm$ 0.022</td>\n",
       "      <td>0.591 $\\pm$ 0.018</td>\n",
       "      <td>0.591 $\\pm$ 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>LIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "      <td>-0.099 $\\pm$ 0.278</td>\n",
       "      <td>0.603 $\\pm$ 0.043</td>\n",
       "      <td>0.598 $\\pm$ 0.023</td>\n",
       "      <td>0.597 $\\pm$ 0.019</td>\n",
       "      <td>0.596 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.112 $\\pm$ 0.11</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "      <td>-0.109 $\\pm$ 0.281</td>\n",
       "      <td>0.612 $\\pm$ 0.046</td>\n",
       "      <td>0.605 $\\pm$ 0.024</td>\n",
       "      <td>0.604 $\\pm$ 0.02</td>\n",
       "      <td>0.603 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519 $\\pm$ 0.313</td>\n",
       "      <td>0.182 $\\pm$ 0.067</td>\n",
       "      <td>0.109 $\\pm$ 0.037</td>\n",
       "      <td>0.102 $\\pm$ 0.03</td>\n",
       "      <td>0.097 $\\pm$ 0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519 $\\pm$ 0.313</td>\n",
       "      <td>0.182 $\\pm$ 0.067</td>\n",
       "      <td>0.109 $\\pm$ 0.037</td>\n",
       "      <td>0.102 $\\pm$ 0.03</td>\n",
       "      <td>0.097 $\\pm$ 0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>18.637 $\\pm$ 0.447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519 $\\pm$ 0.313</td>\n",
       "      <td>0.182 $\\pm$ 0.067</td>\n",
       "      <td>0.109 $\\pm$ 0.037</td>\n",
       "      <td>0.102 $\\pm$ 0.03</td>\n",
       "      <td>0.097 $\\pm$ 0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.536 $\\pm$ 0.12</td>\n",
       "      <td>0.308 $\\pm$ 0.061</td>\n",
       "      <td>0.308 $\\pm$ 0.05</td>\n",
       "      <td>0.308 $\\pm$ 0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.68 $\\pm$ 0.116</td>\n",
       "      <td>0.388 $\\pm$ 0.065</td>\n",
       "      <td>0.388 $\\pm$ 0.056</td>\n",
       "      <td>0.388 $\\pm$ 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>5.071 $\\pm$ 0.404</td>\n",
       "      <td>0.377</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.425 $\\pm$ 0.119</td>\n",
       "      <td>0.409 $\\pm$ 0.071</td>\n",
       "      <td>0.409 $\\pm$ 0.062</td>\n",
       "      <td>0.409 $\\pm$ 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.364 $\\pm$ 0.132</td>\n",
       "      <td>0.356 $\\pm$ 0.075</td>\n",
       "      <td>0.357 $\\pm$ 0.064</td>\n",
       "      <td>0.357 $\\pm$ 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2500</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.4 $\\pm$ 0.125</td>\n",
       "      <td>0.388 $\\pm$ 0.072</td>\n",
       "      <td>0.388 $\\pm$ 0.062</td>\n",
       "      <td>0.388 $\\pm$ 0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.742 $\\pm$ 0.105</td>\n",
       "      <td>0.44 $\\pm$ 0.067</td>\n",
       "      <td>0.441 $\\pm$ 0.058</td>\n",
       "      <td>0.44 $\\pm$ 0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.996 $\\pm$ 0.006</td>\n",
       "      <td>-</td>\n",
       "      <td>0.965 $\\pm$ 0.114</td>\n",
       "      <td>0.628 $\\pm$ 0.24</td>\n",
       "      <td>0.597 $\\pm$ 0.215</td>\n",
       "      <td>0.551 $\\pm$ 0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2500</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997 $\\pm$ 0.004</td>\n",
       "      <td>-</td>\n",
       "      <td>0.967 $\\pm$ 0.099</td>\n",
       "      <td>0.903 $\\pm$ 0.144</td>\n",
       "      <td>0.876 $\\pm$ 0.149</td>\n",
       "      <td>0.845 $\\pm$ 0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.927 $\\pm$ 0.032</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.997 $\\pm$ 0.003</td>\n",
       "      <td>-</td>\n",
       "      <td>0.955 $\\pm$ 0.113</td>\n",
       "      <td>0.901 $\\pm$ 0.141</td>\n",
       "      <td>0.874 $\\pm$ 0.144</td>\n",
       "      <td>0.842 $\\pm$ 0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.995 $\\pm$ 0.012</td>\n",
       "      <td>0.073 $\\pm$ 0.315</td>\n",
       "      <td>0.796 $\\pm$ 0.283</td>\n",
       "      <td>0.25 $\\pm$ 0.097</td>\n",
       "      <td>0.219 $\\pm$ 0.065</td>\n",
       "      <td>0.201 $\\pm$ 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2500</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.992 $\\pm$ 0.014</td>\n",
       "      <td>0.054 $\\pm$ 0.284</td>\n",
       "      <td>0.799 $\\pm$ 0.272</td>\n",
       "      <td>0.697 $\\pm$ 0.278</td>\n",
       "      <td>0.615 $\\pm$ 0.26</td>\n",
       "      <td>0.525 $\\pm$ 0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.351 $\\pm$ 0.033</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.985 $\\pm$ 0.02</td>\n",
       "      <td>0.056 $\\pm$ 0.272</td>\n",
       "      <td>0.806 $\\pm$ 0.263</td>\n",
       "      <td>0.736 $\\pm$ 0.25</td>\n",
       "      <td>0.664 $\\pm$ 0.235</td>\n",
       "      <td>0.587 $\\pm$ 0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.996 $\\pm$ 0.008</td>\n",
       "      <td>0.063 $\\pm$ 0.257</td>\n",
       "      <td>0.769 $\\pm$ 0.292</td>\n",
       "      <td>0.267 $\\pm$ 0.122</td>\n",
       "      <td>0.233 $\\pm$ 0.085</td>\n",
       "      <td>0.208 $\\pm$ 0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2500</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.993 $\\pm$ 0.01</td>\n",
       "      <td>0.053 $\\pm$ 0.298</td>\n",
       "      <td>0.81 $\\pm$ 0.268</td>\n",
       "      <td>0.728 $\\pm$ 0.266</td>\n",
       "      <td>0.654 $\\pm$ 0.254</td>\n",
       "      <td>0.575 $\\pm$ 0.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neighborhood Size    Dataset          Method          Total Time Fidelity  \\\n",
       "0                1000      Adult      \\fire (DT)                 NaN    0.907   \n",
       "1                2500      Adult      \\fire (DT)                 NaN    0.897   \n",
       "2                5000      Adult      \\fire (DT)   2.137 $\\pm$ 0.177    0.897   \n",
       "3                1000      Adult     \\fire (SVM)                 NaN    0.522   \n",
       "4                2500      Adult     \\fire (SVM)                 NaN        -   \n",
       "5                5000      Adult     \\fire (SVM)   1.112 $\\pm$ 0.212    0.529   \n",
       "6                1000      Adult      \\fire (LR)                 NaN    0.895   \n",
       "7                2500      Adult      \\fire (LR)                 NaN    0.846   \n",
       "8                5000      Adult      \\fire (LR)   2.054 $\\pm$ 0.629      0.9   \n",
       "9                1000      Adult            LIME                 NaN    0.908   \n",
       "10               2500      Adult            LIME                 NaN    0.903   \n",
       "11               5000      Adult            LIME   0.081 $\\pm$ 0.006    0.926   \n",
       "12               1000      Adult            SHAP                 NaN      NaN   \n",
       "13               2500      Adult            SHAP                 NaN      NaN   \n",
       "14               5000      Adult            SHAP   2.445 $\\pm$ 0.065      NaN   \n",
       "15               1000      Adult   Lore (Random)                 NaN    0.636   \n",
       "16               2500      Adult   Lore (Random)                 NaN    0.636   \n",
       "17               5000      Adult   Lore (Random)  13.242 $\\pm$ 0.564    0.652   \n",
       "18               1000      Adult  Lore (Genetic)                 NaN    0.666   \n",
       "19               2500      Adult  Lore (Genetic)                 NaN    0.669   \n",
       "20               5000      Adult  Lore (Genetic)                 NaN        -   \n",
       "21               1000  Covertype      \\fire (DT)                 NaN    0.834   \n",
       "22               2500  Covertype      \\fire (DT)                 NaN     0.84   \n",
       "23               5000  Covertype      \\fire (DT)   2.348 $\\pm$ 0.579    0.842   \n",
       "24               1000  Covertype     \\fire (SVM)                 NaN    0.602   \n",
       "25               2500  Covertype     \\fire (SVM)                 NaN    0.578   \n",
       "26               5000  Covertype     \\fire (SVM)   1.199 $\\pm$ 0.602    0.562   \n",
       "27               1000  Covertype      \\fire (LR)                 NaN    0.872   \n",
       "28               2500  Covertype      \\fire (LR)                 NaN    0.861   \n",
       "29               5000  Covertype      \\fire (LR)  17.707 $\\pm$ 9.385    0.854   \n",
       "30               1000  Covertype            LIME                 NaN    0.714   \n",
       "31               2500  Covertype            LIME                 NaN    0.712   \n",
       "32               5000  Covertype            LIME    0.112 $\\pm$ 0.11    0.709   \n",
       "33               1000  Covertype            SHAP                 NaN      NaN   \n",
       "34               2500  Covertype            SHAP                 NaN      NaN   \n",
       "35               5000  Covertype            SHAP  18.637 $\\pm$ 0.447      NaN   \n",
       "36               1000  Covertype   Lore (Random)                 NaN    0.394   \n",
       "37               2500  Covertype   Lore (Random)                 NaN    0.394   \n",
       "38               5000  Covertype   Lore (Random)   5.071 $\\pm$ 0.404    0.377   \n",
       "39               1000  Covertype  Lore (Genetic)                 NaN    0.361   \n",
       "40               2500  Covertype  Lore (Genetic)                 NaN    0.366   \n",
       "41               5000  Covertype  Lore (Genetic)                 NaN        -   \n",
       "42               1000      Dutch      \\fire (DT)                 NaN    0.995   \n",
       "43               2500      Dutch      \\fire (DT)                 NaN    0.997   \n",
       "44               5000      Dutch      \\fire (DT)   0.927 $\\pm$ 0.032    0.996   \n",
       "45               1000      Dutch     \\fire (SVM)                 NaN    0.997   \n",
       "46               2500      Dutch     \\fire (SVM)                 NaN    0.994   \n",
       "47               5000      Dutch     \\fire (SVM)   0.351 $\\pm$ 0.033    0.989   \n",
       "48               1000      Dutch      \\fire (LR)                 NaN    0.997   \n",
       "49               2500      Dutch      \\fire (LR)                 NaN    0.994   \n",
       "\n",
       "          Fid. Neigh.        Faithfulness          Stability  \\\n",
       "0    0.918 $\\pm$ 0.04                   -   0.845 $\\pm$ 0.23   \n",
       "1   0.931 $\\pm$ 0.037                   -  0.898 $\\pm$ 0.167   \n",
       "2    0.94 $\\pm$ 0.032                   -   0.92 $\\pm$ 0.148   \n",
       "3   0.514 $\\pm$ 0.175   0.019 $\\pm$ 0.117  0.861 $\\pm$ 0.267   \n",
       "4                   -    0.01 $\\pm$ 0.112  0.859 $\\pm$ 0.258   \n",
       "5   0.518 $\\pm$ 0.177   0.012 $\\pm$ 0.122   0.727 $\\pm$ 0.34   \n",
       "6   0.969 $\\pm$ 0.019  -0.013 $\\pm$ 0.211  0.384 $\\pm$ 0.279   \n",
       "7   0.974 $\\pm$ 0.014   0.012 $\\pm$ 0.212     0.5 $\\pm$ 0.28   \n",
       "8     0.98 $\\pm$ 0.01   0.003 $\\pm$ 0.211  0.469 $\\pm$ 0.224   \n",
       "9   0.729 $\\pm$ 0.017    0.066 $\\pm$ 0.18   0.04 $\\pm$ 0.017   \n",
       "10  0.729 $\\pm$ 0.017    0.064 $\\pm$ 0.18  0.046 $\\pm$ 0.018   \n",
       "11  0.729 $\\pm$ 0.017   0.064 $\\pm$ 0.177   0.055 $\\pm$ 0.02   \n",
       "12                NaN    0.515 $\\pm$ 0.16  0.406 $\\pm$ 0.196   \n",
       "13                NaN    0.515 $\\pm$ 0.16  0.406 $\\pm$ 0.196   \n",
       "14                NaN    0.515 $\\pm$ 0.16  0.406 $\\pm$ 0.196   \n",
       "15      1.0 $\\pm$ 0.0                   -  0.377 $\\pm$ 0.153   \n",
       "16      1.0 $\\pm$ 0.0                   -  0.469 $\\pm$ 0.154   \n",
       "17      1.0 $\\pm$ 0.0                   -  0.339 $\\pm$ 0.223   \n",
       "18                  -                   -  0.222 $\\pm$ 0.252   \n",
       "19                  -                   -  0.301 $\\pm$ 0.235   \n",
       "20                  -                   -  0.546 $\\pm$ 0.175   \n",
       "21  0.831 $\\pm$ 0.044                   -  0.902 $\\pm$ 0.154   \n",
       "22  0.847 $\\pm$ 0.034                   -  0.925 $\\pm$ 0.133   \n",
       "23  0.854 $\\pm$ 0.028                   -   0.94 $\\pm$ 0.114   \n",
       "24   0.571 $\\pm$ 0.12  -0.078 $\\pm$ 0.262   0.57 $\\pm$ 0.343   \n",
       "25  0.546 $\\pm$ 0.104  -0.025 $\\pm$ 0.216  0.554 $\\pm$ 0.369   \n",
       "26  0.525 $\\pm$ 0.096  -0.023 $\\pm$ 0.195  0.547 $\\pm$ 0.381   \n",
       "27  0.867 $\\pm$ 0.041  -0.039 $\\pm$ 0.328  0.696 $\\pm$ 0.365   \n",
       "28  0.866 $\\pm$ 0.033  -0.069 $\\pm$ 0.308  0.946 $\\pm$ 0.188   \n",
       "29  0.865 $\\pm$ 0.029  -0.071 $\\pm$ 0.297   0.944 $\\pm$ 0.19   \n",
       "30  0.261 $\\pm$ 0.107  -0.101 $\\pm$ 0.274   0.597 $\\pm$ 0.04   \n",
       "31  0.261 $\\pm$ 0.107  -0.099 $\\pm$ 0.278  0.603 $\\pm$ 0.043   \n",
       "32  0.261 $\\pm$ 0.107  -0.109 $\\pm$ 0.281  0.612 $\\pm$ 0.046   \n",
       "33                NaN   0.519 $\\pm$ 0.313  0.182 $\\pm$ 0.067   \n",
       "34                NaN   0.519 $\\pm$ 0.313  0.182 $\\pm$ 0.067   \n",
       "35                NaN   0.519 $\\pm$ 0.313  0.182 $\\pm$ 0.067   \n",
       "36      1.0 $\\pm$ 0.0                   -   0.536 $\\pm$ 0.12   \n",
       "37      1.0 $\\pm$ 0.0                   -   0.68 $\\pm$ 0.116   \n",
       "38      1.0 $\\pm$ 0.0                   -  0.425 $\\pm$ 0.119   \n",
       "39                  -                   -  0.364 $\\pm$ 0.132   \n",
       "40                  -                   -    0.4 $\\pm$ 0.125   \n",
       "41                  -                   -  0.742 $\\pm$ 0.105   \n",
       "42  0.996 $\\pm$ 0.006                   -  0.965 $\\pm$ 0.114   \n",
       "43  0.997 $\\pm$ 0.004                   -  0.967 $\\pm$ 0.099   \n",
       "44  0.997 $\\pm$ 0.003                   -  0.955 $\\pm$ 0.113   \n",
       "45  0.995 $\\pm$ 0.012   0.073 $\\pm$ 0.315  0.796 $\\pm$ 0.283   \n",
       "46  0.992 $\\pm$ 0.014   0.054 $\\pm$ 0.284  0.799 $\\pm$ 0.272   \n",
       "47   0.985 $\\pm$ 0.02   0.056 $\\pm$ 0.272  0.806 $\\pm$ 0.263   \n",
       "48  0.996 $\\pm$ 0.008   0.063 $\\pm$ 0.257  0.769 $\\pm$ 0.292   \n",
       "49   0.993 $\\pm$ 0.01   0.053 $\\pm$ 0.298   0.81 $\\pm$ 0.268   \n",
       "\n",
       "       Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "0   0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "1   0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "2   0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "3   0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084  0.257 $\\pm$ 0.081  \n",
       "4   0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "5   0.242 $\\pm$ 0.103   0.24 $\\pm$ 0.094  0.238 $\\pm$ 0.088  \n",
       "6   0.177 $\\pm$ 0.125  0.155 $\\pm$ 0.088  0.137 $\\pm$ 0.059  \n",
       "7   0.274 $\\pm$ 0.133   0.27 $\\pm$ 0.122  0.265 $\\pm$ 0.114  \n",
       "8   0.247 $\\pm$ 0.092  0.244 $\\pm$ 0.081   0.24 $\\pm$ 0.075  \n",
       "9    0.04 $\\pm$ 0.008   0.04 $\\pm$ 0.006   0.04 $\\pm$ 0.005  \n",
       "10  0.046 $\\pm$ 0.009  0.046 $\\pm$ 0.006  0.046 $\\pm$ 0.005  \n",
       "11  0.054 $\\pm$ 0.009  0.054 $\\pm$ 0.007  0.054 $\\pm$ 0.005  \n",
       "12  0.263 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.087  \n",
       "13  0.263 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.087  \n",
       "14  0.263 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.087  \n",
       "15  0.225 $\\pm$ 0.112  0.224 $\\pm$ 0.098  0.224 $\\pm$ 0.091  \n",
       "16  0.235 $\\pm$ 0.104  0.235 $\\pm$ 0.088  0.235 $\\pm$ 0.077  \n",
       "17  0.342 $\\pm$ 0.137  0.341 $\\pm$ 0.122  0.341 $\\pm$ 0.113  \n",
       "18  0.221 $\\pm$ 0.143  0.221 $\\pm$ 0.124  0.222 $\\pm$ 0.112  \n",
       "19  0.299 $\\pm$ 0.143  0.299 $\\pm$ 0.127  0.299 $\\pm$ 0.118  \n",
       "20  0.251 $\\pm$ 0.103  0.251 $\\pm$ 0.083  0.252 $\\pm$ 0.071  \n",
       "21  0.464 $\\pm$ 0.102  0.453 $\\pm$ 0.087  0.438 $\\pm$ 0.082  \n",
       "22  0.598 $\\pm$ 0.113  0.584 $\\pm$ 0.101   0.57 $\\pm$ 0.093  \n",
       "23  0.618 $\\pm$ 0.115  0.602 $\\pm$ 0.104  0.588 $\\pm$ 0.096  \n",
       "24  0.127 $\\pm$ 0.046  0.121 $\\pm$ 0.041   0.114 $\\pm$ 0.04  \n",
       "25  0.176 $\\pm$ 0.074  0.171 $\\pm$ 0.063  0.165 $\\pm$ 0.056  \n",
       "26  0.167 $\\pm$ 0.067  0.164 $\\pm$ 0.057  0.159 $\\pm$ 0.051  \n",
       "27  0.101 $\\pm$ 0.063  0.093 $\\pm$ 0.043   0.085 $\\pm$ 0.03  \n",
       "28  0.243 $\\pm$ 0.122  0.233 $\\pm$ 0.109  0.221 $\\pm$ 0.099  \n",
       "29  0.244 $\\pm$ 0.112  0.235 $\\pm$ 0.098  0.224 $\\pm$ 0.089  \n",
       "30  0.592 $\\pm$ 0.022  0.591 $\\pm$ 0.018  0.591 $\\pm$ 0.016  \n",
       "31  0.598 $\\pm$ 0.023  0.597 $\\pm$ 0.019  0.596 $\\pm$ 0.017  \n",
       "32  0.605 $\\pm$ 0.024   0.604 $\\pm$ 0.02  0.603 $\\pm$ 0.017  \n",
       "33  0.109 $\\pm$ 0.037   0.102 $\\pm$ 0.03  0.097 $\\pm$ 0.025  \n",
       "34  0.109 $\\pm$ 0.037   0.102 $\\pm$ 0.03  0.097 $\\pm$ 0.025  \n",
       "35  0.109 $\\pm$ 0.037   0.102 $\\pm$ 0.03  0.097 $\\pm$ 0.025  \n",
       "36  0.308 $\\pm$ 0.061   0.308 $\\pm$ 0.05  0.308 $\\pm$ 0.043  \n",
       "37  0.388 $\\pm$ 0.065  0.388 $\\pm$ 0.056   0.388 $\\pm$ 0.05  \n",
       "38  0.409 $\\pm$ 0.071  0.409 $\\pm$ 0.062  0.409 $\\pm$ 0.057  \n",
       "39  0.356 $\\pm$ 0.075  0.357 $\\pm$ 0.064  0.357 $\\pm$ 0.059  \n",
       "40  0.388 $\\pm$ 0.072  0.388 $\\pm$ 0.062  0.388 $\\pm$ 0.058  \n",
       "41   0.44 $\\pm$ 0.067  0.441 $\\pm$ 0.058   0.44 $\\pm$ 0.053  \n",
       "42   0.628 $\\pm$ 0.24  0.597 $\\pm$ 0.215  0.551 $\\pm$ 0.186  \n",
       "43  0.903 $\\pm$ 0.144  0.876 $\\pm$ 0.149  0.845 $\\pm$ 0.151  \n",
       "44  0.901 $\\pm$ 0.141  0.874 $\\pm$ 0.144  0.842 $\\pm$ 0.144  \n",
       "45   0.25 $\\pm$ 0.097  0.219 $\\pm$ 0.065   0.201 $\\pm$ 0.05  \n",
       "46  0.697 $\\pm$ 0.278   0.615 $\\pm$ 0.26  0.525 $\\pm$ 0.218  \n",
       "47   0.736 $\\pm$ 0.25  0.664 $\\pm$ 0.235  0.587 $\\pm$ 0.203  \n",
       "48  0.267 $\\pm$ 0.122  0.233 $\\pm$ 0.085  0.208 $\\pm$ 0.066  \n",
       "49  0.728 $\\pm$ 0.266  0.654 $\\pm$ 0.254  0.575 $\\pm$ 0.226  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000, 2500, 5000])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"Neighborhood Size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.546 $\\pm$ 0.175</td>\n",
       "      <td>0.251 $\\pm$ 0.103</td>\n",
       "      <td>0.251 $\\pm$ 0.083</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.742 $\\pm$ 0.105</td>\n",
       "      <td>0.44 $\\pm$ 0.067</td>\n",
       "      <td>0.441 $\\pm$ 0.058</td>\n",
       "      <td>0.44 $\\pm$ 0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.808 $\\pm$ 0.197</td>\n",
       "      <td>0.598 $\\pm$ 0.123</td>\n",
       "      <td>0.598 $\\pm$ 0.107</td>\n",
       "      <td>0.598 $\\pm$ 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.772 $\\pm$ 0.144</td>\n",
       "      <td>0.553 $\\pm$ 0.1</td>\n",
       "      <td>0.553 $\\pm$ 0.085</td>\n",
       "      <td>0.553 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.9 $\\pm$ 0.059</td>\n",
       "      <td>0.773 $\\pm$ 0.047</td>\n",
       "      <td>0.773 $\\pm$ 0.041</td>\n",
       "      <td>0.773 $\\pm$ 0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.868 $\\pm$ 0.117</td>\n",
       "      <td>0.751 $\\pm$ 0.079</td>\n",
       "      <td>0.75 $\\pm$ 0.069</td>\n",
       "      <td>0.75 $\\pm$ 0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Neighborhood Size    Dataset          Method Total Time Fidelity  \\\n",
       "20                5000      Adult  Lore (Genetic)        NaN        -   \n",
       "41                5000  Covertype  Lore (Genetic)        NaN        -   \n",
       "62                5000      Dutch  Lore (Genetic)        NaN        -   \n",
       "83                5000   House 16  Lore (Genetic)        NaN        -   \n",
       "104               5000     Letter  Lore (Genetic)        NaN        -   \n",
       "125               5000    Shuttle  Lore (Genetic)        NaN        -   \n",
       "\n",
       "    Fid. Neigh. Faithfulness          Stability     Robustness K=5  \\\n",
       "20            -            -  0.546 $\\pm$ 0.175  0.251 $\\pm$ 0.103   \n",
       "41            -            -  0.742 $\\pm$ 0.105   0.44 $\\pm$ 0.067   \n",
       "62            -            -  0.808 $\\pm$ 0.197  0.598 $\\pm$ 0.123   \n",
       "83            -            -  0.772 $\\pm$ 0.144    0.553 $\\pm$ 0.1   \n",
       "104           -            -    0.9 $\\pm$ 0.059  0.773 $\\pm$ 0.047   \n",
       "125           -            -  0.868 $\\pm$ 0.117  0.751 $\\pm$ 0.079   \n",
       "\n",
       "       Robustness K=10    Robustness K=20  \n",
       "20   0.251 $\\pm$ 0.083  0.252 $\\pm$ 0.071  \n",
       "41   0.441 $\\pm$ 0.058   0.44 $\\pm$ 0.053  \n",
       "62   0.598 $\\pm$ 0.107    0.598 $\\pm$ 0.1  \n",
       "83   0.553 $\\pm$ 0.085  0.553 $\\pm$ 0.077  \n",
       "104  0.773 $\\pm$ 0.041  0.773 $\\pm$ 0.038  \n",
       "125   0.75 $\\pm$ 0.069   0.75 $\\pm$ 0.064  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the rows of df_merged where Fidelity is \"-\" and the method is \"Lore (Genetic)\"\n",
    "df_merged[(df_merged[\"Fidelity\"] == \"-\") & (df_merged[\"Method\"] == \"Lore (Genetic)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indexes of rows that need to be updated\n",
    "idx = df_merged[(df_merged[\"Fidelity\"] == \"-\") & (df_merged[\"Method\"] == \"Lore (Genetic)\")].index\n",
    "\n",
    "# Update the values using loc[] to avoid the warning\n",
    "df_merged.loc[idx, \"Fid. Neigh.\"] = \"1.0 $\\pm$ 0.0\"\n",
    "df_merged.loc[idx, \"Fidelity\"] = [0.643, 0.635, 0.501 , 0.611 , 0.041 , 0.674]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.546 $\\pm$ 0.175</td>\n",
       "      <td>0.251 $\\pm$ 0.103</td>\n",
       "      <td>0.251 $\\pm$ 0.083</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.742 $\\pm$ 0.105</td>\n",
       "      <td>0.44 $\\pm$ 0.067</td>\n",
       "      <td>0.441 $\\pm$ 0.058</td>\n",
       "      <td>0.44 $\\pm$ 0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.808 $\\pm$ 0.197</td>\n",
       "      <td>0.598 $\\pm$ 0.123</td>\n",
       "      <td>0.598 $\\pm$ 0.107</td>\n",
       "      <td>0.598 $\\pm$ 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.772 $\\pm$ 0.144</td>\n",
       "      <td>0.553 $\\pm$ 0.1</td>\n",
       "      <td>0.553 $\\pm$ 0.085</td>\n",
       "      <td>0.553 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.9 $\\pm$ 0.059</td>\n",
       "      <td>0.773 $\\pm$ 0.047</td>\n",
       "      <td>0.773 $\\pm$ 0.041</td>\n",
       "      <td>0.773 $\\pm$ 0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.868 $\\pm$ 0.117</td>\n",
       "      <td>0.751 $\\pm$ 0.079</td>\n",
       "      <td>0.75 $\\pm$ 0.069</td>\n",
       "      <td>0.75 $\\pm$ 0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Neighborhood Size    Dataset          Method Total Time Fidelity  \\\n",
       "20                5000      Adult  Lore (Genetic)        NaN    0.643   \n",
       "41                5000  Covertype  Lore (Genetic)        NaN    0.635   \n",
       "62                5000      Dutch  Lore (Genetic)        NaN    0.501   \n",
       "83                5000   House 16  Lore (Genetic)        NaN    0.611   \n",
       "104               5000     Letter  Lore (Genetic)        NaN    0.041   \n",
       "125               5000    Shuttle  Lore (Genetic)        NaN    0.674   \n",
       "\n",
       "       Fid. Neigh. Faithfulness          Stability     Robustness K=5  \\\n",
       "20   1.0 $\\pm$ 0.0            -  0.546 $\\pm$ 0.175  0.251 $\\pm$ 0.103   \n",
       "41   1.0 $\\pm$ 0.0            -  0.742 $\\pm$ 0.105   0.44 $\\pm$ 0.067   \n",
       "62   1.0 $\\pm$ 0.0            -  0.808 $\\pm$ 0.197  0.598 $\\pm$ 0.123   \n",
       "83   1.0 $\\pm$ 0.0            -  0.772 $\\pm$ 0.144    0.553 $\\pm$ 0.1   \n",
       "104  1.0 $\\pm$ 0.0            -    0.9 $\\pm$ 0.059  0.773 $\\pm$ 0.047   \n",
       "125  1.0 $\\pm$ 0.0            -  0.868 $\\pm$ 0.117  0.751 $\\pm$ 0.079   \n",
       "\n",
       "       Robustness K=10    Robustness K=20  \n",
       "20   0.251 $\\pm$ 0.083  0.252 $\\pm$ 0.071  \n",
       "41   0.441 $\\pm$ 0.058   0.44 $\\pm$ 0.053  \n",
       "62   0.598 $\\pm$ 0.107    0.598 $\\pm$ 0.1  \n",
       "83   0.553 $\\pm$ 0.085  0.553 $\\pm$ 0.077  \n",
       "104  0.773 $\\pm$ 0.041  0.773 $\\pm$ 0.038  \n",
       "125   0.75 $\\pm$ 0.069   0.75 $\\pm$ 0.064  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2500</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.262 $\\pm$ 0.616</td>\n",
       "      <td>0.805 $\\pm$ 0.283</td>\n",
       "      <td>0.435 $\\pm$ 0.156</td>\n",
       "      <td>0.423 $\\pm$ 0.142</td>\n",
       "      <td>0.41 $\\pm$ 0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.474 $\\pm$ 0.406</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.268 $\\pm$ 0.612</td>\n",
       "      <td>0.806 $\\pm$ 0.282</td>\n",
       "      <td>0.433 $\\pm$ 0.154</td>\n",
       "      <td>0.421 $\\pm$ 0.141</td>\n",
       "      <td>0.408 $\\pm$ 0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2500</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.054 $\\pm$ 0.657</td>\n",
       "      <td>0.835 $\\pm$ 0.262</td>\n",
       "      <td>0.51 $\\pm$ 0.185</td>\n",
       "      <td>0.49 $\\pm$ 0.167</td>\n",
       "      <td>0.468 $\\pm$ 0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>1.994 $\\pm$ 1.839</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.05 $\\pm$ 0.658</td>\n",
       "      <td>0.841 $\\pm$ 0.258</td>\n",
       "      <td>0.506 $\\pm$ 0.184</td>\n",
       "      <td>0.487 $\\pm$ 0.167</td>\n",
       "      <td>0.466 $\\pm$ 0.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Neighborhood Size  Dataset       Method         Total Time Fidelity  \\\n",
       "4                 2500    Adult  \\fire (SVM)                NaN        -   \n",
       "109               2500  Shuttle  \\fire (SVM)                NaN        -   \n",
       "110               5000  Shuttle  \\fire (SVM)  0.474 $\\pm$ 0.406        -   \n",
       "112               2500  Shuttle   \\fire (LR)                NaN        -   \n",
       "113               5000  Shuttle   \\fire (LR)  1.994 $\\pm$ 1.839        -   \n",
       "\n",
       "    Fid. Neigh.       Faithfulness          Stability     Robustness K=5  \\\n",
       "4             -   0.01 $\\pm$ 0.112  0.859 $\\pm$ 0.258  0.296 $\\pm$ 0.107   \n",
       "109           -  0.262 $\\pm$ 0.616  0.805 $\\pm$ 0.283  0.435 $\\pm$ 0.156   \n",
       "110           -  0.268 $\\pm$ 0.612  0.806 $\\pm$ 0.282  0.433 $\\pm$ 0.154   \n",
       "112           -  0.054 $\\pm$ 0.657  0.835 $\\pm$ 0.262   0.51 $\\pm$ 0.185   \n",
       "113           -   0.05 $\\pm$ 0.658  0.841 $\\pm$ 0.258  0.506 $\\pm$ 0.184   \n",
       "\n",
       "       Robustness K=10    Robustness K=20  \n",
       "4    0.292 $\\pm$ 0.099  0.288 $\\pm$ 0.093  \n",
       "109  0.423 $\\pm$ 0.142   0.41 $\\pm$ 0.132  \n",
       "110  0.421 $\\pm$ 0.141  0.408 $\\pm$ 0.132  \n",
       "112   0.49 $\\pm$ 0.167  0.468 $\\pm$ 0.155  \n",
       "113  0.487 $\\pm$ 0.167  0.466 $\\pm$ 0.156  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[(df_merged[\"Fidelity\"] == \"-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged[(df_merged[\"Fidelity\"] == \"-\")].index\n",
    "\n",
    "df_merged.loc[idx, \"Fidelity\"] = [0.522, 0.992 , 0.995 , 0.991 , 0.993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.112 $\\pm$ 0.212</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.518 $\\pm$ 0.177</td>\n",
       "      <td>0.012 $\\pm$ 0.122</td>\n",
       "      <td>0.727 $\\pm$ 0.34</td>\n",
       "      <td>0.242 $\\pm$ 0.103</td>\n",
       "      <td>0.24 $\\pm$ 0.094</td>\n",
       "      <td>0.238 $\\pm$ 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>2.054 $\\pm$ 0.629</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98 $\\pm$ 0.01</td>\n",
       "      <td>0.003 $\\pm$ 0.211</td>\n",
       "      <td>0.469 $\\pm$ 0.224</td>\n",
       "      <td>0.247 $\\pm$ 0.092</td>\n",
       "      <td>0.244 $\\pm$ 0.081</td>\n",
       "      <td>0.24 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.081 $\\pm$ 0.006</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "      <td>0.064 $\\pm$ 0.177</td>\n",
       "      <td>0.055 $\\pm$ 0.02</td>\n",
       "      <td>0.054 $\\pm$ 0.009</td>\n",
       "      <td>0.054 $\\pm$ 0.007</td>\n",
       "      <td>0.054 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.445 $\\pm$ 0.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.406 $\\pm$ 0.196</td>\n",
       "      <td>0.263 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>13.242 $\\pm$ 0.564</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.339 $\\pm$ 0.223</td>\n",
       "      <td>0.342 $\\pm$ 0.137</td>\n",
       "      <td>0.341 $\\pm$ 0.122</td>\n",
       "      <td>0.341 $\\pm$ 0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.546 $\\pm$ 0.175</td>\n",
       "      <td>0.251 $\\pm$ 0.103</td>\n",
       "      <td>0.251 $\\pm$ 0.083</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neighborhood Size Dataset          Method          Total Time Fidelity  \\\n",
       "2                5000   Adult      \\fire (DT)   2.137 $\\pm$ 0.177    0.897   \n",
       "5                5000   Adult     \\fire (SVM)   1.112 $\\pm$ 0.212    0.529   \n",
       "8                5000   Adult      \\fire (LR)   2.054 $\\pm$ 0.629      0.9   \n",
       "11               5000   Adult            LIME   0.081 $\\pm$ 0.006    0.926   \n",
       "14               5000   Adult            SHAP   2.445 $\\pm$ 0.065      NaN   \n",
       "17               5000   Adult   Lore (Random)  13.242 $\\pm$ 0.564    0.652   \n",
       "20               5000   Adult  Lore (Genetic)                 NaN    0.643   \n",
       "\n",
       "          Fid. Neigh.       Faithfulness          Stability  \\\n",
       "2    0.94 $\\pm$ 0.032                  -   0.92 $\\pm$ 0.148   \n",
       "5   0.518 $\\pm$ 0.177  0.012 $\\pm$ 0.122   0.727 $\\pm$ 0.34   \n",
       "8     0.98 $\\pm$ 0.01  0.003 $\\pm$ 0.211  0.469 $\\pm$ 0.224   \n",
       "11  0.729 $\\pm$ 0.017  0.064 $\\pm$ 0.177   0.055 $\\pm$ 0.02   \n",
       "14                NaN   0.515 $\\pm$ 0.16  0.406 $\\pm$ 0.196   \n",
       "17      1.0 $\\pm$ 0.0                  -  0.339 $\\pm$ 0.223   \n",
       "20      1.0 $\\pm$ 0.0                  -  0.546 $\\pm$ 0.175   \n",
       "\n",
       "       Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "2   0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "5   0.242 $\\pm$ 0.103   0.24 $\\pm$ 0.094  0.238 $\\pm$ 0.088  \n",
       "8   0.247 $\\pm$ 0.092  0.244 $\\pm$ 0.081   0.24 $\\pm$ 0.075  \n",
       "11  0.054 $\\pm$ 0.009  0.054 $\\pm$ 0.007  0.054 $\\pm$ 0.005  \n",
       "14  0.263 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.087  \n",
       "17  0.342 $\\pm$ 0.137  0.341 $\\pm$ 0.122  0.341 $\\pm$ 0.113  \n",
       "20  0.251 $\\pm$ 0.103  0.251 $\\pm$ 0.083  0.252 $\\pm$ 0.071  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[(df_merged[\"Neighborhood Size\"] == 5000.0) & (df_merged[\"Dataset\"] == \"Adult\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.112 $\\pm$ 0.212</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.518 $\\pm$ 0.177</td>\n",
       "      <td>0.012 $\\pm$ 0.122</td>\n",
       "      <td>0.727 $\\pm$ 0.34</td>\n",
       "      <td>0.242 $\\pm$ 0.103</td>\n",
       "      <td>0.24 $\\pm$ 0.094</td>\n",
       "      <td>0.238 $\\pm$ 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>2.054 $\\pm$ 0.629</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98 $\\pm$ 0.01</td>\n",
       "      <td>0.003 $\\pm$ 0.211</td>\n",
       "      <td>0.469 $\\pm$ 0.224</td>\n",
       "      <td>0.247 $\\pm$ 0.092</td>\n",
       "      <td>0.244 $\\pm$ 0.081</td>\n",
       "      <td>0.24 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.081 $\\pm$ 0.006</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.729 $\\pm$ 0.017</td>\n",
       "      <td>0.064 $\\pm$ 0.177</td>\n",
       "      <td>0.055 $\\pm$ 0.02</td>\n",
       "      <td>0.054 $\\pm$ 0.009</td>\n",
       "      <td>0.054 $\\pm$ 0.007</td>\n",
       "      <td>0.054 $\\pm$ 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.445 $\\pm$ 0.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515 $\\pm$ 0.16</td>\n",
       "      <td>0.406 $\\pm$ 0.196</td>\n",
       "      <td>0.263 $\\pm$ 0.112</td>\n",
       "      <td>0.257 $\\pm$ 0.096</td>\n",
       "      <td>0.251 $\\pm$ 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>13.242 $\\pm$ 0.564</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.339 $\\pm$ 0.223</td>\n",
       "      <td>0.342 $\\pm$ 0.137</td>\n",
       "      <td>0.341 $\\pm$ 0.122</td>\n",
       "      <td>0.341 $\\pm$ 0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.546 $\\pm$ 0.175</td>\n",
       "      <td>0.251 $\\pm$ 0.103</td>\n",
       "      <td>0.251 $\\pm$ 0.083</td>\n",
       "      <td>0.252 $\\pm$ 0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.348 $\\pm$ 0.579</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.854 $\\pm$ 0.028</td>\n",
       "      <td>-</td>\n",
       "      <td>0.94 $\\pm$ 0.114</td>\n",
       "      <td>0.618 $\\pm$ 0.115</td>\n",
       "      <td>0.602 $\\pm$ 0.104</td>\n",
       "      <td>0.588 $\\pm$ 0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>1.199 $\\pm$ 0.602</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.525 $\\pm$ 0.096</td>\n",
       "      <td>-0.023 $\\pm$ 0.195</td>\n",
       "      <td>0.547 $\\pm$ 0.381</td>\n",
       "      <td>0.167 $\\pm$ 0.067</td>\n",
       "      <td>0.164 $\\pm$ 0.057</td>\n",
       "      <td>0.159 $\\pm$ 0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>17.707 $\\pm$ 9.385</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.865 $\\pm$ 0.029</td>\n",
       "      <td>-0.071 $\\pm$ 0.297</td>\n",
       "      <td>0.944 $\\pm$ 0.19</td>\n",
       "      <td>0.244 $\\pm$ 0.112</td>\n",
       "      <td>0.235 $\\pm$ 0.098</td>\n",
       "      <td>0.224 $\\pm$ 0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.112 $\\pm$ 0.11</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.261 $\\pm$ 0.107</td>\n",
       "      <td>-0.109 $\\pm$ 0.281</td>\n",
       "      <td>0.612 $\\pm$ 0.046</td>\n",
       "      <td>0.605 $\\pm$ 0.024</td>\n",
       "      <td>0.604 $\\pm$ 0.02</td>\n",
       "      <td>0.603 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>18.637 $\\pm$ 0.447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519 $\\pm$ 0.313</td>\n",
       "      <td>0.182 $\\pm$ 0.067</td>\n",
       "      <td>0.109 $\\pm$ 0.037</td>\n",
       "      <td>0.102 $\\pm$ 0.03</td>\n",
       "      <td>0.097 $\\pm$ 0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>5.071 $\\pm$ 0.404</td>\n",
       "      <td>0.377</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.425 $\\pm$ 0.119</td>\n",
       "      <td>0.409 $\\pm$ 0.071</td>\n",
       "      <td>0.409 $\\pm$ 0.062</td>\n",
       "      <td>0.409 $\\pm$ 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5000</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.742 $\\pm$ 0.105</td>\n",
       "      <td>0.44 $\\pm$ 0.067</td>\n",
       "      <td>0.441 $\\pm$ 0.058</td>\n",
       "      <td>0.44 $\\pm$ 0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.927 $\\pm$ 0.032</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.997 $\\pm$ 0.003</td>\n",
       "      <td>-</td>\n",
       "      <td>0.955 $\\pm$ 0.113</td>\n",
       "      <td>0.901 $\\pm$ 0.141</td>\n",
       "      <td>0.874 $\\pm$ 0.144</td>\n",
       "      <td>0.842 $\\pm$ 0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.351 $\\pm$ 0.033</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.985 $\\pm$ 0.02</td>\n",
       "      <td>0.056 $\\pm$ 0.272</td>\n",
       "      <td>0.806 $\\pm$ 0.263</td>\n",
       "      <td>0.736 $\\pm$ 0.25</td>\n",
       "      <td>0.664 $\\pm$ 0.235</td>\n",
       "      <td>0.587 $\\pm$ 0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>6.553 $\\pm$ 6.838</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.988 $\\pm$ 0.012</td>\n",
       "      <td>0.061 $\\pm$ 0.286</td>\n",
       "      <td>0.827 $\\pm$ 0.25</td>\n",
       "      <td>0.757 $\\pm$ 0.236</td>\n",
       "      <td>0.691 $\\pm$ 0.223</td>\n",
       "      <td>0.619 $\\pm$ 0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.091 $\\pm$ 0.125</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.516 $\\pm$ 0.193</td>\n",
       "      <td>0.06 $\\pm$ 0.256</td>\n",
       "      <td>0.478 $\\pm$ 0.164</td>\n",
       "      <td>0.461 $\\pm$ 0.108</td>\n",
       "      <td>0.454 $\\pm$ 0.098</td>\n",
       "      <td>0.443 $\\pm$ 0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.724 $\\pm$ 0.077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461 $\\pm$ 0.358</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>0.833 $\\pm$ 0.208</td>\n",
       "      <td>0.783 $\\pm$ 0.214</td>\n",
       "      <td>0.72 $\\pm$ 0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>2.137 $\\pm$ 0.131</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.713 $\\pm$ 0.123</td>\n",
       "      <td>0.682 $\\pm$ 0.077</td>\n",
       "      <td>0.682 $\\pm$ 0.068</td>\n",
       "      <td>0.682 $\\pm$ 0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.808 $\\pm$ 0.197</td>\n",
       "      <td>0.598 $\\pm$ 0.123</td>\n",
       "      <td>0.598 $\\pm$ 0.107</td>\n",
       "      <td>0.598 $\\pm$ 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.255 $\\pm$ 0.083</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.886 $\\pm$ 0.028</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93 $\\pm$ 0.117</td>\n",
       "      <td>0.687 $\\pm$ 0.089</td>\n",
       "      <td>0.683 $\\pm$ 0.082</td>\n",
       "      <td>0.679 $\\pm$ 0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.416 $\\pm$ 0.051</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.608 $\\pm$ 0.135</td>\n",
       "      <td>0.023 $\\pm$ 0.215</td>\n",
       "      <td>0.525 $\\pm$ 0.398</td>\n",
       "      <td>0.229 $\\pm$ 0.119</td>\n",
       "      <td>0.224 $\\pm$ 0.108</td>\n",
       "      <td>0.217 $\\pm$ 0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>1.111 $\\pm$ 0.334</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.916 $\\pm$ 0.019</td>\n",
       "      <td>-0.133 $\\pm$ 0.268</td>\n",
       "      <td>0.749 $\\pm$ 0.209</td>\n",
       "      <td>0.526 $\\pm$ 0.129</td>\n",
       "      <td>0.512 $\\pm$ 0.12</td>\n",
       "      <td>0.497 $\\pm$ 0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.066 $\\pm$ 0.079</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.245 $\\pm$ 0.145</td>\n",
       "      <td>0.077 $\\pm$ 0.255</td>\n",
       "      <td>0.579 $\\pm$ 0.128</td>\n",
       "      <td>0.47 $\\pm$ 0.06</td>\n",
       "      <td>0.467 $\\pm$ 0.045</td>\n",
       "      <td>0.464 $\\pm$ 0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.64 $\\pm$ 0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319 $\\pm$ 0.384</td>\n",
       "      <td>0.746 $\\pm$ 0.146</td>\n",
       "      <td>0.189 $\\pm$ 0.063</td>\n",
       "      <td>0.181 $\\pm$ 0.05</td>\n",
       "      <td>0.173 $\\pm$ 0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>2.279 $\\pm$ 0.1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.513 $\\pm$ 0.147</td>\n",
       "      <td>0.51 $\\pm$ 0.084</td>\n",
       "      <td>0.51 $\\pm$ 0.072</td>\n",
       "      <td>0.51 $\\pm$ 0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5000</td>\n",
       "      <td>House 16</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.772 $\\pm$ 0.144</td>\n",
       "      <td>0.553 $\\pm$ 0.1</td>\n",
       "      <td>0.553 $\\pm$ 0.085</td>\n",
       "      <td>0.553 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>1.216 $\\pm$ 0.084</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.611 $\\pm$ 0.083</td>\n",
       "      <td>-</td>\n",
       "      <td>0.977 $\\pm$ 0.071</td>\n",
       "      <td>0.666 $\\pm$ 0.101</td>\n",
       "      <td>0.655 $\\pm$ 0.092</td>\n",
       "      <td>0.64 $\\pm$ 0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.872 $\\pm$ 0.213</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77 $\\pm$ 0.067</td>\n",
       "      <td>0.047 $\\pm$ 0.203</td>\n",
       "      <td>0.887 $\\pm$ 0.272</td>\n",
       "      <td>0.146 $\\pm$ 0.091</td>\n",
       "      <td>0.133 $\\pm$ 0.065</td>\n",
       "      <td>0.121 $\\pm$ 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>4.402 $\\pm$ 1.141</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.715 $\\pm$ 0.07</td>\n",
       "      <td>0.026 $\\pm$ 0.194</td>\n",
       "      <td>0.919 $\\pm$ 0.198</td>\n",
       "      <td>0.192 $\\pm$ 0.113</td>\n",
       "      <td>0.174 $\\pm$ 0.091</td>\n",
       "      <td>0.156 $\\pm$ 0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.103 $\\pm$ 0.124</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053 $\\pm$ 0.019</td>\n",
       "      <td>0.041 $\\pm$ 0.201</td>\n",
       "      <td>0.232 $\\pm$ 0.107</td>\n",
       "      <td>0.186 $\\pm$ 0.071</td>\n",
       "      <td>0.179 $\\pm$ 0.064</td>\n",
       "      <td>0.169 $\\pm$ 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>2.433 $\\pm$ 0.121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567 $\\pm$ 0.223</td>\n",
       "      <td>0.522 $\\pm$ 0.153</td>\n",
       "      <td>0.24 $\\pm$ 0.101</td>\n",
       "      <td>0.22 $\\pm$ 0.089</td>\n",
       "      <td>0.198 $\\pm$ 0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>2.754 $\\pm$ 0.078</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.619 $\\pm$ 0.1</td>\n",
       "      <td>0.61 $\\pm$ 0.058</td>\n",
       "      <td>0.609 $\\pm$ 0.051</td>\n",
       "      <td>0.609 $\\pm$ 0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5000</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.9 $\\pm$ 0.059</td>\n",
       "      <td>0.773 $\\pm$ 0.047</td>\n",
       "      <td>0.773 $\\pm$ 0.041</td>\n",
       "      <td>0.773 $\\pm$ 0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>1.186 $\\pm$ 0.405</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.985 $\\pm$ 0.017</td>\n",
       "      <td>-</td>\n",
       "      <td>0.926 $\\pm$ 0.151</td>\n",
       "      <td>0.739 $\\pm$ 0.147</td>\n",
       "      <td>0.731 $\\pm$ 0.136</td>\n",
       "      <td>0.721 $\\pm$ 0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.474 $\\pm$ 0.406</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-</td>\n",
       "      <td>0.268 $\\pm$ 0.612</td>\n",
       "      <td>0.806 $\\pm$ 0.282</td>\n",
       "      <td>0.433 $\\pm$ 0.154</td>\n",
       "      <td>0.421 $\\pm$ 0.141</td>\n",
       "      <td>0.408 $\\pm$ 0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>\\fire (LR)</td>\n",
       "      <td>1.994 $\\pm$ 1.839</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-</td>\n",
       "      <td>0.05 $\\pm$ 0.658</td>\n",
       "      <td>0.841 $\\pm$ 0.258</td>\n",
       "      <td>0.506 $\\pm$ 0.184</td>\n",
       "      <td>0.487 $\\pm$ 0.167</td>\n",
       "      <td>0.466 $\\pm$ 0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>LIME</td>\n",
       "      <td>0.069 $\\pm$ 0.096</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.078 $\\pm$ 0.047</td>\n",
       "      <td>0.01 $\\pm$ 0.668</td>\n",
       "      <td>0.423 $\\pm$ 0.195</td>\n",
       "      <td>0.328 $\\pm$ 0.144</td>\n",
       "      <td>0.32 $\\pm$ 0.132</td>\n",
       "      <td>0.312 $\\pm$ 0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>SHAP</td>\n",
       "      <td>1.095 $\\pm$ 0.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57 $\\pm$ 0.551</td>\n",
       "      <td>1.0 $\\pm$ 0.008</td>\n",
       "      <td>0.693 $\\pm$ 0.17</td>\n",
       "      <td>0.663 $\\pm$ 0.156</td>\n",
       "      <td>0.634 $\\pm$ 0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>1.823 $\\pm$ 0.181</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.713 $\\pm$ 0.115</td>\n",
       "      <td>0.7 $\\pm$ 0.073</td>\n",
       "      <td>0.7 $\\pm$ 0.065</td>\n",
       "      <td>0.7 $\\pm$ 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5000</td>\n",
       "      <td>Shuttle</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674</td>\n",
       "      <td>1.0 $\\pm$ 0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.868 $\\pm$ 0.117</td>\n",
       "      <td>0.751 $\\pm$ 0.079</td>\n",
       "      <td>0.75 $\\pm$ 0.069</td>\n",
       "      <td>0.75 $\\pm$ 0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Neighborhood Size    Dataset          Method          Total Time  \\\n",
       "2                 5000      Adult      \\fire (DT)   2.137 $\\pm$ 0.177   \n",
       "5                 5000      Adult     \\fire (SVM)   1.112 $\\pm$ 0.212   \n",
       "8                 5000      Adult      \\fire (LR)   2.054 $\\pm$ 0.629   \n",
       "11                5000      Adult            LIME   0.081 $\\pm$ 0.006   \n",
       "14                5000      Adult            SHAP   2.445 $\\pm$ 0.065   \n",
       "17                5000      Adult   Lore (Random)  13.242 $\\pm$ 0.564   \n",
       "20                5000      Adult  Lore (Genetic)                 NaN   \n",
       "23                5000  Covertype      \\fire (DT)   2.348 $\\pm$ 0.579   \n",
       "26                5000  Covertype     \\fire (SVM)   1.199 $\\pm$ 0.602   \n",
       "29                5000  Covertype      \\fire (LR)  17.707 $\\pm$ 9.385   \n",
       "32                5000  Covertype            LIME    0.112 $\\pm$ 0.11   \n",
       "35                5000  Covertype            SHAP  18.637 $\\pm$ 0.447   \n",
       "38                5000  Covertype   Lore (Random)   5.071 $\\pm$ 0.404   \n",
       "41                5000  Covertype  Lore (Genetic)                 NaN   \n",
       "44                5000      Dutch      \\fire (DT)   0.927 $\\pm$ 0.032   \n",
       "47                5000      Dutch     \\fire (SVM)   0.351 $\\pm$ 0.033   \n",
       "50                5000      Dutch      \\fire (LR)   6.553 $\\pm$ 6.838   \n",
       "53                5000      Dutch            LIME   0.091 $\\pm$ 0.125   \n",
       "56                5000      Dutch            SHAP   1.724 $\\pm$ 0.077   \n",
       "59                5000      Dutch   Lore (Random)   2.137 $\\pm$ 0.131   \n",
       "62                5000      Dutch  Lore (Genetic)                 NaN   \n",
       "65                5000   House 16      \\fire (DT)   2.255 $\\pm$ 0.083   \n",
       "68                5000   House 16     \\fire (SVM)   0.416 $\\pm$ 0.051   \n",
       "71                5000   House 16      \\fire (LR)   1.111 $\\pm$ 0.334   \n",
       "74                5000   House 16            LIME   0.066 $\\pm$ 0.079   \n",
       "77                5000   House 16            SHAP    1.64 $\\pm$ 0.049   \n",
       "80                5000   House 16   Lore (Random)     2.279 $\\pm$ 0.1   \n",
       "83                5000   House 16  Lore (Genetic)                 NaN   \n",
       "86                5000     Letter      \\fire (DT)   1.216 $\\pm$ 0.084   \n",
       "89                5000     Letter     \\fire (SVM)   0.872 $\\pm$ 0.213   \n",
       "92                5000     Letter      \\fire (LR)   4.402 $\\pm$ 1.141   \n",
       "95                5000     Letter            LIME   0.103 $\\pm$ 0.124   \n",
       "98                5000     Letter            SHAP   2.433 $\\pm$ 0.121   \n",
       "101               5000     Letter   Lore (Random)   2.754 $\\pm$ 0.078   \n",
       "104               5000     Letter  Lore (Genetic)                 NaN   \n",
       "107               5000    Shuttle      \\fire (DT)   1.186 $\\pm$ 0.405   \n",
       "110               5000    Shuttle     \\fire (SVM)   0.474 $\\pm$ 0.406   \n",
       "113               5000    Shuttle      \\fire (LR)   1.994 $\\pm$ 1.839   \n",
       "116               5000    Shuttle            LIME   0.069 $\\pm$ 0.096   \n",
       "119               5000    Shuttle            SHAP   1.095 $\\pm$ 0.051   \n",
       "122               5000    Shuttle   Lore (Random)   1.823 $\\pm$ 0.181   \n",
       "125               5000    Shuttle  Lore (Genetic)                 NaN   \n",
       "\n",
       "    Fidelity        Fid. Neigh.        Faithfulness          Stability  \\\n",
       "2      0.897   0.94 $\\pm$ 0.032                   -   0.92 $\\pm$ 0.148   \n",
       "5      0.529  0.518 $\\pm$ 0.177   0.012 $\\pm$ 0.122   0.727 $\\pm$ 0.34   \n",
       "8        0.9    0.98 $\\pm$ 0.01   0.003 $\\pm$ 0.211  0.469 $\\pm$ 0.224   \n",
       "11     0.926  0.729 $\\pm$ 0.017   0.064 $\\pm$ 0.177   0.055 $\\pm$ 0.02   \n",
       "14       NaN                NaN    0.515 $\\pm$ 0.16  0.406 $\\pm$ 0.196   \n",
       "17     0.652      1.0 $\\pm$ 0.0                   -  0.339 $\\pm$ 0.223   \n",
       "20     0.643      1.0 $\\pm$ 0.0                   -  0.546 $\\pm$ 0.175   \n",
       "23     0.842  0.854 $\\pm$ 0.028                   -   0.94 $\\pm$ 0.114   \n",
       "26     0.562  0.525 $\\pm$ 0.096  -0.023 $\\pm$ 0.195  0.547 $\\pm$ 0.381   \n",
       "29     0.854  0.865 $\\pm$ 0.029  -0.071 $\\pm$ 0.297   0.944 $\\pm$ 0.19   \n",
       "32     0.709  0.261 $\\pm$ 0.107  -0.109 $\\pm$ 0.281  0.612 $\\pm$ 0.046   \n",
       "35       NaN                NaN   0.519 $\\pm$ 0.313  0.182 $\\pm$ 0.067   \n",
       "38     0.377      1.0 $\\pm$ 0.0                   -  0.425 $\\pm$ 0.119   \n",
       "41     0.635      1.0 $\\pm$ 0.0                   -  0.742 $\\pm$ 0.105   \n",
       "44     0.996  0.997 $\\pm$ 0.003                   -  0.955 $\\pm$ 0.113   \n",
       "47     0.989   0.985 $\\pm$ 0.02   0.056 $\\pm$ 0.272  0.806 $\\pm$ 0.263   \n",
       "50     0.992  0.988 $\\pm$ 0.012   0.061 $\\pm$ 0.286   0.827 $\\pm$ 0.25   \n",
       "53     0.896  0.516 $\\pm$ 0.193    0.06 $\\pm$ 0.256  0.478 $\\pm$ 0.164   \n",
       "56       NaN                NaN   0.461 $\\pm$ 0.358      1.0 $\\pm$ 0.0   \n",
       "59     0.501      1.0 $\\pm$ 0.0                   -  0.713 $\\pm$ 0.123   \n",
       "62     0.501      1.0 $\\pm$ 0.0                   -  0.808 $\\pm$ 0.197   \n",
       "65     0.908  0.886 $\\pm$ 0.028                   -   0.93 $\\pm$ 0.117   \n",
       "68     0.678  0.608 $\\pm$ 0.135   0.023 $\\pm$ 0.215  0.525 $\\pm$ 0.398   \n",
       "71     0.936  0.916 $\\pm$ 0.019  -0.133 $\\pm$ 0.268  0.749 $\\pm$ 0.209   \n",
       "74     0.872  0.245 $\\pm$ 0.145   0.077 $\\pm$ 0.255  0.579 $\\pm$ 0.128   \n",
       "77       NaN                NaN   0.319 $\\pm$ 0.384  0.746 $\\pm$ 0.146   \n",
       "80      0.57      1.0 $\\pm$ 0.0                   -  0.513 $\\pm$ 0.147   \n",
       "83     0.611      1.0 $\\pm$ 0.0                   -  0.772 $\\pm$ 0.144   \n",
       "86     0.674  0.611 $\\pm$ 0.083                   -  0.977 $\\pm$ 0.071   \n",
       "89      0.82   0.77 $\\pm$ 0.067   0.047 $\\pm$ 0.203  0.887 $\\pm$ 0.272   \n",
       "92     0.778   0.715 $\\pm$ 0.07   0.026 $\\pm$ 0.194  0.919 $\\pm$ 0.198   \n",
       "95      0.04  0.053 $\\pm$ 0.019   0.041 $\\pm$ 0.201  0.232 $\\pm$ 0.107   \n",
       "98       NaN                NaN   0.567 $\\pm$ 0.223  0.522 $\\pm$ 0.153   \n",
       "101    0.043      1.0 $\\pm$ 0.0                   -    0.619 $\\pm$ 0.1   \n",
       "104    0.041      1.0 $\\pm$ 0.0                   -    0.9 $\\pm$ 0.059   \n",
       "107    0.991  0.985 $\\pm$ 0.017                   -  0.926 $\\pm$ 0.151   \n",
       "110    0.995                  -   0.268 $\\pm$ 0.612  0.806 $\\pm$ 0.282   \n",
       "113    0.993                  -    0.05 $\\pm$ 0.658  0.841 $\\pm$ 0.258   \n",
       "116    0.801  0.078 $\\pm$ 0.047    0.01 $\\pm$ 0.668  0.423 $\\pm$ 0.195   \n",
       "119      NaN                NaN    0.57 $\\pm$ 0.551    1.0 $\\pm$ 0.008   \n",
       "122     0.66      1.0 $\\pm$ 0.0                   -  0.713 $\\pm$ 0.115   \n",
       "125    0.674      1.0 $\\pm$ 0.0                   -  0.868 $\\pm$ 0.117   \n",
       "\n",
       "        Robustness K=5    Robustness K=10    Robustness K=20  \n",
       "2    0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  \n",
       "5    0.242 $\\pm$ 0.103   0.24 $\\pm$ 0.094  0.238 $\\pm$ 0.088  \n",
       "8    0.247 $\\pm$ 0.092  0.244 $\\pm$ 0.081   0.24 $\\pm$ 0.075  \n",
       "11   0.054 $\\pm$ 0.009  0.054 $\\pm$ 0.007  0.054 $\\pm$ 0.005  \n",
       "14   0.263 $\\pm$ 0.112  0.257 $\\pm$ 0.096  0.251 $\\pm$ 0.087  \n",
       "17   0.342 $\\pm$ 0.137  0.341 $\\pm$ 0.122  0.341 $\\pm$ 0.113  \n",
       "20   0.251 $\\pm$ 0.103  0.251 $\\pm$ 0.083  0.252 $\\pm$ 0.071  \n",
       "23   0.618 $\\pm$ 0.115  0.602 $\\pm$ 0.104  0.588 $\\pm$ 0.096  \n",
       "26   0.167 $\\pm$ 0.067  0.164 $\\pm$ 0.057  0.159 $\\pm$ 0.051  \n",
       "29   0.244 $\\pm$ 0.112  0.235 $\\pm$ 0.098  0.224 $\\pm$ 0.089  \n",
       "32   0.605 $\\pm$ 0.024   0.604 $\\pm$ 0.02  0.603 $\\pm$ 0.017  \n",
       "35   0.109 $\\pm$ 0.037   0.102 $\\pm$ 0.03  0.097 $\\pm$ 0.025  \n",
       "38   0.409 $\\pm$ 0.071  0.409 $\\pm$ 0.062  0.409 $\\pm$ 0.057  \n",
       "41    0.44 $\\pm$ 0.067  0.441 $\\pm$ 0.058   0.44 $\\pm$ 0.053  \n",
       "44   0.901 $\\pm$ 0.141  0.874 $\\pm$ 0.144  0.842 $\\pm$ 0.144  \n",
       "47    0.736 $\\pm$ 0.25  0.664 $\\pm$ 0.235  0.587 $\\pm$ 0.203  \n",
       "50   0.757 $\\pm$ 0.236  0.691 $\\pm$ 0.223  0.619 $\\pm$ 0.197  \n",
       "53   0.461 $\\pm$ 0.108  0.454 $\\pm$ 0.098  0.443 $\\pm$ 0.094  \n",
       "56   0.833 $\\pm$ 0.208  0.783 $\\pm$ 0.214    0.72 $\\pm$ 0.21  \n",
       "59   0.682 $\\pm$ 0.077  0.682 $\\pm$ 0.068  0.682 $\\pm$ 0.063  \n",
       "62   0.598 $\\pm$ 0.123  0.598 $\\pm$ 0.107    0.598 $\\pm$ 0.1  \n",
       "65   0.687 $\\pm$ 0.089  0.683 $\\pm$ 0.082  0.679 $\\pm$ 0.079  \n",
       "68   0.229 $\\pm$ 0.119  0.224 $\\pm$ 0.108  0.217 $\\pm$ 0.101  \n",
       "71   0.526 $\\pm$ 0.129   0.512 $\\pm$ 0.12  0.497 $\\pm$ 0.115  \n",
       "74     0.47 $\\pm$ 0.06  0.467 $\\pm$ 0.045  0.464 $\\pm$ 0.036  \n",
       "77   0.189 $\\pm$ 0.063   0.181 $\\pm$ 0.05  0.173 $\\pm$ 0.043  \n",
       "80    0.51 $\\pm$ 0.084   0.51 $\\pm$ 0.072   0.51 $\\pm$ 0.065  \n",
       "83     0.553 $\\pm$ 0.1  0.553 $\\pm$ 0.085  0.553 $\\pm$ 0.077  \n",
       "86   0.666 $\\pm$ 0.101  0.655 $\\pm$ 0.092   0.64 $\\pm$ 0.084  \n",
       "89   0.146 $\\pm$ 0.091  0.133 $\\pm$ 0.065   0.121 $\\pm$ 0.05  \n",
       "92   0.192 $\\pm$ 0.113  0.174 $\\pm$ 0.091  0.156 $\\pm$ 0.075  \n",
       "95   0.186 $\\pm$ 0.071  0.179 $\\pm$ 0.064  0.169 $\\pm$ 0.057  \n",
       "98    0.24 $\\pm$ 0.101   0.22 $\\pm$ 0.089  0.198 $\\pm$ 0.077  \n",
       "101   0.61 $\\pm$ 0.058  0.609 $\\pm$ 0.051  0.609 $\\pm$ 0.046  \n",
       "104  0.773 $\\pm$ 0.047  0.773 $\\pm$ 0.041  0.773 $\\pm$ 0.038  \n",
       "107  0.739 $\\pm$ 0.147  0.731 $\\pm$ 0.136  0.721 $\\pm$ 0.129  \n",
       "110  0.433 $\\pm$ 0.154  0.421 $\\pm$ 0.141  0.408 $\\pm$ 0.132  \n",
       "113  0.506 $\\pm$ 0.184  0.487 $\\pm$ 0.167  0.466 $\\pm$ 0.156  \n",
       "116  0.328 $\\pm$ 0.144   0.32 $\\pm$ 0.132  0.312 $\\pm$ 0.125  \n",
       "119   0.693 $\\pm$ 0.17  0.663 $\\pm$ 0.156  0.634 $\\pm$ 0.147  \n",
       "122    0.7 $\\pm$ 0.073    0.7 $\\pm$ 0.065     0.7 $\\pm$ 0.06  \n",
       "125  0.751 $\\pm$ 0.079   0.75 $\\pm$ 0.069   0.75 $\\pm$ 0.064  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[(df_merged[\"Neighborhood Size\"] == 5000.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_5000 = df_merged[df_merged[\"Neighborhood Size\"] == 5000.0]\n",
    "samples_1000 = df_merged[df_merged[\"Neighborhood Size\"] == 1000.0]\n",
    "samples_2500 = df_merged[df_merged[\"Neighborhood Size\"] == 2500.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Total Time & Fidelity & Fid. Neigh. & Faithfulness & Stability & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 2.137 $\\pm$ 0.177 & 0.897000 & 0.94 $\\pm$ 0.032 & - & 0.92 $\\pm$ 0.148 & 0.609 $\\pm$ 0.121 & 0.6 $\\pm$ 0.106 & 0.59 $\\pm$ 0.097 \\\\\n",
      "Adult & \\fire (SVM) & 1.112 $\\pm$ 0.212 & 0.529000 & 0.518 $\\pm$ 0.177 & 0.012 $\\pm$ 0.122 & 0.727 $\\pm$ 0.34 & 0.242 $\\pm$ 0.103 & 0.24 $\\pm$ 0.094 & 0.238 $\\pm$ 0.088 \\\\\n",
      "Adult & \\fire (LR) & 2.054 $\\pm$ 0.629 & 0.900000 & 0.98 $\\pm$ 0.01 & 0.003 $\\pm$ 0.211 & 0.469 $\\pm$ 0.224 & 0.247 $\\pm$ 0.092 & 0.244 $\\pm$ 0.081 & 0.24 $\\pm$ 0.075 \\\\\n",
      "Adult & LIME & 0.081 $\\pm$ 0.006 & 0.926 & 0.729 $\\pm$ 0.017 & 0.064 $\\pm$ 0.177 & 0.055 $\\pm$ 0.02 & 0.054 $\\pm$ 0.009 & 0.054 $\\pm$ 0.007 & 0.054 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & 2.445 $\\pm$ 0.065 & NaN & NaN & 0.515 $\\pm$ 0.16 & 0.406 $\\pm$ 0.196 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 13.242 $\\pm$ 0.564 & 0.652 & 1.0 $\\pm$ 0.0 & - & 0.339 $\\pm$ 0.223 & 0.342 $\\pm$ 0.137 & 0.341 $\\pm$ 0.122 & 0.341 $\\pm$ 0.113 \\\\\n",
      "Adult & Lore (Genetic) & NaN & 0.643000 & 1.0 $\\pm$ 0.0 & - & 0.546 $\\pm$ 0.175 & 0.251 $\\pm$ 0.103 & 0.251 $\\pm$ 0.083 & 0.252 $\\pm$ 0.071 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 2.348 $\\pm$ 0.579 & 0.842000 & 0.854 $\\pm$ 0.028 & - & 0.94 $\\pm$ 0.114 & 0.618 $\\pm$ 0.115 & 0.602 $\\pm$ 0.104 & 0.588 $\\pm$ 0.096 \\\\\n",
      "Covertype & \\fire (SVM) & 1.199 $\\pm$ 0.602 & 0.562000 & 0.525 $\\pm$ 0.096 & -0.023 $\\pm$ 0.195 & 0.547 $\\pm$ 0.381 & 0.167 $\\pm$ 0.067 & 0.164 $\\pm$ 0.057 & 0.159 $\\pm$ 0.051 \\\\\n",
      "Covertype & \\fire (LR) & 17.707 $\\pm$ 9.385 & 0.854000 & 0.865 $\\pm$ 0.029 & -0.071 $\\pm$ 0.297 & 0.944 $\\pm$ 0.19 & 0.244 $\\pm$ 0.112 & 0.235 $\\pm$ 0.098 & 0.224 $\\pm$ 0.089 \\\\\n",
      "Covertype & LIME & 0.112 $\\pm$ 0.11 & 0.709 & 0.261 $\\pm$ 0.107 & -0.109 $\\pm$ 0.281 & 0.612 $\\pm$ 0.046 & 0.605 $\\pm$ 0.024 & 0.604 $\\pm$ 0.02 & 0.603 $\\pm$ 0.017 \\\\\n",
      "Covertype & SHAP & 18.637 $\\pm$ 0.447 & NaN & NaN & 0.519 $\\pm$ 0.313 & 0.182 $\\pm$ 0.067 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 5.071 $\\pm$ 0.404 & 0.377 & 1.0 $\\pm$ 0.0 & - & 0.425 $\\pm$ 0.119 & 0.409 $\\pm$ 0.071 & 0.409 $\\pm$ 0.062 & 0.409 $\\pm$ 0.057 \\\\\n",
      "Covertype & Lore (Genetic) & NaN & 0.635000 & 1.0 $\\pm$ 0.0 & - & 0.742 $\\pm$ 0.105 & 0.44 $\\pm$ 0.067 & 0.441 $\\pm$ 0.058 & 0.44 $\\pm$ 0.053 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.927 $\\pm$ 0.032 & 0.996000 & 0.997 $\\pm$ 0.003 & - & 0.955 $\\pm$ 0.113 & 0.901 $\\pm$ 0.141 & 0.874 $\\pm$ 0.144 & 0.842 $\\pm$ 0.144 \\\\\n",
      "Dutch & \\fire (SVM) & 0.351 $\\pm$ 0.033 & 0.989000 & 0.985 $\\pm$ 0.02 & 0.056 $\\pm$ 0.272 & 0.806 $\\pm$ 0.263 & 0.736 $\\pm$ 0.25 & 0.664 $\\pm$ 0.235 & 0.587 $\\pm$ 0.203 \\\\\n",
      "Dutch & \\fire (LR) & 6.553 $\\pm$ 6.838 & 0.992000 & 0.988 $\\pm$ 0.012 & 0.061 $\\pm$ 0.286 & 0.827 $\\pm$ 0.25 & 0.757 $\\pm$ 0.236 & 0.691 $\\pm$ 0.223 & 0.619 $\\pm$ 0.197 \\\\\n",
      "Dutch & LIME & 0.091 $\\pm$ 0.125 & 0.896 & 0.516 $\\pm$ 0.193 & 0.06 $\\pm$ 0.256 & 0.478 $\\pm$ 0.164 & 0.461 $\\pm$ 0.108 & 0.454 $\\pm$ 0.098 & 0.443 $\\pm$ 0.094 \\\\\n",
      "Dutch & SHAP & 1.724 $\\pm$ 0.077 & NaN & NaN & 0.461 $\\pm$ 0.358 & 1.0 $\\pm$ 0.0 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 2.137 $\\pm$ 0.131 & 0.501 & 1.0 $\\pm$ 0.0 & - & 0.713 $\\pm$ 0.123 & 0.682 $\\pm$ 0.077 & 0.682 $\\pm$ 0.068 & 0.682 $\\pm$ 0.063 \\\\\n",
      "Dutch & Lore (Genetic) & NaN & 0.501000 & 1.0 $\\pm$ 0.0 & - & 0.808 $\\pm$ 0.197 & 0.598 $\\pm$ 0.123 & 0.598 $\\pm$ 0.107 & 0.598 $\\pm$ 0.1 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 2.255 $\\pm$ 0.083 & 0.908000 & 0.886 $\\pm$ 0.028 & - & 0.93 $\\pm$ 0.117 & 0.687 $\\pm$ 0.089 & 0.683 $\\pm$ 0.082 & 0.679 $\\pm$ 0.079 \\\\\n",
      "House 16 & \\fire (SVM) & 0.416 $\\pm$ 0.051 & 0.678000 & 0.608 $\\pm$ 0.135 & 0.023 $\\pm$ 0.215 & 0.525 $\\pm$ 0.398 & 0.229 $\\pm$ 0.119 & 0.224 $\\pm$ 0.108 & 0.217 $\\pm$ 0.101 \\\\\n",
      "House 16 & \\fire (LR) & 1.111 $\\pm$ 0.334 & 0.936000 & 0.916 $\\pm$ 0.019 & -0.133 $\\pm$ 0.268 & 0.749 $\\pm$ 0.209 & 0.526 $\\pm$ 0.129 & 0.512 $\\pm$ 0.12 & 0.497 $\\pm$ 0.115 \\\\\n",
      "House 16 & LIME & 0.066 $\\pm$ 0.079 & 0.872 & 0.245 $\\pm$ 0.145 & 0.077 $\\pm$ 0.255 & 0.579 $\\pm$ 0.128 & 0.47 $\\pm$ 0.06 & 0.467 $\\pm$ 0.045 & 0.464 $\\pm$ 0.036 \\\\\n",
      "House 16 & SHAP & 1.64 $\\pm$ 0.049 & NaN & NaN & 0.319 $\\pm$ 0.384 & 0.746 $\\pm$ 0.146 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 2.279 $\\pm$ 0.1 & 0.57 & 1.0 $\\pm$ 0.0 & - & 0.513 $\\pm$ 0.147 & 0.51 $\\pm$ 0.084 & 0.51 $\\pm$ 0.072 & 0.51 $\\pm$ 0.065 \\\\\n",
      "House 16 & Lore (Genetic) & NaN & 0.611000 & 1.0 $\\pm$ 0.0 & - & 0.772 $\\pm$ 0.144 & 0.553 $\\pm$ 0.1 & 0.553 $\\pm$ 0.085 & 0.553 $\\pm$ 0.077 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 1.216 $\\pm$ 0.084 & 0.674000 & 0.611 $\\pm$ 0.083 & - & 0.977 $\\pm$ 0.071 & 0.666 $\\pm$ 0.101 & 0.655 $\\pm$ 0.092 & 0.64 $\\pm$ 0.084 \\\\\n",
      "Letter & \\fire (SVM) & 0.872 $\\pm$ 0.213 & 0.820000 & 0.77 $\\pm$ 0.067 & 0.047 $\\pm$ 0.203 & 0.887 $\\pm$ 0.272 & 0.146 $\\pm$ 0.091 & 0.133 $\\pm$ 0.065 & 0.121 $\\pm$ 0.05 \\\\\n",
      "Letter & \\fire (LR) & 4.402 $\\pm$ 1.141 & 0.778000 & 0.715 $\\pm$ 0.07 & 0.026 $\\pm$ 0.194 & 0.919 $\\pm$ 0.198 & 0.192 $\\pm$ 0.113 & 0.174 $\\pm$ 0.091 & 0.156 $\\pm$ 0.075 \\\\\n",
      "Letter & LIME & 0.103 $\\pm$ 0.124 & 0.04 & 0.053 $\\pm$ 0.019 & 0.041 $\\pm$ 0.201 & 0.232 $\\pm$ 0.107 & 0.186 $\\pm$ 0.071 & 0.179 $\\pm$ 0.064 & 0.169 $\\pm$ 0.057 \\\\\n",
      "Letter & SHAP & 2.433 $\\pm$ 0.121 & NaN & NaN & 0.567 $\\pm$ 0.223 & 0.522 $\\pm$ 0.153 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 2.754 $\\pm$ 0.078 & 0.043 & 1.0 $\\pm$ 0.0 & - & 0.619 $\\pm$ 0.1 & 0.61 $\\pm$ 0.058 & 0.609 $\\pm$ 0.051 & 0.609 $\\pm$ 0.046 \\\\\n",
      "Letter & Lore (Genetic) & NaN & 0.041000 & 1.0 $\\pm$ 0.0 & - & 0.9 $\\pm$ 0.059 & 0.773 $\\pm$ 0.047 & 0.773 $\\pm$ 0.041 & 0.773 $\\pm$ 0.038 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 1.186 $\\pm$ 0.405 & 0.991000 & 0.985 $\\pm$ 0.017 & - & 0.926 $\\pm$ 0.151 & 0.739 $\\pm$ 0.147 & 0.731 $\\pm$ 0.136 & 0.721 $\\pm$ 0.129 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.474 $\\pm$ 0.406 & 0.995000 & - & 0.268 $\\pm$ 0.612 & 0.806 $\\pm$ 0.282 & 0.433 $\\pm$ 0.154 & 0.421 $\\pm$ 0.141 & 0.408 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 1.994 $\\pm$ 1.839 & 0.993000 & - & 0.05 $\\pm$ 0.658 & 0.841 $\\pm$ 0.258 & 0.506 $\\pm$ 0.184 & 0.487 $\\pm$ 0.167 & 0.466 $\\pm$ 0.156 \\\\\n",
      "Shuttle & LIME & 0.069 $\\pm$ 0.096 & 0.801 & 0.078 $\\pm$ 0.047 & 0.01 $\\pm$ 0.668 & 0.423 $\\pm$ 0.195 & 0.328 $\\pm$ 0.144 & 0.32 $\\pm$ 0.132 & 0.312 $\\pm$ 0.125 \\\\\n",
      "Shuttle & SHAP & 1.095 $\\pm$ 0.051 & NaN & NaN & 0.57 $\\pm$ 0.551 & 1.0 $\\pm$ 0.008 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 1.823 $\\pm$ 0.181 & 0.66 & 1.0 $\\pm$ 0.0 & - & 0.713 $\\pm$ 0.115 & 0.7 $\\pm$ 0.073 & 0.7 $\\pm$ 0.065 & 0.7 $\\pm$ 0.06 \\\\\n",
      "Shuttle & Lore (Genetic) & NaN & 0.674000 & 1.0 $\\pm$ 0.0 & - & 0.868 $\\pm$ 0.117 & 0.751 $\\pm$ 0.079 & 0.75 $\\pm$ 0.069 & 0.75 $\\pm$ 0.064 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_merged[df_merged[\"Neighborhood Size\"] == 5000.0].drop(columns=['Neighborhood Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Fidelity & Fid. Neigh. & Faithfulness & Stability & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.897000 & 0.931 $\\pm$ 0.037 & - & 0.898 $\\pm$ 0.167 & 0.586 $\\pm$ 0.126 & 0.575 $\\pm$ 0.111 & 0.564 $\\pm$ 0.102 \\\\\n",
      "Adult & \\fire (SVM) & 0.522000 & - & 0.01 $\\pm$ 0.112 & 0.859 $\\pm$ 0.258 & 0.296 $\\pm$ 0.107 & 0.292 $\\pm$ 0.099 & 0.288 $\\pm$ 0.093 \\\\\n",
      "Adult & \\fire (LR) & 0.846000 & 0.974 $\\pm$ 0.014 & 0.012 $\\pm$ 0.212 & 0.5 $\\pm$ 0.28 & 0.274 $\\pm$ 0.133 & 0.27 $\\pm$ 0.122 & 0.265 $\\pm$ 0.114 \\\\\n",
      "Adult & LIME & 0.903 & 0.729 $\\pm$ 0.017 & 0.064 $\\pm$ 0.18 & 0.046 $\\pm$ 0.018 & 0.046 $\\pm$ 0.009 & 0.046 $\\pm$ 0.006 & 0.046 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & NaN & NaN & 0.515 $\\pm$ 0.16 & 0.406 $\\pm$ 0.196 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 0.636 & 1.0 $\\pm$ 0.0 & - & 0.469 $\\pm$ 0.154 & 0.235 $\\pm$ 0.104 & 0.235 $\\pm$ 0.088 & 0.235 $\\pm$ 0.077 \\\\\n",
      "Adult & Lore (Genetic) & 0.669 & - & - & 0.301 $\\pm$ 0.235 & 0.299 $\\pm$ 0.143 & 0.299 $\\pm$ 0.127 & 0.299 $\\pm$ 0.118 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.840000 & 0.847 $\\pm$ 0.034 & - & 0.925 $\\pm$ 0.133 & 0.598 $\\pm$ 0.113 & 0.584 $\\pm$ 0.101 & 0.57 $\\pm$ 0.093 \\\\\n",
      "Covertype & \\fire (SVM) & 0.578000 & 0.546 $\\pm$ 0.104 & -0.025 $\\pm$ 0.216 & 0.554 $\\pm$ 0.369 & 0.176 $\\pm$ 0.074 & 0.171 $\\pm$ 0.063 & 0.165 $\\pm$ 0.056 \\\\\n",
      "Covertype & \\fire (LR) & 0.861000 & 0.866 $\\pm$ 0.033 & -0.069 $\\pm$ 0.308 & 0.946 $\\pm$ 0.188 & 0.243 $\\pm$ 0.122 & 0.233 $\\pm$ 0.109 & 0.221 $\\pm$ 0.099 \\\\\n",
      "Covertype & LIME & 0.712 & 0.261 $\\pm$ 0.107 & -0.099 $\\pm$ 0.278 & 0.603 $\\pm$ 0.043 & 0.598 $\\pm$ 0.023 & 0.597 $\\pm$ 0.019 & 0.596 $\\pm$ 0.017 \\\\\n",
      "Covertype & SHAP & NaN & NaN & 0.519 $\\pm$ 0.313 & 0.182 $\\pm$ 0.067 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.394 & 1.0 $\\pm$ 0.0 & - & 0.68 $\\pm$ 0.116 & 0.388 $\\pm$ 0.065 & 0.388 $\\pm$ 0.056 & 0.388 $\\pm$ 0.05 \\\\\n",
      "Covertype & Lore (Genetic) & 0.366 & - & - & 0.4 $\\pm$ 0.125 & 0.388 $\\pm$ 0.072 & 0.388 $\\pm$ 0.062 & 0.388 $\\pm$ 0.058 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.997000 & 0.997 $\\pm$ 0.004 & - & 0.967 $\\pm$ 0.099 & 0.903 $\\pm$ 0.144 & 0.876 $\\pm$ 0.149 & 0.845 $\\pm$ 0.151 \\\\\n",
      "Dutch & \\fire (SVM) & 0.994000 & 0.992 $\\pm$ 0.014 & 0.054 $\\pm$ 0.284 & 0.799 $\\pm$ 0.272 & 0.697 $\\pm$ 0.278 & 0.615 $\\pm$ 0.26 & 0.525 $\\pm$ 0.218 \\\\\n",
      "Dutch & \\fire (LR) & 0.994000 & 0.993 $\\pm$ 0.01 & 0.053 $\\pm$ 0.298 & 0.81 $\\pm$ 0.268 & 0.728 $\\pm$ 0.266 & 0.654 $\\pm$ 0.254 & 0.575 $\\pm$ 0.226 \\\\\n",
      "Dutch & LIME & 0.896 & 0.516 $\\pm$ 0.193 & 0.06 $\\pm$ 0.257 & 0.404 $\\pm$ 0.146 & 0.394 $\\pm$ 0.091 & 0.387 $\\pm$ 0.082 & 0.378 $\\pm$ 0.078 \\\\\n",
      "Dutch & SHAP & NaN & NaN & 0.461 $\\pm$ 0.358 & 1.0 $\\pm$ 0.0 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.501 & 1.0 $\\pm$ 0.0 & - & 0.771 $\\pm$ 0.224 & 0.561 $\\pm$ 0.134 & 0.56 $\\pm$ 0.118 & 0.561 $\\pm$ 0.108 \\\\\n",
      "Dutch & Lore (Genetic) & 0.502 & - & - & 0.692 $\\pm$ 0.131 & 0.667 $\\pm$ 0.082 & 0.668 $\\pm$ 0.074 & 0.668 $\\pm$ 0.069 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.900000 & 0.876 $\\pm$ 0.031 & - & 0.91 $\\pm$ 0.134 & 0.66 $\\pm$ 0.09 & 0.656 $\\pm$ 0.082 & 0.65 $\\pm$ 0.079 \\\\\n",
      "House 16 & \\fire (SVM) & 0.711000 & 0.61 $\\pm$ 0.126 & 0.023 $\\pm$ 0.215 & 0.557 $\\pm$ 0.396 & 0.246 $\\pm$ 0.135 & 0.24 $\\pm$ 0.126 & 0.232 $\\pm$ 0.118 \\\\\n",
      "House 16 & \\fire (LR) & 0.939000 & 0.916 $\\pm$ 0.021 & -0.141 $\\pm$ 0.261 & 0.788 $\\pm$ 0.204 & 0.536 $\\pm$ 0.132 & 0.522 $\\pm$ 0.12 & 0.504 $\\pm$ 0.113 \\\\\n",
      "House 16 & LIME & 0.875 & 0.245 $\\pm$ 0.145 & 0.071 $\\pm$ 0.257 & 0.534 $\\pm$ 0.124 & 0.463 $\\pm$ 0.058 & 0.46 $\\pm$ 0.044 & 0.458 $\\pm$ 0.035 \\\\\n",
      "House 16 & SHAP & NaN & NaN & 0.319 $\\pm$ 0.384 & 0.746 $\\pm$ 0.146 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.61 & 1.0 $\\pm$ 0.0 & - & 0.731 $\\pm$ 0.15 & 0.5 $\\pm$ 0.105 & 0.5 $\\pm$ 0.09 & 0.5 $\\pm$ 0.08 \\\\\n",
      "House 16 & Lore (Genetic) & 0.539 & - & - & 0.443 $\\pm$ 0.16 & 0.439 $\\pm$ 0.084 & 0.438 $\\pm$ 0.068 & 0.438 $\\pm$ 0.059 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.699000 & 0.61 $\\pm$ 0.098 & - & 0.963 $\\pm$ 0.091 & 0.63 $\\pm$ 0.105 & 0.617 $\\pm$ 0.096 & 0.601 $\\pm$ 0.087 \\\\\n",
      "Letter & \\fire (SVM) & 0.841000 & 0.774 $\\pm$ 0.074 & 0.044 $\\pm$ 0.208 & 0.86 $\\pm$ 0.297 & 0.135 $\\pm$ 0.093 & 0.122 $\\pm$ 0.066 & 0.111 $\\pm$ 0.049 \\\\\n",
      "Letter & \\fire (LR) & 0.817000 & 0.731 $\\pm$ 0.079 & 0.021 $\\pm$ 0.189 & 0.87 $\\pm$ 0.249 & 0.177 $\\pm$ 0.106 & 0.16 $\\pm$ 0.082 & 0.143 $\\pm$ 0.067 \\\\\n",
      "Letter & LIME & 0.04 & 0.053 $\\pm$ 0.019 & 0.035 $\\pm$ 0.204 & 0.195 $\\pm$ 0.1 & 0.163 $\\pm$ 0.062 & 0.157 $\\pm$ 0.055 & 0.151 $\\pm$ 0.049 \\\\\n",
      "Letter & SHAP & NaN & NaN & 0.567 $\\pm$ 0.223 & 0.522 $\\pm$ 0.153 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.044 & 1.0 $\\pm$ 0.0 & - & 0.864 $\\pm$ 0.067 & 0.746 $\\pm$ 0.051 & 0.746 $\\pm$ 0.045 & 0.745 $\\pm$ 0.042 \\\\\n",
      "Letter & Lore (Genetic) & 0.04 & - & - & 0.58 $\\pm$ 0.11 & 0.574 $\\pm$ 0.064 & 0.575 $\\pm$ 0.056 & 0.575 $\\pm$ 0.051 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.987000 & 0.984 $\\pm$ 0.021 & - & 0.925 $\\pm$ 0.151 & 0.756 $\\pm$ 0.154 & 0.747 $\\pm$ 0.144 & 0.737 $\\pm$ 0.14 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.992000 & - & 0.262 $\\pm$ 0.616 & 0.805 $\\pm$ 0.283 & 0.435 $\\pm$ 0.156 & 0.423 $\\pm$ 0.142 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 0.991000 & - & 0.054 $\\pm$ 0.657 & 0.835 $\\pm$ 0.262 & 0.51 $\\pm$ 0.185 & 0.49 $\\pm$ 0.167 & 0.468 $\\pm$ 0.155 \\\\\n",
      "Shuttle & LIME & 0.801 & 0.078 $\\pm$ 0.047 & -0.004 $\\pm$ 0.663 & 0.37 $\\pm$ 0.193 & 0.294 $\\pm$ 0.131 & 0.288 $\\pm$ 0.119 & 0.281 $\\pm$ 0.112 \\\\\n",
      "Shuttle & SHAP & NaN & NaN & 0.57 $\\pm$ 0.551 & 1.0 $\\pm$ 0.008 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.663 & 1.0 $\\pm$ 0.0 & - & 0.834 $\\pm$ 0.141 & 0.708 $\\pm$ 0.084 & 0.707 $\\pm$ 0.072 & 0.707 $\\pm$ 0.066 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.659 & - & - & 0.674 $\\pm$ 0.125 & 0.663 $\\pm$ 0.074 & 0.663 $\\pm$ 0.064 & 0.663 $\\pm$ 0.058 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_merged[df_merged[\"Neighborhood Size\"] == 2500].drop(columns=['Neighborhood Size', \"Total Time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "Dataset & Method & Fidelity & Fid. Neigh. & Faithfulness & Stability & Robustness K=5 & Robustness K=10 & Robustness K=20 \\\\\n",
      "\\midrule\n",
      "Adult & \\fire (DT) & 0.907000 & 0.918 $\\pm$ 0.04 & - & 0.845 $\\pm$ 0.23 & 0.397 $\\pm$ 0.122 & 0.375 $\\pm$ 0.104 & 0.358 $\\pm$ 0.098 \\\\\n",
      "Adult & \\fire (SVM) & 0.522000 & 0.514 $\\pm$ 0.175 & 0.019 $\\pm$ 0.117 & 0.861 $\\pm$ 0.267 & 0.261 $\\pm$ 0.097 & 0.259 $\\pm$ 0.084 & 0.257 $\\pm$ 0.081 \\\\\n",
      "Adult & \\fire (LR) & 0.895000 & 0.969 $\\pm$ 0.019 & -0.013 $\\pm$ 0.211 & 0.384 $\\pm$ 0.279 & 0.177 $\\pm$ 0.125 & 0.155 $\\pm$ 0.088 & 0.137 $\\pm$ 0.059 \\\\\n",
      "Adult & LIME & 0.908 & 0.729 $\\pm$ 0.017 & 0.066 $\\pm$ 0.18 & 0.04 $\\pm$ 0.017 & 0.04 $\\pm$ 0.008 & 0.04 $\\pm$ 0.006 & 0.04 $\\pm$ 0.005 \\\\\n",
      "Adult & SHAP & NaN & NaN & 0.515 $\\pm$ 0.16 & 0.406 $\\pm$ 0.196 & 0.263 $\\pm$ 0.112 & 0.257 $\\pm$ 0.096 & 0.251 $\\pm$ 0.087 \\\\\n",
      "Adult & Lore (Random) & 0.636 & 1.0 $\\pm$ 0.0 & - & 0.377 $\\pm$ 0.153 & 0.225 $\\pm$ 0.112 & 0.224 $\\pm$ 0.098 & 0.224 $\\pm$ 0.091 \\\\\n",
      "Adult & Lore (Genetic) & 0.666 & - & - & 0.222 $\\pm$ 0.252 & 0.221 $\\pm$ 0.143 & 0.221 $\\pm$ 0.124 & 0.222 $\\pm$ 0.112 \\\\\\midrule\n",
      "Covertype & \\fire (DT) & 0.834000 & 0.831 $\\pm$ 0.044 & - & 0.902 $\\pm$ 0.154 & 0.464 $\\pm$ 0.102 & 0.453 $\\pm$ 0.087 & 0.438 $\\pm$ 0.082 \\\\\n",
      "Covertype & \\fire (SVM) & 0.602000 & 0.571 $\\pm$ 0.12 & -0.078 $\\pm$ 0.262 & 0.57 $\\pm$ 0.343 & 0.127 $\\pm$ 0.046 & 0.121 $\\pm$ 0.041 & 0.114 $\\pm$ 0.04 \\\\\n",
      "Covertype & \\fire (LR) & 0.872000 & 0.867 $\\pm$ 0.041 & -0.039 $\\pm$ 0.328 & 0.696 $\\pm$ 0.365 & 0.101 $\\pm$ 0.063 & 0.093 $\\pm$ 0.043 & 0.085 $\\pm$ 0.03 \\\\\n",
      "Covertype & LIME & 0.714 & 0.261 $\\pm$ 0.107 & -0.101 $\\pm$ 0.274 & 0.597 $\\pm$ 0.04 & 0.592 $\\pm$ 0.022 & 0.591 $\\pm$ 0.018 & 0.591 $\\pm$ 0.016 \\\\\n",
      "Covertype & SHAP & NaN & NaN & 0.519 $\\pm$ 0.313 & 0.182 $\\pm$ 0.067 & 0.109 $\\pm$ 0.037 & 0.102 $\\pm$ 0.03 & 0.097 $\\pm$ 0.025 \\\\\n",
      "Covertype & Lore (Random) & 0.394 & 1.0 $\\pm$ 0.0 & - & 0.536 $\\pm$ 0.12 & 0.308 $\\pm$ 0.061 & 0.308 $\\pm$ 0.05 & 0.308 $\\pm$ 0.043 \\\\\n",
      "Covertype & Lore (Genetic) & 0.361 & - & - & 0.364 $\\pm$ 0.132 & 0.356 $\\pm$ 0.075 & 0.357 $\\pm$ 0.064 & 0.357 $\\pm$ 0.059 \\\\\\midrule\n",
      "Dutch & \\fire (DT) & 0.995000 & 0.996 $\\pm$ 0.006 & - & 0.965 $\\pm$ 0.114 & 0.628 $\\pm$ 0.24 & 0.597 $\\pm$ 0.215 & 0.551 $\\pm$ 0.186 \\\\\n",
      "Dutch & \\fire (SVM) & 0.997000 & 0.995 $\\pm$ 0.012 & 0.073 $\\pm$ 0.315 & 0.796 $\\pm$ 0.283 & 0.25 $\\pm$ 0.097 & 0.219 $\\pm$ 0.065 & 0.201 $\\pm$ 0.05 \\\\\n",
      "Dutch & \\fire (LR) & 0.997000 & 0.996 $\\pm$ 0.008 & 0.063 $\\pm$ 0.257 & 0.769 $\\pm$ 0.292 & 0.267 $\\pm$ 0.122 & 0.233 $\\pm$ 0.085 & 0.208 $\\pm$ 0.066 \\\\\n",
      "Dutch & LIME & 0.893 & 0.516 $\\pm$ 0.193 & 0.058 $\\pm$ 0.254 & 0.34 $\\pm$ 0.133 & 0.328 $\\pm$ 0.081 & 0.323 $\\pm$ 0.073 & 0.316 $\\pm$ 0.069 \\\\\n",
      "Dutch & SHAP & NaN & NaN & 0.461 $\\pm$ 0.358 & 1.0 $\\pm$ 0.0 & 0.833 $\\pm$ 0.208 & 0.783 $\\pm$ 0.214 & 0.72 $\\pm$ 0.21 \\\\\n",
      "Dutch & Lore (Random) & 0.501 & 1.0 $\\pm$ 0.0 & - & 0.733 $\\pm$ 0.255 & 0.5 $\\pm$ 0.151 & 0.499 $\\pm$ 0.132 & 0.5 $\\pm$ 0.12 \\\\\n",
      "Dutch & Lore (Genetic) & 0.501 & - & - & 0.641 $\\pm$ 0.157 & 0.625 $\\pm$ 0.098 & 0.625 $\\pm$ 0.087 & 0.625 $\\pm$ 0.082 \\\\\\midrule\n",
      "House 16 & \\fire (DT) & 0.899000 & 0.864 $\\pm$ 0.043 & - & 0.916 $\\pm$ 0.129 & 0.572 $\\pm$ 0.104 & 0.563 $\\pm$ 0.09 & 0.553 $\\pm$ 0.082 \\\\\n",
      "House 16 & \\fire (SVM) & 0.745000 & 0.631 $\\pm$ 0.12 & 0.005 $\\pm$ 0.196 & 0.531 $\\pm$ 0.393 & 0.175 $\\pm$ 0.079 & 0.166 $\\pm$ 0.074 & 0.155 $\\pm$ 0.063 \\\\\n",
      "House 16 & \\fire (LR) & 0.962000 & 0.947 $\\pm$ 0.026 & 0.091 $\\pm$ 0.236 & 0.68 $\\pm$ 0.244 & 0.35 $\\pm$ 0.111 & 0.33 $\\pm$ 0.094 & 0.309 $\\pm$ 0.078 \\\\\n",
      "House 16 & LIME & 0.882 & 0.245 $\\pm$ 0.145 & 0.07 $\\pm$ 0.255 & 0.498 $\\pm$ 0.119 & 0.452 $\\pm$ 0.054 & 0.45 $\\pm$ 0.041 & 0.449 $\\pm$ 0.032 \\\\\n",
      "House 16 & SHAP & NaN & NaN & 0.319 $\\pm$ 0.384 & 0.746 $\\pm$ 0.146 & 0.189 $\\pm$ 0.063 & 0.181 $\\pm$ 0.05 & 0.173 $\\pm$ 0.043 \\\\\n",
      "House 16 & Lore (Random) & 0.61 & 1.0 $\\pm$ 0.0 & - & 0.655 $\\pm$ 0.161 & 0.425 $\\pm$ 0.119 & 0.425 $\\pm$ 0.099 & 0.425 $\\pm$ 0.088 \\\\\n",
      "House 16 & Lore (Genetic) & 0.535 & - & - & 0.472 $\\pm$ 0.154 & 0.472 $\\pm$ 0.086 & 0.472 $\\pm$ 0.073 & 0.472 $\\pm$ 0.064 \\\\\\midrule\n",
      "Letter & \\fire (DT) & 0.709000 & 0.614 $\\pm$ 0.122 & - & 0.927 $\\pm$ 0.135 & 0.478 $\\pm$ 0.125 & 0.471 $\\pm$ 0.116 & 0.47 $\\pm$ 0.116 \\\\\n",
      "Letter & \\fire (SVM) & 0.862000 & 0.769 $\\pm$ 0.089 & 0.02 $\\pm$ 0.241 & 0.859 $\\pm$ 0.283 & 0.083 $\\pm$ 0.052 & 0.083 $\\pm$ 0.05 & 0.083 $\\pm$ 0.05 \\\\\n",
      "Letter & \\fire (LR) & 0.845000 & 0.752 $\\pm$ 0.095 & 0.0 $\\pm$ 0.188 & 0.629 $\\pm$ 0.313 & 0.089 $\\pm$ 0.048 & 0.087 $\\pm$ 0.046 & 0.087 $\\pm$ 0.046 \\\\\n",
      "Letter & LIME & 0.04 & 0.053 $\\pm$ 0.019 & 0.023 $\\pm$ 0.206 & 0.143 $\\pm$ 0.09 & 0.128 $\\pm$ 0.048 & 0.126 $\\pm$ 0.04 & 0.122 $\\pm$ 0.035 \\\\\n",
      "Letter & SHAP & NaN & NaN & 0.567 $\\pm$ 0.223 & 0.522 $\\pm$ 0.153 & 0.24 $\\pm$ 0.101 & 0.22 $\\pm$ 0.089 & 0.198 $\\pm$ 0.077 \\\\\n",
      "Letter & Lore (Random) & 0.044 & 1.0 $\\pm$ 0.0 & - & 0.764 $\\pm$ 0.085 & 0.669 $\\pm$ 0.06 & 0.668 $\\pm$ 0.053 & 0.668 $\\pm$ 0.05 \\\\\n",
      "Letter & Lore (Genetic) & 0.039 & - & - & 0.521 $\\pm$ 0.126 & 0.516 $\\pm$ 0.074 & 0.517 $\\pm$ 0.065 & 0.517 $\\pm$ 0.059 \\\\\\midrule\n",
      "Shuttle & \\fire (DT) & 0.985000 & 0.982 $\\pm$ 0.027 & - & 0.913 $\\pm$ 0.19 & 0.781 $\\pm$ 0.181 & 0.772 $\\pm$ 0.174 & 0.76 $\\pm$ 0.171 \\\\\n",
      "Shuttle & \\fire (SVM) & 0.988000 & 0.992 $\\pm$ 0.016 & 0.261 $\\pm$ 0.615 & 0.809 $\\pm$ 0.278 & 0.436 $\\pm$ 0.155 & 0.423 $\\pm$ 0.141 & 0.41 $\\pm$ 0.132 \\\\\n",
      "Shuttle & \\fire (LR) & 0.992000 & 0.987 $\\pm$ 0.022 & 0.049 $\\pm$ 0.659 & 0.839 $\\pm$ 0.26 & 0.507 $\\pm$ 0.185 & 0.487 $\\pm$ 0.166 & 0.466 $\\pm$ 0.155 \\\\\n",
      "Shuttle & LIME & 0.801 & 0.078 $\\pm$ 0.047 & 0.024 $\\pm$ 0.653 & 0.276 $\\pm$ 0.17 & 0.235 $\\pm$ 0.103 & 0.232 $\\pm$ 0.091 & 0.228 $\\pm$ 0.083 \\\\\n",
      "Shuttle & SHAP & NaN & NaN & 0.57 $\\pm$ 0.551 & 1.0 $\\pm$ 0.008 & 0.693 $\\pm$ 0.17 & 0.663 $\\pm$ 0.156 & 0.634 $\\pm$ 0.147 \\\\\n",
      "Shuttle & Lore (Random) & 0.663 & 1.0 $\\pm$ 0.0 & - & 0.755 $\\pm$ 0.172 & 0.627 $\\pm$ 0.096 & 0.627 $\\pm$ 0.082 & 0.627 $\\pm$ 0.075 \\\\\n",
      "Shuttle & Lore (Genetic) & 0.659 & - & - & 0.626 $\\pm$ 0.135 & 0.621 $\\pm$ 0.072 & 0.621 $\\pm$ 0.06 & 0.621 $\\pm$ 0.052 \\\\\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_fancy_table(df_merged[df_merged[\"Neighborhood Size\"] == 1000].drop(columns=['Neighborhood Size', \"Total Time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare dataframe for custom LaTeX output\n",
    "# df_grouped = df_merged.groupby('Dataset')\n",
    "\n",
    "# # Create a mapping for the method renaming\n",
    "# method_rename = {\n",
    "#     'Decision Tree': '\\\\fire (DT)',\n",
    "#     'SVM': '\\\\fire (SVM)',\n",
    "#     'Logistic Regr.': '\\\\fire (LR)',\n",
    "#     'LIME': 'LIME',\n",
    "#     'SHAP': 'SHAP',\n",
    "#     'Lore (Random)': 'Lore (Random)',\n",
    "#     'Lore (Genetic)': 'Lore (Genetic)'\n",
    "# }\n",
    "\n",
    "# # Start building the LaTeX table\n",
    "# latex_output = \"\\\\begin{tabular}{\" + \"l\" * len(df_merged.columns) + \"}\\n\"\n",
    "# latex_output += \"\\\\toprule\\n\"\n",
    "\n",
    "# # Add headers\n",
    "# latex_output += \" & \".join(df_merged.columns) + \" \\\\\\\\\\n\"\n",
    "# latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "# # Add rows with midrules between datasets\n",
    "# datasets = df_merged['Dataset'].unique()\n",
    "# for i, dataset in enumerate(datasets):\n",
    "#     group = df_grouped.get_group(dataset)\n",
    "    \n",
    "#     # Convert group dataframe to LaTeX rows but don't add to output yet\n",
    "#     rows_latex = group.to_latex(index=False, header=False)\n",
    "    \n",
    "#     # Extract just the rows part (not headers or table structure)\n",
    "#     rows_only = \"\\n\".join(rows_latex.split(\"\\n\")[3:-3])\n",
    "    \n",
    "#     # Apply the method renaming\n",
    "#     for old_method, new_method in method_rename.items():\n",
    "#         rows_only = rows_only.replace(old_method, new_method)\n",
    "    \n",
    "#     latex_output += rows_only\n",
    "    \n",
    "#     # Add midrule if not the last dataset\n",
    "#     if i < len(datasets) - 1:\n",
    "#         latex_output += \"\\\\midrule\\n\"\n",
    "\n",
    "# latex_output += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "\n",
    "# print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "map_method = {\n",
    "    r\"\\fire (DT)\": \"FIRE360 (DT)\",\n",
    "    r\"\\fire (SVM)\": \"FIRE360 (SVM)\",\n",
    "    r\"\\fire (LR)\": \"FIRE360 (LR)\",\n",
    "    \"LIME\": \"LIME\",\n",
    "    \"SHAP\": \"SHAP\",\n",
    "    \"Lore (Random)\": \"LORE (Random)\",\n",
    "    \"Lore (Genetic)\": \"LORE (Genetic)\"\n",
    "}\n",
    "def plot_metrics_per_dataset(df, metrics):\n",
    "    \"\"\"\n",
    "    Generate a plot for each dataset comparing different methods based on the selected metrics\n",
    "    against the Neighborhood Size.\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - metrics: List of metrics to plot (e.g., [\"Fidelity\", \"Stability\"]).\n",
    "    \"\"\"\n",
    "    # Ensure proper numeric conversion for Neighborhood Size\n",
    "    df[\"Neighborhood Size\"] = pd.to_numeric(df[\"Neighborhood Size\"], errors='coerce')\n",
    "    \n",
    "    # Extract unique datasets\n",
    "    datasets = df[\"Dataset\"].unique()\n",
    "    \n",
    "    # Define colors, markers, and styles\n",
    "    colors = [\"#FF774E\", \"#7c7787\", \"#53C4FE\", \"#70DDA8\", \"#dc68e4\", \"#755c51\", \"gray\"]\n",
    "    edge_colors = [\"#E45D22\", \"#5a5255\", \"#009EFF\", \"#00B977\", \"fuchsia\", \"#ae5a41\", \"black\"]\n",
    "    markers = ['o', 'd', 'v', 'h', 's', 'P', 'p']\n",
    "    \n",
    "    # Define the specific x values we want to display\n",
    "    x_ticks = [1000, 2500, 5000]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        # Change: plots stacked vertically, not side by side\n",
    "        fig, axes = plt.subplots(len(metrics), 1, figsize=(6, 5 * len(metrics)))\n",
    "        subset = df[df[\"Dataset\"] == dataset]\n",
    "        \n",
    "        if len(metrics) == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for ax_idx, (ax, metric) in enumerate(zip(axes, metrics)):\n",
    "            for i, method in enumerate(subset[\"Method\"].unique()):\n",
    "                method_subset = subset[subset[\"Method\"] == method]\n",
    "                \n",
    "                # Extract metric values and convert them to numerical format\n",
    "                y_values = method_subset[metric].astype(str).str.split(\" \").str[0]\n",
    "                y_values = pd.to_numeric(y_values, errors='coerce')\n",
    "                \n",
    "                # Sort values for smooth plotting\n",
    "                sorted_indices = np.argsort(method_subset[\"Neighborhood Size\"].values)\n",
    "                x_values = method_subset[\"Neighborhood Size\"].values[sorted_indices]\n",
    "                y_values = y_values.values[sorted_indices]\n",
    "                \n",
    "                ax.plot(x_values, y_values,\n",
    "                       marker=markers[i % len(markers)],\n",
    "                       markersize=11,\n",
    "                       linewidth=3,\n",
    "                       linestyle=\"--\",\n",
    "                       color=colors[i % len(colors)],\n",
    "                       markerfacecolor=colors[i % len(colors)],\n",
    "                       markeredgecolor=edge_colors[i % len(colors)],\n",
    "                       markeredgewidth=2,\n",
    "                       alpha=0.8,\n",
    "                       zorder=3,\n",
    "                       label=map_method[method])\n",
    "\n",
    "                \n",
    "                ax.set_title(f'', fontsize=20)\n",
    "                # Set x-axis label on all plots\n",
    "                ax.set_xlabel(\"Synthetic Data Size\", fontsize=22)\n",
    "                # Set y-axis label on all plots (metric-dependent)\n",
    "                ax.set_ylabel(metric, fontsize=22)\n",
    "                \n",
    "                # Set specific x-ticks\n",
    "                ax.set_xticks(x_ticks)\n",
    "                ax.set_xticklabels([str(x) for x in x_ticks])\n",
    "                ax.set_xlim(min(x_ticks) - 200, max(x_ticks) + 200)\n",
    "                \n",
    "                ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "                \n",
    "            # Let each plot have its own y-axis scale (plot-dependent)\n",
    "            ax.autoscale(axis='y')\n",
    "            # x ticks fontsize\n",
    "            ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "        # Add dataset name at the top of the plot with less space\n",
    "        fig.suptitle(str(dataset), fontsize=26, y=0.98)\n",
    "        \n",
    "        # Adjust layout to make room for the legend and suptitle\n",
    "        plt.tight_layout(rect=[0, 0.01, 1, 0.99])\n",
    "        \n",
    "        # Save the plot\n",
    "        os.makedirs('plots', exist_ok=True)\n",
    "        plot_filename = f'plots/{dataset}_metrics.png'\n",
    "        plt.savefig(plot_filename, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "plot_metrics_per_dataset(df_merged, [\"Fidelity\", \"Stability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Method</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Fid. Neigh.</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.918 $\\pm$ 0.04</td>\n",
       "      <td>-</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.931 $\\pm$ 0.037</td>\n",
       "      <td>-</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>2.137 $\\pm$ 0.177</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.94 $\\pm$ 0.032</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neighborhood Size Dataset      Method         Total Time Fidelity  \\\n",
       "0               1000   Adult  \\fire (DT)                NaN    0.907   \n",
       "1               2500   Adult  \\fire (DT)                NaN    0.897   \n",
       "2               5000   Adult  \\fire (DT)  2.137 $\\pm$ 0.177    0.897   \n",
       "\n",
       "         Fid. Neigh. Faithfulness          Stability     Robustness K=5  \\\n",
       "0   0.918 $\\pm$ 0.04            -   0.845 $\\pm$ 0.23  0.397 $\\pm$ 0.122   \n",
       "1  0.931 $\\pm$ 0.037            -  0.898 $\\pm$ 0.167  0.586 $\\pm$ 0.126   \n",
       "2   0.94 $\\pm$ 0.032            -   0.92 $\\pm$ 0.148  0.609 $\\pm$ 0.121   \n",
       "\n",
       "     Robustness K=10    Robustness K=20  \n",
       "0  0.375 $\\pm$ 0.104  0.358 $\\pm$ 0.098  \n",
       "1  0.575 $\\pm$ 0.111  0.564 $\\pm$ 0.102  \n",
       "2    0.6 $\\pm$ 0.106   0.59 $\\pm$ 0.097  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult', 'Covertype', 'Dutch', 'House 16', 'Letter', 'Shuttle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"Dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Neighborhood Size</th>\n",
       "      <th>Method</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Robustness K=5</th>\n",
       "      <th>Robustness K=10</th>\n",
       "      <th>Robustness K=20</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.845 $\\pm$ 0.23</td>\n",
       "      <td>-</td>\n",
       "      <td>0.397 $\\pm$ 0.122</td>\n",
       "      <td>0.375 $\\pm$ 0.104</td>\n",
       "      <td>0.358 $\\pm$ 0.098</td>\n",
       "      <td>Adult_\\fire (DT)1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.898 $\\pm$ 0.167</td>\n",
       "      <td>-</td>\n",
       "      <td>0.586 $\\pm$ 0.126</td>\n",
       "      <td>0.575 $\\pm$ 0.111</td>\n",
       "      <td>0.564 $\\pm$ 0.102</td>\n",
       "      <td>Adult_\\fire (DT)2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Adult</td>\n",
       "      <td>5000</td>\n",
       "      <td>\\fire (DT)</td>\n",
       "      <td>0.92 $\\pm$ 0.148</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609 $\\pm$ 0.121</td>\n",
       "      <td>0.6 $\\pm$ 0.106</td>\n",
       "      <td>0.59 $\\pm$ 0.097</td>\n",
       "      <td>Adult_\\fire (DT)5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adult</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.861 $\\pm$ 0.267</td>\n",
       "      <td>0.019 $\\pm$ 0.117</td>\n",
       "      <td>0.261 $\\pm$ 0.097</td>\n",
       "      <td>0.259 $\\pm$ 0.084</td>\n",
       "      <td>0.257 $\\pm$ 0.081</td>\n",
       "      <td>Adult_\\fire (SVM)1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adult</td>\n",
       "      <td>2500</td>\n",
       "      <td>\\fire (SVM)</td>\n",
       "      <td>0.859 $\\pm$ 0.258</td>\n",
       "      <td>0.01 $\\pm$ 0.112</td>\n",
       "      <td>0.296 $\\pm$ 0.107</td>\n",
       "      <td>0.292 $\\pm$ 0.099</td>\n",
       "      <td>0.288 $\\pm$ 0.093</td>\n",
       "      <td>Adult_\\fire (SVM)2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.834 $\\pm$ 0.141</td>\n",
       "      <td>-</td>\n",
       "      <td>0.708 $\\pm$ 0.084</td>\n",
       "      <td>0.707 $\\pm$ 0.072</td>\n",
       "      <td>0.707 $\\pm$ 0.066</td>\n",
       "      <td>Shuttle_Lore (Random)2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lore (Random)</td>\n",
       "      <td>0.713 $\\pm$ 0.115</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7 $\\pm$ 0.073</td>\n",
       "      <td>0.7 $\\pm$ 0.065</td>\n",
       "      <td>0.7 $\\pm$ 0.06</td>\n",
       "      <td>Shuttle_Lore (Random)5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>1000</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.626 $\\pm$ 0.135</td>\n",
       "      <td>-</td>\n",
       "      <td>0.621 $\\pm$ 0.072</td>\n",
       "      <td>0.621 $\\pm$ 0.06</td>\n",
       "      <td>0.621 $\\pm$ 0.052</td>\n",
       "      <td>Shuttle_Lore (Genetic)1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>2500</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.674 $\\pm$ 0.125</td>\n",
       "      <td>-</td>\n",
       "      <td>0.663 $\\pm$ 0.074</td>\n",
       "      <td>0.663 $\\pm$ 0.064</td>\n",
       "      <td>0.663 $\\pm$ 0.058</td>\n",
       "      <td>Shuttle_Lore (Genetic)2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lore (Genetic)</td>\n",
       "      <td>0.868 $\\pm$ 0.117</td>\n",
       "      <td>-</td>\n",
       "      <td>0.751 $\\pm$ 0.079</td>\n",
       "      <td>0.75 $\\pm$ 0.069</td>\n",
       "      <td>0.75 $\\pm$ 0.064</td>\n",
       "      <td>Shuttle_Lore (Genetic)5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Neighborhood Size          Method          Stability  \\\n",
       "63    Adult               1000      \\fire (DT)   0.845 $\\pm$ 0.23   \n",
       "64    Adult               2500      \\fire (DT)  0.898 $\\pm$ 0.167   \n",
       "65    Adult               5000      \\fire (DT)   0.92 $\\pm$ 0.148   \n",
       "66    Adult               1000     \\fire (SVM)  0.861 $\\pm$ 0.267   \n",
       "67    Adult               2500     \\fire (SVM)  0.859 $\\pm$ 0.258   \n",
       "..      ...                ...             ...                ...   \n",
       "58  Shuttle               2500   Lore (Random)  0.834 $\\pm$ 0.141   \n",
       "59  Shuttle               5000   Lore (Random)  0.713 $\\pm$ 0.115   \n",
       "60  Shuttle               1000  Lore (Genetic)  0.626 $\\pm$ 0.135   \n",
       "61  Shuttle               2500  Lore (Genetic)  0.674 $\\pm$ 0.125   \n",
       "62  Shuttle               5000  Lore (Genetic)  0.868 $\\pm$ 0.117   \n",
       "\n",
       "         Faithfulness     Robustness K=5    Robustness K=10  \\\n",
       "63                  -  0.397 $\\pm$ 0.122  0.375 $\\pm$ 0.104   \n",
       "64                  -  0.586 $\\pm$ 0.126  0.575 $\\pm$ 0.111   \n",
       "65                  -  0.609 $\\pm$ 0.121    0.6 $\\pm$ 0.106   \n",
       "66  0.019 $\\pm$ 0.117  0.261 $\\pm$ 0.097  0.259 $\\pm$ 0.084   \n",
       "67   0.01 $\\pm$ 0.112  0.296 $\\pm$ 0.107  0.292 $\\pm$ 0.099   \n",
       "..                ...                ...                ...   \n",
       "58                  -  0.708 $\\pm$ 0.084  0.707 $\\pm$ 0.072   \n",
       "59                  -    0.7 $\\pm$ 0.073    0.7 $\\pm$ 0.065   \n",
       "60                  -  0.621 $\\pm$ 0.072   0.621 $\\pm$ 0.06   \n",
       "61                  -  0.663 $\\pm$ 0.074  0.663 $\\pm$ 0.064   \n",
       "62                  -  0.751 $\\pm$ 0.079   0.75 $\\pm$ 0.069   \n",
       "\n",
       "      Robustness K=20                          id  \n",
       "63  0.358 $\\pm$ 0.098        Adult_\\fire (DT)1000  \n",
       "64  0.564 $\\pm$ 0.102        Adult_\\fire (DT)2500  \n",
       "65   0.59 $\\pm$ 0.097        Adult_\\fire (DT)5000  \n",
       "66  0.257 $\\pm$ 0.081       Adult_\\fire (SVM)1000  \n",
       "67  0.288 $\\pm$ 0.093       Adult_\\fire (SVM)2500  \n",
       "..                ...                         ...  \n",
       "58  0.707 $\\pm$ 0.066   Shuttle_Lore (Random)2500  \n",
       "59     0.7 $\\pm$ 0.06   Shuttle_Lore (Random)5000  \n",
       "60  0.621 $\\pm$ 0.052  Shuttle_Lore (Genetic)1000  \n",
       "61  0.663 $\\pm$ 0.058  Shuttle_Lore (Genetic)2500  \n",
       "62   0.75 $\\pm$ 0.064  Shuttle_Lore (Genetic)5000  \n",
       "\n",
       "[126 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_robustness_per_dataset(df_metrics):\n",
    "    # Create the plots directory if it doesn't exist\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    # Get the unique datasets and define top_k values\n",
    "    datasets = df_metrics['Dataset'].unique()\n",
    "    top_k = [3, 5, 8, 10, 20]\n",
    "    \n",
    "    # Define a color-blind-friendly palette and markers\n",
    "    colors = [\"#FF774E\", \"#7c7787\", \"#53C4FE\", \"#70DDA8\", \"#dc68e4\", \"#755c51\", \"gray\"]\n",
    "    edge_colors = [\"#E45D22\", \"#5a5255\", \"#009EFF\", \"#00B977\", \"fuchsia\", \"#ae5a41\", \"black\"]\n",
    "    markers = ['o', 'd', 'v', 'h', 's', 'P', 'p']\n",
    "#     'D', '^', 'v', 'P', '*', 'X', 'p', 'h']  # Different markers\n",
    "    \n",
    "    # Create a single figure with subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 15), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    handles, labels = [], []\n",
    "    \n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        ax = axes[idx]\n",
    "        subset = df_metrics[df_metrics['Dataset'] == dataset]\n",
    "        \n",
    "        for i, method in enumerate(subset['Method'].unique()):\n",
    "            method_subset = subset[subset['Method'] == method]\n",
    "            robustness_values = []\n",
    "            \n",
    "            for k in top_k:\n",
    "                value = method_subset[f'Robustness K={k}'].values[0]\n",
    "                robustness_value = float(str(value).split(' ')[0])  # Ensure extraction is robust\n",
    "                robustness_values.append(robustness_value)\n",
    "            \n",
    "            line, = ax.plot(top_k, \n",
    "                            robustness_values,\n",
    "                            marker=markers[i % len(markers)],\n",
    "                            markersize=20, \n",
    "                            linewidth=3, \n",
    "                            linestyle=\"--\",\n",
    "                            color=colors[i % len(colors)],\n",
    "                            markerfacecolor=colors[i % len(colors)], \n",
    "                            markeredgecolor=edge_colors[i % len(colors)], \n",
    "                            markeredgewidth=2,\n",
    "                            alpha=0.8, zorder=3)\n",
    "            if idx == 0:  # Collect legend elements only once\n",
    "                handles.append(line)\n",
    "                labels.append(method)\n",
    "        \n",
    "        ax.set_title(f'{dataset}', fontsize=25, fontweight='bold')\n",
    "        ax.set_xlabel('K', fontsize=25)\n",
    "        ax.set_ylabel('Robustness', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "    \n",
    "    # Add external legend below plots\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.02), ncol=3, fontsize=20, frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('plots/robustness_all_datasets.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Call the function with df_metrics_complete\n",
    "plot_robustness_per_dataset(df_metrics_all_the_robustness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = download_runs(project_name=\"tango_generation\")\n",
    "project_name = \"tango_generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project_data[\"generated_dataset_size_10000_epochs_5000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distant_values_probability</th>\n",
       "      <th>kmap</th>\n",
       "      <th>_step</th>\n",
       "      <th>identifiability_score</th>\n",
       "      <th>max_mean_discrepancy</th>\n",
       "      <th>xgb_gt</th>\n",
       "      <th>gmm</th>\n",
       "      <th>close_values_probability</th>\n",
       "      <th>ks_test</th>\n",
       "      <th>common_rows_proportion</th>\n",
       "      <th>...</th>\n",
       "      <th>k_anonymization_gt</th>\n",
       "      <th>xgb_syn_ood</th>\n",
       "      <th>wasserstein_dist</th>\n",
       "      <th>mlp</th>\n",
       "      <th>l_diversity_syn</th>\n",
       "      <th>k_anonymization_syn</th>\n",
       "      <th>dataset</th>\n",
       "      <th>epochs</th>\n",
       "      <th>synthesizer</th>\n",
       "      <th>samples_to_generate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>417.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>letter</td>\n",
       "      <td>5000</td>\n",
       "      <td>tvae</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   distant_values_probability   kmap  _step  identifiability_score  \\\n",
       "0                         NaN    NaN      0                    NaN   \n",
       "1                    0.000313    NaN      1                    NaN   \n",
       "2                         NaN    NaN      2                    NaN   \n",
       "3                         NaN    NaN      3                    NaN   \n",
       "4                         NaN    NaN      4                    NaN   \n",
       "5                         NaN  164.0      5               0.008937   \n",
       "\n",
       "   max_mean_discrepancy    xgb_gt       gmm  close_values_probability  \\\n",
       "0                   NaN       NaN       NaN                       NaN   \n",
       "1                   NaN       NaN       NaN                  0.480187   \n",
       "2              0.000194       NaN       NaN                       NaN   \n",
       "3                   NaN  0.999036       NaN                       NaN   \n",
       "4                   NaN       NaN  0.530612                       NaN   \n",
       "5                   NaN       NaN       NaN                       NaN   \n",
       "\n",
       "    ks_test  common_rows_proportion  ...  k_anonymization_gt  xgb_syn_ood  \\\n",
       "0       NaN                     NaN  ...                 NaN          NaN   \n",
       "1       NaN                     0.0  ...                 NaN          NaN   \n",
       "2  0.953315                     NaN  ...                 NaN          NaN   \n",
       "3       NaN                     NaN  ...                 NaN     0.786037   \n",
       "4       NaN                     NaN  ...                 NaN          NaN   \n",
       "5       NaN                     NaN  ...               417.0          NaN   \n",
       "\n",
       "   wasserstein_dist      mlp  l_diversity_syn  k_anonymization_syn  dataset  \\\n",
       "0               NaN      NaN              NaN                  NaN   letter   \n",
       "1               NaN      NaN              NaN                  NaN   letter   \n",
       "2          0.499363      NaN              NaN                  NaN   letter   \n",
       "3               NaN      NaN              NaN                  NaN   letter   \n",
       "4               NaN  0.48976              NaN                  NaN   letter   \n",
       "5               NaN      NaN            417.0                417.0   letter   \n",
       "\n",
       "   epochs  synthesizer  samples_to_generate  \n",
       "0    5000         tvae                10000  \n",
       "1    5000         tvae                10000  \n",
       "2    5000         tvae                10000  \n",
       "3    5000         tvae                10000  \n",
       "4    5000         tvae                10000  \n",
       "5    5000         tvae                10000  \n",
       "\n",
       "[6 rows x 34 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data[\"generated_dataset_size_10000_epochs_5000\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rows_remove_nan(rows_list):\n",
    "    \"\"\"\n",
    "    Merge multiple rows from a dataset, keeping only non-NaN values for each column.\n",
    "    \n",
    "    Args:\n",
    "        rows_list: List of dataframes or series to merge\n",
    "        \n",
    "    Returns:\n",
    "        A single pandas Series with merged non-NaN values\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary to store the merged values\n",
    "    merged_dict = {}\n",
    "    \n",
    "    # Process each row\n",
    "    for index, row in rows_list.iterrows():\n",
    "        # For each column in the row\n",
    "        for col in row.index:\n",
    "            # If the value is not NaN and the column is not already in the merged_dict\n",
    "            # or the column is in merged_dict but the current value is not NaN\n",
    "            if not pd.isna(row[col]) and (col not in merged_dict or pd.isna(merged_dict.get(col))):\n",
    "                merged_dict[col] = row[col]\n",
    "    \n",
    "    # Convert the dictionary to a pandas Series\n",
    "    return pd.Series(merged_dict)\n",
    "\n",
    "# # Apply the function to merge rows\n",
    "# merged_row = merge_rows_remove_nan(project_data[\"generated_dataset_size_10000_epochs_5000\"][0])\n",
    "\n",
    "# # Display the merged row\n",
    "# print(merged_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pr in project_data[\"generated_dataset_size_10000_epochs_5000\"]:\n",
    "#     print(pr[\"synthesizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_data[project_data[\"Dataset\"] == \"dutch\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "dataset_sizes = [10000, 25000, 50000, 75000, 100000, 150000, 200000]\n",
    "epochs = [1000, 2500, 5000]\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}   \n",
    "    for dataset_size in dataset_sizes:\n",
    "        for epoch in epochs:\n",
    "            experiment_name = f\"generated_dataset_size_{dataset_size}_epochs_{epoch}\"\n",
    "            if experiment_name in project_data:\n",
    "                results = project_data[f\"generated_dataset_size_{dataset_size}_epochs_{epoch}\"]\n",
    "                for result in results:\n",
    "                    if len(result[\"dataset\"]) > 0 and result[\"dataset\"][0] == dataset:\n",
    "                        if \"synthesizer\" in result:\n",
    "                            result = merge_rows_remove_nan(result)\n",
    "                            \n",
    "                            synthesizer = result.get(\"synthesizer\", None)\n",
    "                            # if dataset == \"adult\":\n",
    "                                # print(synthesizer)\n",
    "                            common_rows_proportion = result.get(\"common_rows_proportion\", 0)\n",
    "                            close_values_probability = result.get(\"close_values_probability\", 0)\n",
    "\n",
    "                            xgb_gt = result.get(\"xgb_gt\", 0)\n",
    "\n",
    "                            xgb = result.get(\"xgb\", 0)\n",
    "                            linear = result.get(\"linear\", 0)\n",
    "                            mlp = result.get(\"mlp\", 0)\n",
    "\n",
    "                            chi_squared_test = result.get(\"chi_squared_test\", 0)\n",
    "\n",
    "                            k_anonymization_syn = result.get(\"k_anonymization_syn\", 0)\n",
    "                            identifiability_score = result.get(\"identifiability_score\", 0)\n",
    "\n",
    "                            metrics[dataset][experiment_name] = {} if experiment_name not in metrics[dataset] else metrics[dataset][experiment_name]\n",
    "\n",
    "                            metrics[dataset][experiment_name][synthesizer] = {\n",
    "                                \"Common Rows Proportion\": round(common_rows_proportion, 4),\n",
    "                                \"Close Values Probability\": round(close_values_probability, 3),\n",
    "                                \"xgb_gt\": round(xgb_gt, 3),\n",
    "                                \"Linear\": round(linear, 3),\n",
    "                                \"XGB\": round(xgb, 3),\n",
    "                                \"MLP\": round(xgb, 3),\n",
    "                                \"Chi Squared Test\": round(chi_squared_test, 3),\n",
    "\n",
    "                                \"K-Anonymization\": round(k_anonymization_syn, 3),\n",
    "                                \"Identifiability Score\": round(identifiability_score, 3),\n",
    "                                \n",
    "                                \"Synthesizer\": synthesizer,\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the metrics to a DataFrame\n",
    "rows = []\n",
    "for dataset in datasets:\n",
    "    for dataset_size in dataset_sizes:\n",
    "        for epoch in epochs:\n",
    "            for synthesizer in [\"ctgan\", \"tvae\"]:\n",
    "                experiment_name = f\"generated_dataset_size_{dataset_size}_epochs_{epoch}\"\n",
    "                if experiment_name in metrics[dataset] and synthesizer in metrics[dataset][experiment_name]:\n",
    "                    row = {\n",
    "                        'Dataset': dataset,\n",
    "                        'Generated Samples': dataset_size,\n",
    "                        'Epochs': epoch,\n",
    "                        \"Synthesizer\": synthesizer,\n",
    "                        # Sanity\n",
    "                        'Com. Rows Prop.': metrics[dataset][experiment_name][synthesizer]['Common Rows Proportion'],\n",
    "                        'Close Val. Prob.': metrics[dataset][experiment_name][synthesizer]['Close Values Probability'],\n",
    "\n",
    "                        # Statistical\n",
    "                        \"Chi Squar. Test.\": metrics[dataset][experiment_name][synthesizer]['Chi Squared Test'],\n",
    "                        # Performance\n",
    "                        \"XGB Perf.\": metrics[dataset][experiment_name][synthesizer]['xgb_gt'],\n",
    "                        # Detection\n",
    "                        \"MLP Det.\": metrics[dataset][experiment_name][synthesizer]['MLP'],\n",
    "                        \"Lin. Det.\": metrics[dataset][experiment_name][synthesizer]['Linear'],\n",
    "                        \"XGB Det.\": metrics[dataset][experiment_name][synthesizer]['XGB'],\n",
    "                        # Privacy\n",
    "                        \"K Anon.\": metrics[dataset][experiment_name][synthesizer]['K-Anonymization'],\n",
    "                        'Id. Score': metrics[dataset][experiment_name][synthesizer]['Identifiability Score'],\n",
    "                        \n",
    "                    }\n",
    "                    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the rows\n",
    "df_metrics = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_mapping = {\n",
    "    'adult': 'Adult',\n",
    "    'house16': 'House16',\n",
    "    'letter': 'Letter',\n",
    "    'dutch': 'Dutch',\n",
    "    'covertype': 'Covertype',\n",
    "    'shuttle': 'Shuttle'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Method column\n",
    "df_metrics[\"Dataset\"] = df_metrics[\"Dataset\"].map(dataset_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = df_metrics.round(3).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "Adult & 10000 & 1000 & ctgan & 0.0 & 0.999 & 0.858 & 0.924 & 1.0 & 0.999 & 1.0 & 24.0 & 0.0 \\\\\n",
      "Adult & 10000 & 1000 & tvae & 0.0 & 0.995 & 0.757 & 0.924 & 1.0 & 0.999 & 1.0 & 2.0 & 0.0 \\\\\n",
      "Adult & 10000 & 2500 & ctgan & 0.0 & 0.998 & 0.908 & 0.924 & 1.0 & 0.998 & 1.0 & 166.0 & 0.0 \\\\\n",
      "Adult & 10000 & 2500 & tvae & 0.0 & 1.0 & 0.846 & 0.924 & 1.0 & 0.999 & 1.0 & 2.0 & 0.0 \\\\\n",
      "Adult & 10000 & 5000 & ctgan & 0.0 & 0.997 & 0.912 & 0.924 & 1.0 & 0.999 & 1.0 & 102.0 & 0.0 \\\\\n",
      "Adult & 10000 & 5000 & tvae & 0.0 & 0.999 & 0.901 & 0.924 & 1.0 & 0.999 & 1.0 & 22.0 & 0.0 \\\\\n",
      "Adult & 25000 & 1000 & ctgan & 0.0 & 0.999 & 0.858 & 0.924 & 1.0 & 0.999 & 1.0 & 76.0 & 0.0 \\\\\n",
      "Adult & 25000 & 1000 & tvae & 0.0 & 1.0 & 0.768 & 0.924 & 1.0 & 0.999 & 1.0 & 16.0 & 0.0 \\\\\n",
      "Adult & 25000 & 2500 & ctgan & 0.0 & 0.998 & 0.908 & 0.924 & 1.0 & 0.998 & 1.0 & 325.0 & 0.0 \\\\\n",
      "Adult & 25000 & 2500 & tvae & 0.0 & 1.0 & 0.88 & 0.924 & 1.0 & 0.999 & 1.0 & 10.0 & 0.0 \\\\\n",
      "Adult & 25000 & 5000 & ctgan & 0.0 & 0.997 & 0.911 & 0.924 & 1.0 & 0.999 & 1.0 & 380.0 & 0.0 \\\\\n",
      "Adult & 25000 & 5000 & tvae & 0.0 & 1.0 & 0.907 & 0.924 & 1.0 & 0.999 & 1.0 & 22.0 & 0.0 \\\\\n",
      "Adult & 50000 & 1000 & ctgan & 0.0 & 0.999 & 0.857 & 0.924 & 1.0 & 0.998 & 1.0 & 151.0 & 0.0 \\\\\n",
      "Adult & 50000 & 1000 & tvae & 0.0 & 1.0 & 0.829 & 0.924 & 1.0 & 0.999 & 1.0 & 28.0 & 0.0 \\\\\n",
      "Adult & 50000 & 2500 & ctgan & 0.0 & 0.998 & 0.907 & 0.924 & 1.0 & 0.998 & 1.0 & 601.0 & 0.0 \\\\\n",
      "Adult & 50000 & 2500 & tvae & 0.0 & 1.0 & 0.897 & 0.924 & 1.0 & 0.998 & 1.0 & 13.0 & 0.0 \\\\\n",
      "Adult & 50000 & 5000 & ctgan & 0.0 & 0.997 & 0.911 & 0.924 & 1.0 & 0.999 & 1.0 & 723.0 & 0.0 \\\\\n",
      "Adult & 50000 & 5000 & tvae & 0.0 & 1.0 & 0.918 & 0.924 & 1.0 & 0.999 & 1.0 & 56.0 & 0.0 \\\\\n",
      "Adult & 75000 & 1000 & ctgan & 0.0 & 0.999 & 0.858 & 0.924 & 1.0 & 0.999 & 1.0 & 205.0 & 0.0 \\\\\n",
      "Adult & 75000 & 1000 & tvae & 0.0 & 0.995 & 0.844 & 0.924 & 1.0 & 0.998 & 1.0 & 46.0 & 0.0 \\\\\n",
      "Adult & 75000 & 2500 & ctgan & 0.0 & 0.998 & 0.908 & 0.924 & 1.0 & 0.998 & 1.0 & 818.0 & 0.0 \\\\\n",
      "Adult & 75000 & 2500 & tvae & 0.0 & 0.995 & 0.915 & 0.924 & 1.0 & 0.999 & 1.0 & 3.0 & 0.0 \\\\\n",
      "Adult & 75000 & 5000 & ctgan & 0.0 & 0.997 & 0.911 & 0.924 & 1.0 & 0.998 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 75000 & 5000 & tvae & 0.0 & 1.0 & 0.925 & 0.924 & 1.0 & 0.999 & 1.0 & 218.0 & 0.0 \\\\\n",
      "Adult & 100000 & 1000 & ctgan & 0.0 & 0.999 & 0.857 & 0.924 & 1.0 & 0.999 & 1.0 & 226.0 & 0.0 \\\\\n",
      "Adult & 100000 & 1000 & tvae & 0.0 & 0.995 & 0.86 & 0.924 & 1.0 & 0.999 & 1.0 & 44.0 & 0.0 \\\\\n",
      "Adult & 100000 & 2500 & ctgan & 0.0 & 0.998 & 0.908 & 0.924 & 1.0 & 0.998 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 100000 & 2500 & tvae & 0.0 & 1.0 & 0.915 & 0.924 & 1.0 & 0.999 & 1.0 & 21.0 & 0.0 \\\\\n",
      "Adult & 100000 & 5000 & ctgan & 0.0 & 0.997 & 0.91 & 0.924 & 1.0 & 0.999 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 100000 & 5000 & tvae & 0.0 & 1.0 & 0.925 & 0.924 & 1.0 & 0.999 & 1.0 & 373.0 & 0.0 \\\\\n",
      "Adult & 150000 & 1000 & ctgan & 0.0 & 0.999 & 0.857 & 0.924 & 1.0 & 0.999 & 1.0 & 405.0 & 0.0 \\\\\n",
      "Adult & 150000 & 1000 & tvae & 0.0 & 0.995 & 0.858 & 0.924 & 1.0 & 0.998 & 1.0 & 40.0 & 0.0 \\\\\n",
      "Adult & 150000 & 2500 & ctgan & 0.0 & 0.999 & 0.908 & 0.924 & 1.0 & 0.997 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 150000 & 2500 & tvae & 0.0 & 1.0 & 0.914 & 0.924 & 1.0 & 0.999 & 1.0 & 23.0 & 0.0 \\\\\n",
      "Adult & 150000 & 5000 & ctgan & 0.0 & 0.997 & 0.911 & 0.924 & 1.0 & 0.999 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 150000 & 5000 & tvae & 0.0 & 1.0 & 0.925 & 0.924 & 1.0 & 0.999 & 1.0 & 369.0 & 0.0 \\\\\n",
      "Adult & 200000 & 1000 & ctgan & 0.0 & 0.999 & 0.857 & 0.924 & 1.0 & 0.998 & 1.0 & 525.0 & 0.0 \\\\\n",
      "Adult & 200000 & 1000 & tvae & 0.0 & 0.995 & 0.886 & 0.924 & 1.0 & 0.999 & 1.0 & 123.0 & 0.0 \\\\\n",
      "Adult & 200000 & 2500 & ctgan & 0.0 & 0.998 & 0.908 & 0.924 & 1.0 & 0.998 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 200000 & 2500 & tvae & 0.0 & 1.0 & 0.914 & 0.924 & 1.0 & 0.999 & 1.0 & 35.0 & 0.0 \\\\\n",
      "Adult & 200000 & 5000 & ctgan & 0.0 & 0.997 & 0.911 & 0.924 & 1.0 & 0.998 & 1.0 & 999.0 & 0.0 \\\\\n",
      "Adult & 200000 & 5000 & tvae & 0.0 & 1.0 & 0.925 & 0.924 & 1.0 & 0.998 & 1.0 & 770.0 & 0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adult = df_metrics[df_metrics[\"Dataset\"] == \"Adult\"]\n",
    "print(adult.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "Dutch & 10000 & 1000 & ctgan & 0.06 & 0.971 & 0.888 & 0.913 & 0.773 & 0.605 & 0.773 & 144.0 & 0.027 \\\\\n",
      "Dutch & 10000 & 1000 & tvae & 0.068 & 0.987 & 0.993 & 0.913 & 0.715 & 0.589 & 0.715 & 94.0 & 0.028 \\\\\n",
      "Dutch & 10000 & 2500 & ctgan & 0.064 & 0.976 & 0.888 & 0.913 & 0.743 & 0.594 & 0.743 & 157.0 & 0.03 \\\\\n",
      "Dutch & 10000 & 2500 & tvae & 0.063 & 0.989 & 0.996 & 0.913 & 0.756 & 0.61 & 0.756 & 137.0 & 0.026 \\\\\n",
      "Dutch & 10000 & 5000 & ctgan & 0.061 & 0.966 & 0.977 & 0.913 & 0.724 & 0.597 & 0.724 & 55.0 & 0.03 \\\\\n",
      "Dutch & 10000 & 5000 & tvae & 0.069 & 0.995 & 0.991 & 0.913 & 0.712 & 0.537 & 0.712 & 145.0 & 0.028 \\\\\n",
      "Dutch & 25000 & 1000 & ctgan & 0.098 & 0.978 & 0.886 & 0.913 & 0.782 & 0.611 & 0.782 & 345.0 & 0.052 \\\\\n",
      "Dutch & 25000 & 1000 & tvae & 0.107 & 0.984 & 0.994 & 0.913 & 0.73 & 0.592 & 0.73 & 245.0 & 0.054 \\\\\n",
      "Dutch & 25000 & 2500 & ctgan & 0.104 & 0.981 & 0.887 & 0.913 & 0.757 & 0.6 & 0.757 & 244.0 & 0.056 \\\\\n",
      "Dutch & 25000 & 2500 & tvae & 0.101 & 0.982 & 0.995 & 0.913 & 0.764 & 0.614 & 0.764 & 359.0 & 0.049 \\\\\n",
      "Dutch & 25000 & 5000 & ctgan & 0.102 & 0.981 & 0.895 & 0.913 & 0.738 & 0.597 & 0.738 & 623.0 & 0.054 \\\\\n",
      "Dutch & 25000 & 5000 & tvae & 0.108 & 0.995 & 0.992 & 0.913 & 0.722 & 0.538 & 0.722 & 245.0 & 0.055 \\\\\n",
      "Dutch & 50000 & 1000 & ctgan & 0.128 & 0.986 & 0.97 & 0.913 & 0.786 & 0.607 & 0.786 & 170.0 & 0.073 \\\\\n",
      "Dutch & 50000 & 1000 & tvae & 0.142 & 0.991 & 0.995 & 0.913 & 0.73 & 0.589 & 0.73 & 512.0 & 0.079 \\\\\n",
      "Dutch & 50000 & 2500 & ctgan & 0.142 & 0.989 & 0.887 & 0.913 & 0.755 & 0.599 & 0.755 & 515.0 & 0.081 \\\\\n",
      "Dutch & 50000 & 2500 & tvae & 0.131 & 0.968 & 0.996 & 0.913 & 0.767 & 0.614 & 0.767 & 651.0 & 0.072 \\\\\n",
      "Dutch & 50000 & 5000 & ctgan & 0.137 & 0.988 & 0.978 & 0.913 & 0.74 & 0.596 & 0.74 & 180.0 & 0.081 \\\\\n",
      "Dutch & 50000 & 5000 & tvae & 0.142 & 0.929 & 0.99 & 0.913 & 0.726 & 0.543 & 0.726 & 532.0 & 0.08 \\\\\n",
      "Dutch & 75000 & 1000 & ctgan & 0.148 & 0.935 & 0.886 & 0.913 & 0.787 & 0.609 & 0.787 & 666.0 & 0.088 \\\\\n",
      "Dutch & 75000 & 1000 & tvae & 0.161 & 0.993 & 0.994 & 0.913 & 0.733 & 0.59 & 0.733 & 829.0 & 0.095 \\\\\n",
      "Dutch & 75000 & 2500 & ctgan & 0.162 & 0.947 & 0.887 & 0.913 & 0.759 & 0.598 & 0.759 & 317.0 & 0.097 \\\\\n",
      "Dutch & 75000 & 2500 & tvae & 0.151 & 0.73 & 0.995 & 0.913 & 0.77 & 0.618 & 0.77 & 450.0 & 0.087 \\\\\n",
      "Dutch & 75000 & 5000 & ctgan & 0.159 & 0.983 & 0.977 & 0.913 & 0.744 & 0.598 & 0.744 & 454.0 & 0.097 \\\\\n",
      "Dutch & 75000 & 5000 & tvae & 0.161 & 0.945 & 0.991 & 0.913 & 0.724 & 0.539 & 0.724 & 999.0 & 0.095 \\\\\n",
      "Dutch & 100000 & 1000 & ctgan & 0.162 & 0.982 & 0.886 & 0.913 & 0.788 & 0.609 & 0.788 & 999.0 & 0.1 \\\\\n",
      "Dutch & 100000 & 1000 & tvae & 0.176 & 0.994 & 0.994 & 0.913 & 0.734 & 0.59 & 0.734 & 999.0 & 0.107 \\\\\n",
      "Dutch & 100000 & 2500 & ctgan & 0.178 & 0.807 & 0.887 & 0.913 & 0.759 & 0.6 & 0.759 & 999.0 & 0.11 \\\\\n",
      "Dutch & 100000 & 2500 & tvae & 0.163 & 0.989 & 0.995 & 0.913 & 0.771 & 0.617 & 0.771 & 999.0 & 0.098 \\\\\n",
      "Dutch & 100000 & 5000 & ctgan & 0.171 & 0.986 & 0.977 & 0.913 & 0.744 & 0.597 & 0.744 & 606.0 & 0.108 \\\\\n",
      "Dutch & 100000 & 5000 & tvae & 0.176 & 0.953 & 0.99 & 0.913 & 0.725 & 0.541 & 0.725 & 999.0 & 0.108 \\\\\n",
      "Dutch & 150000 & 1000 & ctgan & 0.182 & 0.987 & 0.886 & 0.913 & 0.788 & 0.608 & 0.788 & 502.0 & 0.114 \\\\\n",
      "Dutch & 150000 & 1000 & tvae & 0.193 & 0.961 & 0.994 & 0.913 & 0.735 & 0.591 & 0.735 & 999.0 & 0.121 \\\\\n",
      "Dutch & 150000 & 2500 & ctgan & 0.198 & 0.841 & 0.971 & 0.913 & 0.758 & 0.598 & 0.758 & 999.0 & 0.125 \\\\\n",
      "Dutch & 150000 & 2500 & tvae & 0.183 & 0.992 & 0.995 & 0.913 & 0.77 & 0.617 & 0.77 & 999.0 & 0.114 \\\\\n",
      "Dutch & 150000 & 5000 & ctgan & 0.191 & 0.965 & 0.977 & 0.913 & 0.743 & 0.597 & 0.743 & 463.0 & 0.124 \\\\\n",
      "Dutch & 150000 & 5000 & tvae & 0.194 & 0.963 & 0.99 & 0.913 & 0.727 & 0.541 & 0.727 & 999.0 & 0.124 \\\\\n",
      "Dutch & 200000 & 1000 & ctgan & 0.194 & 0.964 & 0.886 & 0.913 & 0.79 & 0.611 & 0.79 & 999.0 & 0.125 \\\\\n",
      "Dutch & 200000 & 1000 & tvae & 0.206 & 0.967 & 0.994 & 0.913 & 0.736 & 0.591 & 0.736 & 999.0 & 0.132 \\\\\n",
      "Dutch & 200000 & 2500 & ctgan & 0.212 & 0.86 & 0.887 & 0.913 & 0.76 & 0.599 & 0.76 & 887.0 & 0.138 \\\\\n",
      "Dutch & 200000 & 2500 & tvae & 0.196 & 0.813 & 0.995 & 0.913 & 0.772 & 0.618 & 0.772 & 999.0 & 0.124 \\\\\n",
      "Dutch & 200000 & 5000 & ctgan & 0.205 & 0.836 & 0.977 & 0.913 & 0.745 & 0.597 & 0.745 & 999.0 & 0.135 \\\\\n",
      "Dutch & 200000 & 5000 & tvae & 0.206 & 0.815 & 0.99 & 0.913 & 0.727 & 0.542 & 0.727 & 999.0 & 0.134 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dutch = df_metrics[df_metrics[\"Dataset\"] == \"Dutch\"]\n",
    "print(dutch.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "Shuttle & 10000 & 1000 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.998 & 0.763 & 0.998 & 95.0 & 0.003 \\\\\n",
      "Shuttle & 10000 & 1000 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.994 & 0.581 & 0.994 & 149.0 & 0.004 \\\\\n",
      "Shuttle & 10000 & 2500 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.997 & 0.757 & 0.997 & 122.0 & 0.003 \\\\\n",
      "Shuttle & 10000 & 2500 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.993 & 0.553 & 0.993 & 95.0 & 0.005 \\\\\n",
      "Shuttle & 10000 & 5000 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.997 & 0.77 & 0.997 & 157.0 & 0.004 \\\\\n",
      "Shuttle & 10000 & 5000 & tvae & 0.0 & 0.999 & 0.1 & 1.0 & 0.994 & 0.646 & 0.994 & 103.0 & 0.003 \\\\\n",
      "Shuttle & 25000 & 1000 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.998 & 0.766 & 0.998 & 224.0 & 0.005 \\\\\n",
      "Shuttle & 25000 & 1000 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.995 & 0.584 & 0.995 & 213.0 & 0.009 \\\\\n",
      "Shuttle & 25000 & 2500 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.998 & 0.758 & 0.998 & 301.0 & 0.005 \\\\\n",
      "Shuttle & 25000 & 2500 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.994 & 0.561 & 0.994 & 98.0 & 0.01 \\\\\n",
      "Shuttle & 25000 & 5000 & ctgan & 0.0 & 0.999 & 0.097 & 1.0 & 0.997 & 0.777 & 0.997 & 378.0 & 0.007 \\\\\n",
      "Shuttle & 25000 & 5000 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.996 & 0.635 & 0.996 & 216.0 & 0.006 \\\\\n",
      "Shuttle & 50000 & 1000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.999 & 0.766 & 0.999 & 419.0 & 0.007 \\\\\n",
      "Shuttle & 50000 & 1000 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.995 & 0.576 & 0.995 & 449.0 & 0.016 \\\\\n",
      "Shuttle & 50000 & 2500 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.763 & 0.998 & 671.0 & 0.007 \\\\\n",
      "Shuttle & 50000 & 2500 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.995 & 0.533 & 0.995 & 485.0 & 0.015 \\\\\n",
      "Shuttle & 50000 & 5000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.776 & 0.998 & 757.0 & 0.011 \\\\\n",
      "Shuttle & 50000 & 5000 & tvae & 0.0 & 0.999 & 0.1 & 1.0 & 0.996 & 0.617 & 0.996 & 444.0 & 0.011 \\\\\n",
      "Shuttle & 75000 & 1000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.765 & 0.998 & 638.0 & 0.01 \\\\\n",
      "Shuttle & 75000 & 1000 & tvae & 0.001 & 0.999 & 0.0 & 1.0 & 0.995 & 0.571 & 0.995 & 712.0 & 0.021 \\\\\n",
      "Shuttle & 75000 & 2500 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.763 & 0.998 & 999.0 & 0.009 \\\\\n",
      "Shuttle & 75000 & 2500 & tvae & 0.0 & 0.999 & 0.0 & 1.0 & 0.995 & 0.524 & 0.995 & 736.0 & 0.021 \\\\\n",
      "Shuttle & 75000 & 5000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.777 & 0.998 & 999.0 & 0.013 \\\\\n",
      "Shuttle & 75000 & 5000 & tvae & 0.0 & 0.999 & 0.1 & 1.0 & 0.996 & 0.609 & 0.996 & 654.0 & 0.015 \\\\\n",
      "Shuttle & 100000 & 1000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.765 & 0.998 & 999.0 & 0.011 \\\\\n",
      "Shuttle & 100000 & 1000 & tvae & 0.0 & 0.999 & 0.1 & 1.0 & 0.995 & 0.573 & 0.995 & 988.0 & 0.025 \\\\\n",
      "Shuttle & 100000 & 2500 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.765 & 0.998 & 999.0 & 0.013 \\\\\n",
      "Shuttle & 100000 & 2500 & tvae & 0.001 & 0.999 & 0.0 & 1.0 & 0.995 & 0.517 & 0.995 & 791.0 & 0.026 \\\\\n",
      "Shuttle & 100000 & 5000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.777 & 0.998 & 999.0 & 0.016 \\\\\n",
      "Shuttle & 100000 & 5000 & tvae & 0.0 & 0.999 & 0.1 & 1.0 & 0.997 & 0.604 & 0.997 & 877.0 & 0.019 \\\\\n",
      "Shuttle & 150000 & 1000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.999 & 0.766 & 0.999 & 999.0 & 0.015 \\\\\n",
      "Shuttle & 150000 & 1000 & tvae & 0.001 & 0.999 & 0.0 & 1.0 & 0.995 & 0.567 & 0.995 & 999.0 & 0.032 \\\\\n",
      "Shuttle & 150000 & 2500 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.767 & 0.998 & 999.0 & 0.015 \\\\\n",
      "Shuttle & 150000 & 2500 & tvae & 0.001 & 0.999 & 0.0 & 1.0 & 0.995 & 0.52 & 0.995 & 585.0 & 0.032 \\\\\n",
      "Shuttle & 150000 & 5000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.777 & 0.998 & 999.0 & 0.019 \\\\\n",
      "Shuttle & 150000 & 5000 & tvae & 0.001 & 0.999 & 0.1 & 1.0 & 0.997 & 0.602 & 0.997 & 999.0 & 0.025 \\\\\n",
      "Shuttle & 200000 & 1000 & tvae & 0.001 & 0.999 & 0.0 & 1.0 & 0.995 & 0.565 & 0.995 & 999.0 & 0.037 \\\\\n",
      "Shuttle & 200000 & 2500 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.999 & 0.769 & 0.999 & 999.0 & 0.018 \\\\\n",
      "Shuttle & 200000 & 2500 & tvae & 0.001 & 0.999 & 0.1 & 1.0 & 0.995 & 0.52 & 0.995 & 999.0 & 0.038 \\\\\n",
      "Shuttle & 200000 & 5000 & ctgan & 0.0 & 0.999 & 0.096 & 1.0 & 0.998 & 0.776 & 0.998 & 999.0 & 0.024 \\\\\n",
      "Shuttle & 200000 & 5000 & tvae & 0.001 & 0.999 & 0.1 & 1.0 & 0.996 & 0.601 & 0.996 & 999.0 & 0.029 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shuttle = df_metrics[df_metrics[\"Dataset\"] == \"Shuttle\"]\n",
    "print(shuttle.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covertype = df_metrics[df_metrics[\"Dataset\"] == \"Covertype\"]\n",
    "print(covertype.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "House16 & 10000 & 1000 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.991 & 0.644 & 0.991 & 13.0 & 0.281 \\\\\n",
      "House16 & 10000 & 1000 & tvae & 0.0 & 1.0 & 0.41 & 0.95 & 0.986 & 0.69 & 0.986 & 3.0 & 0.32 \\\\\n",
      "House16 & 10000 & 2500 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.985 & 0.621 & 0.985 & 15.0 & 0.28 \\\\\n",
      "House16 & 10000 & 2500 & tvae & 0.0 & 1.0 & 0.406 & 0.95 & 0.982 & 0.654 & 0.982 & 1.0 & 0.334 \\\\\n",
      "House16 & 10000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.982 & 0.612 & 0.982 & 15.0 & 0.286 \\\\\n",
      "House16 & 10000 & 5000 & tvae & 0.0 & 1.0 & 0.403 & 0.95 & 0.99 & 0.667 & 0.99 & 2.0 & 0.336 \\\\\n",
      "House16 & 25000 & 1000 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.993 & 0.644 & 0.993 & 32.0 & 0.46 \\\\\n",
      "House16 & 25000 & 1000 & tvae & 0.0 & 1.0 & 0.527 & 0.95 & 0.988 & 0.689 & 0.988 & 20.0 & 0.514 \\\\\n",
      "House16 & 25000 & 2500 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.987 & 0.633 & 0.987 & 65.0 & 0.462 \\\\\n",
      "House16 & 25000 & 2500 & tvae & 0.0 & 1.0 & 0.347 & 0.95 & 0.985 & 0.655 & 0.985 & 6.0 & 0.536 \\\\\n",
      "House16 & 25000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.986 & 0.616 & 0.986 & 17.0 & 0.471 \\\\\n",
      "House16 & 25000 & 5000 & tvae & 0.0 & 1.0 & 0.462 & 0.95 & 0.991 & 0.66 & 0.991 & 7.0 & 0.549 \\\\\n",
      "House16 & 50000 & 1000 & ctgan & 0.0 & 1.0 & 0.631 & 0.95 & 0.994 & 0.639 & 0.994 & 61.0 & 0.596 \\\\\n",
      "House16 & 50000 & 1000 & tvae & 0.0 & 1.0 & 0.645 & 0.95 & 0.989 & 0.69 & 0.989 & 12.0 & 0.655 \\\\\n",
      "House16 & 50000 & 2500 & ctgan & 0.0 & 1.0 & 0.69 & 0.95 & 0.989 & 0.629 & 0.989 & 125.0 & 0.605 \\\\\n",
      "House16 & 50000 & 2500 & tvae & 0.0 & 1.0 & 0.464 & 0.95 & 0.987 & 0.656 & 0.987 & 18.0 & 0.69 \\\\\n",
      "House16 & 50000 & 5000 & ctgan & 0.0 & 1.0 & 0.69 & 0.95 & 0.987 & 0.612 & 0.987 & 31.0 & 0.618 \\\\\n",
      "House16 & 50000 & 5000 & tvae & 0.0 & 1.0 & 0.403 & 0.95 & 0.992 & 0.653 & 0.992 & 20.0 & 0.693 \\\\\n",
      "House16 & 75000 & 1000 & ctgan & 0.0 & 1.0 & 0.631 & 0.95 & 0.994 & 0.64 & 0.994 & 70.0 & 0.668 \\\\\n",
      "House16 & 75000 & 1000 & tvae & 0.0 & 1.0 & 0.644 & 0.95 & 0.99 & 0.689 & 0.99 & 24.0 & 0.719 \\\\\n",
      "House16 & 75000 & 2500 & ctgan & 0.0 & 1.0 & 0.631 & 0.95 & 0.989 & 0.631 & 0.989 & 126.0 & 0.666 \\\\\n",
      "House16 & 75000 & 2500 & tvae & 0.0 & 1.0 & 0.464 & 0.95 & 0.987 & 0.654 & 0.987 & 16.0 & 0.752 \\\\\n",
      "House16 & 75000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.986 & 0.614 & 0.986 & 120.0 & 0.695 \\\\\n",
      "House16 & 75000 & 5000 & tvae & 0.0 & 1.0 & 0.404 & 0.95 & 0.993 & 0.654 & 0.993 & 19.0 & 0.761 \\\\\n",
      "House16 & 100000 & 1000 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.994 & 0.641 & 0.994 & 95.0 & 0.712 \\\\\n",
      "House16 & 100000 & 1000 & tvae & 0.0 & 1.0 & 0.645 & 0.95 & 0.99 & 0.687 & 0.99 & 26.0 & 0.762 \\\\\n",
      "House16 & 100000 & 2500 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.989 & 0.632 & 0.989 & 180.0 & 0.721 \\\\\n",
      "House16 & 100000 & 2500 & tvae & 0.0 & 1.0 & 0.464 & 0.95 & 0.988 & 0.656 & 0.988 & 43.0 & 0.796 \\\\\n",
      "House16 & 100000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.987 & 0.613 & 0.987 & 57.0 & 0.745 \\\\\n",
      "House16 & 100000 & 5000 & tvae & 0.0 & 1.0 & 0.462 & 0.95 & 0.993 & 0.65 & 0.993 & 33.0 & 0.802 \\\\\n",
      "House16 & 150000 & 1000 & ctgan & 0.0 & 1.0 & 0.63 & 0.95 & 0.994 & 0.64 & 0.994 & 136.0 & 0.764 \\\\\n",
      "House16 & 150000 & 1000 & tvae & 0.0 & 1.0 & 0.645 & 0.95 & 0.99 & 0.687 & 0.99 & 64.0 & 0.82 \\\\\n",
      "House16 & 150000 & 2500 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.989 & 0.631 & 0.989 & 338.0 & 0.783 \\\\\n",
      "House16 & 150000 & 2500 & tvae & 0.0 & 1.0 & 0.523 & 0.95 & 0.988 & 0.652 & 0.988 & 20.0 & 0.844 \\\\\n",
      "House16 & 150000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.987 & 0.612 & 0.987 & 155.0 & 0.804 \\\\\n",
      "House16 & 150000 & 5000 & tvae & 0.0 & 1.0 & 0.521 & 0.95 & 0.993 & 0.648 & 0.993 & 59.0 & 0.851 \\\\\n",
      "House16 & 200000 & 1000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.994 & 0.638 & 0.994 & 259.0 & 0.807 \\\\\n",
      "House16 & 200000 & 1000 & tvae & 0.0 & 1.0 & 0.704 & 0.95 & 0.99 & 0.687 & 0.99 & 78.0 & 0.847 \\\\\n",
      "House16 & 200000 & 2500 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.989 & 0.632 & 0.989 & 346.0 & 0.815 \\\\\n",
      "House16 & 200000 & 2500 & tvae & 0.0 & 1.0 & 0.604 & 0.95 & 0.988 & 0.65 & 0.988 & 63.0 & 0.872 \\\\\n",
      "House16 & 200000 & 5000 & ctgan & 0.0 & 1.0 & 0.689 & 0.95 & 0.987 & 0.611 & 0.987 & 192.0 & 0.837 \\\\\n",
      "House16 & 200000 & 5000 & tvae & 0.0 & 1.0 & 0.521 & 0.95 & 0.993 & 0.646 & 0.993 & 74.0 & 0.877 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house16 = df_metrics[df_metrics[\"Dataset\"] == \"House16\"]\n",
    "print(house16.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "Dataset & Generated Samples & Epochs & Synthesizer & Com. Rows Prop. & Close Val. Prob. & Chi Squar. Test. & XGB Perf. & MLP Det. & Lin. Det. & XGB Det. & K Anon. & Id. Score \\\\\n",
      "\\midrule\n",
      "Letter & 10000 & 1000 & ctgan & 0.0 & 0.021 & 0.353 & 0.999 & 0.993 & 0.548 & 0.993 & 390.0 & 0.001 \\\\\n",
      "Letter & 10000 & 1000 & tvae & 0.0 & 0.16 & 0.412 & 0.999 & 0.989 & 0.585 & 0.989 & 370.0 & 0.008 \\\\\n",
      "Letter & 10000 & 2500 & ctgan & 0.0 & 0.244 & 0.412 & 0.999 & 0.987 & 0.527 & 0.987 & 305.0 & 0.003 \\\\\n",
      "Letter & 10000 & 2500 & tvae & 0.0 & 0.496 & 0.471 & 0.999 & 0.988 & 0.586 & 0.988 & 359.0 & 0.008 \\\\\n",
      "Letter & 10000 & 5000 & ctgan & 0.0 & 0.362 & 0.353 & 0.999 & 0.978 & 0.507 & 0.978 & 266.0 & 0.003 \\\\\n",
      "Letter & 10000 & 5000 & tvae & 0.0 & 0.48 & 0.471 & 0.999 & 0.982 & 0.54 & 0.982 & 417.0 & 0.009 \\\\\n",
      "Letter & 25000 & 1000 & ctgan & 0.0 & 0.03 & 0.353 & 0.999 & 0.994 & 0.547 & 0.994 & 945.0 & 0.004 \\\\\n",
      "Letter & 25000 & 1000 & tvae & 0.0 & 0.496 & 0.471 & 0.999 & 0.992 & 0.586 & 0.992 & 999.0 & 0.013 \\\\\n",
      "Letter & 25000 & 2500 & ctgan & 0.0 & 0.304 & 0.353 & 0.999 & 0.988 & 0.527 & 0.988 & 773.0 & 0.005 \\\\\n",
      "Letter & 25000 & 2500 & tvae & 0.0 & 0.292 & 0.471 & 0.999 & 0.991 & 0.586 & 0.991 & 942.0 & 0.017 \\\\\n",
      "Letter & 25000 & 5000 & ctgan & 0.0 & 0.08 & 0.412 & 0.999 & 0.98 & 0.511 & 0.98 & 899.0 & 0.007 \\\\\n",
      "Letter & 25000 & 5000 & tvae & 0.0 & 0.438 & 0.471 & 0.999 & 0.986 & 0.55 & 0.986 & 999.0 & 0.017 \\\\\n",
      "Letter & 50000 & 1000 & ctgan & 0.0 & 0.029 & 0.353 & 0.999 & 0.995 & 0.548 & 0.995 & 999.0 & 0.006 \\\\\n",
      "Letter & 50000 & 1000 & tvae & 0.0 & 0.183 & 0.471 & 0.999 & 0.993 & 0.585 & 0.993 & 999.0 & 0.024 \\\\\n",
      "Letter & 50000 & 2500 & ctgan & 0.0 & 0.334 & 0.412 & 0.999 & 0.989 & 0.525 & 0.989 & 999.0 & 0.01 \\\\\n",
      "Letter & 50000 & 2500 & tvae & 0.0 & 0.222 & 0.471 & 0.999 & 0.992 & 0.588 & 0.992 & 999.0 & 0.026 \\\\\n",
      "Letter & 50000 & 5000 & ctgan & 0.0 & 0.124 & 0.412 & 0.999 & 0.984 & 0.513 & 0.984 & 999.0 & 0.013 \\\\\n",
      "Letter & 50000 & 5000 & tvae & 0.0 & 0.212 & 0.529 & 0.999 & 0.987 & 0.549 & 0.987 & 999.0 & 0.026 \\\\\n",
      "Letter & 75000 & 1000 & ctgan & 0.0 & 0.258 & 0.353 & 0.999 & 0.995 & 0.548 & 0.995 & 999.0 & 0.009 \\\\\n",
      "Letter & 75000 & 1000 & tvae & 0.0 & 0.21 & 0.471 & 0.999 & 0.993 & 0.587 & 0.993 & 999.0 & 0.028 \\\\\n",
      "Letter & 75000 & 2500 & ctgan & 0.0 & 0.122 & 0.412 & 0.999 & 0.989 & 0.529 & 0.989 & 999.0 & 0.012 \\\\\n",
      "Letter & 75000 & 2500 & tvae & 0.0 & 0.252 & 0.471 & 0.999 & 0.993 & 0.588 & 0.993 & 999.0 & 0.031 \\\\\n",
      "Letter & 75000 & 5000 & ctgan & 0.0 & 0.086 & 0.412 & 0.999 & 0.982 & 0.515 & 0.982 & 999.0 & 0.017 \\\\\n",
      "Letter & 75000 & 5000 & tvae & 0.0 & 0.252 & 0.529 & 0.999 & 0.988 & 0.55 & 0.988 & 999.0 & 0.039 \\\\\n",
      "Letter & 100000 & 1000 & ctgan & 0.0 & 0.238 & 0.353 & 0.999 & 0.994 & 0.546 & 0.994 & 999.0 & 0.011 \\\\\n",
      "Letter & 100000 & 1000 & tvae & 0.0 & 0.159 & 0.471 & 0.999 & 0.994 & 0.585 & 0.994 & 999.0 & 0.034 \\\\\n",
      "Letter & 100000 & 2500 & ctgan & 0.0 & 0.085 & 0.412 & 0.999 & 0.99 & 0.528 & 0.99 & 999.0 & 0.016 \\\\\n",
      "Letter & 100000 & 2500 & tvae & 0.0 & 0.279 & 0.471 & 0.999 & 0.993 & 0.59 & 0.993 & 999.0 & 0.037 \\\\\n",
      "Letter & 100000 & 5000 & ctgan & 0.0 & 0.107 & 0.353 & 0.999 & 0.982 & 0.51 & 0.982 & 999.0 & 0.023 \\\\\n",
      "Letter & 100000 & 5000 & tvae & 0.0 & 0.114 & 0.529 & 0.999 & 0.988 & 0.55 & 0.988 & 999.0 & 0.043 \\\\\n",
      "Letter & 150000 & 1000 & ctgan & 0.0 & 0.059 & 0.353 & 0.999 & 0.995 & 0.545 & 0.995 & 999.0 & 0.013 \\\\\n",
      "Letter & 150000 & 1000 & tvae & 0.0 & 0.272 & 0.529 & 0.999 & 0.993 & 0.585 & 0.993 & 999.0 & 0.041 \\\\\n",
      "Letter & 150000 & 2500 & ctgan & 0.0 & 0.318 & 0.412 & 0.999 & 0.99 & 0.529 & 0.99 & 999.0 & 0.021 \\\\\n",
      "Letter & 150000 & 2500 & tvae & 0.001 & 0.318 & 0.471 & 0.999 & 0.993 & 0.589 & 0.993 & 999.0 & 0.049 \\\\\n",
      "Letter & 150000 & 5000 & ctgan & 0.0 & 0.074 & 0.41 & 0.999 & 0.985 & 0.515 & 0.985 & 999.0 & 0.026 \\\\\n",
      "Letter & 150000 & 5000 & tvae & 0.001 & 0.23 & 0.529 & 0.999 & 0.988 & 0.55 & 0.988 & 999.0 & 0.054 \\\\\n",
      "Letter & 200000 & 1000 & ctgan & 0.0 & 0.032 & 0.353 & 0.999 & 0.994 & 0.548 & 0.994 & 999.0 & 0.016 \\\\\n",
      "Letter & 200000 & 1000 & tvae & 0.001 & 0.291 & 0.529 & 0.999 & 0.994 & 0.585 & 0.994 & 999.0 & 0.047 \\\\\n",
      "Letter & 200000 & 2500 & ctgan & 0.0 & 0.122 & 0.412 & 0.999 & 0.99 & 0.53 & 0.99 & 999.0 & 0.023 \\\\\n",
      "Letter & 200000 & 2500 & tvae & 0.001 & 0.338 & 0.471 & 0.999 & 0.993 & 0.587 & 0.993 & 999.0 & 0.054 \\\\\n",
      "Letter & 200000 & 5000 & ctgan & 0.0 & 0.16 & 0.412 & 0.999 & 0.983 & 0.513 & 0.983 & 999.0 & 0.032 \\\\\n",
      "Letter & 200000 & 5000 & tvae & 0.0 & 0.158 & 0.471 & 0.999 & 0.989 & 0.551 & 0.989 & 999.0 & 0.062 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letter = df_metrics[df_metrics[\"Dataset\"] == \"Letter\"]\n",
    "print(letter.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "epochs = [1000, 2500, 5000]\n",
    "synthesizers = [\"ctgan\", \"tvae\"]\n",
    "for dataset in datasets:\n",
    "    metrics[dataset] = {}\n",
    "    for synth in synthesizers:\n",
    "        for epoch in epochs:\n",
    "            experiment_name = f\"{synth}_epochs_{epoch}\"\n",
    "            if experiment_name in project_data:\n",
    "                results = project_data[experiment_name]\n",
    "                for result in results:\n",
    "                    if len(result[\"dataset\"]) > 0 and result[\"dataset\"][0] == dataset:\n",
    "                        df_result = pd.DataFrame(result)\n",
    "\n",
    "                        if \"loss_generator\" in df_result.columns and \"loss_discriminator\" in df_result.columns:\n",
    "                            loss_discriminator = df_result[\"loss_discriminator\"]\n",
    "                            loss_generator = df_result[\"loss_generator\"]\n",
    "                            # remove nan from the series\n",
    "                            loss_discriminator = list(loss_discriminator[~loss_discriminator.isna()])\n",
    "                            loss_generator = list(loss_generator[~loss_generator.isna()])\n",
    "                            metrics[dataset][experiment_name] = {\n",
    "                                \"Loss Discriminator\": loss_discriminator,\n",
    "                                \"Loss Generator\": loss_generator,\n",
    "                            }\n",
    "                        \n",
    "                        elif \"loss\" in df_result.columns:\n",
    "                            loss = df_result[\"loss\"]\n",
    "                            loss = list(loss[~loss.isna()])\n",
    "                            metrics[dataset][experiment_name] = {\n",
    "                                \"Loss\": loss,\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ctgan_epochs_1000', 'ctgan_epochs_2500', 'ctgan_epochs_5000', 'tvae_epochs_1000', 'tvae_epochs_2500', 'tvae_epochs_5000'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"adult\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created plot for adult with ctgan\n",
      "Created plot for house16 with ctgan\n",
      "Created plot for letter with ctgan\n",
      "Created plot for covertype with ctgan\n",
      "Created plot for shuttle with ctgan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a color-blind-friendly palette and markers\n",
    "colors = [\"#FF774E\", \"#70DDA8\", \"#7c7787\"]\n",
    "edge_colors = [\"#E45D22\", \"#00B977\", \"#5a5255\"]\n",
    "\n",
    "# colors = [\"#FF774E\", \"#7c7787\", \"#53C4FE\", \"#70DDA8\", \"#dc68e4\", \"#755c51\", \"gray\"]\n",
    "# edge_colors = [\"#E45D22\", \"#5a5255\", \"#009EFF\", \"#00B977\", \"fuchsia\", \"#ae5a41\", \"black\"]\n",
    "markers = ['o', 'd', 'v']\n",
    "line_styles = ['-', '--', '-.']\n",
    "alpha_values = [1.0, 0.7, 0.5]\n",
    "marker_sizes = [12, 11, 10]\n",
    "\n",
    "def plot_gan_losses(metrics, dataset_name, synthesizer_name):\n",
    "    \"\"\"\n",
    "    Plot the generator and discriminator losses for a specific dataset and synthesizer\n",
    "    across different epochs.\n",
    "    \"\"\"\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    epochs = [1000, 2500, 5000]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    handles, labels = [], []\n",
    "    \n",
    "    for idx, epoch in enumerate(epochs):\n",
    "        experiment_name = f\"{synthesizer_name}_epochs_{epoch}\"\n",
    "        if experiment_name in metrics[dataset_name]:\n",
    "            \n",
    "            # Plot discriminator loss\n",
    "            loss_data = metrics[dataset_name][experiment_name][\"Loss Discriminator\"]\n",
    "            x_values = list(range(0, len(loss_data), 100))\n",
    "            y_values = [loss_data[j] for j in x_values]\n",
    "            \n",
    "            line, = axes[0].plot(x_values, y_values, marker=markers[idx], markersize=marker_sizes[idx], linewidth=3, linestyle=line_styles[idx],\n",
    "                         color=colors[idx], markerfacecolor=colors[idx], markeredgecolor=edge_colors[idx], \n",
    "                         markeredgewidth=2, alpha=alpha_values[idx], label=f\"Epochs: {epoch}\")\n",
    "            \n",
    "            handles.append(line)\n",
    "            labels.append(f\"Epochs: {epoch}\")\n",
    "            \n",
    "            # Plot generator loss\n",
    "            loss_data = metrics[dataset_name][experiment_name][\"Loss Generator\"]\n",
    "            y_values = [loss_data[j] for j in x_values]\n",
    "            \n",
    "            axes[1].plot(x_values, y_values, marker=markers[idx], markersize=marker_sizes[idx], linewidth=3, linestyle=line_styles[idx],\n",
    "                         color=colors[idx], markerfacecolor=colors[idx], markeredgecolor=edge_colors[idx], \n",
    "                         markeredgewidth=2, alpha=alpha_values[idx])\n",
    "    \n",
    "    # Customize subplots\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_xlabel('Training Steps', fontsize=25)\n",
    "        ax.set_ylabel('Loss', fontsize=25)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "        ax.set_title(f\"{'Discriminator' if i == 0 else 'Generator'} Loss - {dataset_name.capitalize()} - {synthesizer_name.upper()}\", fontsize=25)\n",
    "    \n",
    "    # Add external legend below plots\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.02), ncol=3, fontsize=22, frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "    plt.savefig(f'plots/losses/{dataset_name}_{synthesizer_name}_losses.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_all_loss_plots(metrics):\n",
    "    datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "    synthesizers = [\"ctgan\"]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for synthesizer in synthesizers:\n",
    "            has_data = any(f\"{synthesizer}_epochs_{e}\" in metrics.get(dataset, {}) for e in [1000, 2500, 5000])\n",
    "            if has_data:\n",
    "                plot_gan_losses(metrics, dataset, synthesizer)\n",
    "                print(f\"Created plot for {dataset} with {synthesizer}\")\n",
    "\n",
    "# Execute the function to create all plots\n",
    "create_all_loss_plots(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created plot for adult with tvae\n",
      "Created plot for house16 with tvae\n",
      "Created plot for letter with tvae\n",
      "Created plot for shuttle with tvae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a color-blind-friendly palette and markers\n",
    "colors = [\"#FF774E\", \"#70DDA8\", \"#7c7787\"]\n",
    "edge_colors = [\"#E45D22\", \"#00B977\", \"#5a5255\"]\n",
    "\n",
    "markers = ['o', 'd', 'v']\n",
    "line_styles = ['-', '--', '-.']\n",
    "alpha_values = [1.0, 0.7, 0.5]\n",
    "marker_sizes = [12, 11, 10]\n",
    "\n",
    "def plot_gan_loss(metrics, dataset_name, synthesizer_name):\n",
    "    \"\"\"\n",
    "    Plot the loss for a specific dataset and synthesizer across different epochs.\n",
    "    \"\"\"\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    epochs = [1000, 2500, 5000]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    handles, labels = [], []\n",
    "    \n",
    "    for idx, epoch in enumerate(epochs):\n",
    "        experiment_name = f\"{synthesizer_name}_epochs_{epoch}\"\n",
    "        if experiment_name in metrics[dataset_name]:\n",
    "            \n",
    "            # Plot loss with reduced markers\n",
    "            loss_data = metrics[dataset_name][experiment_name][\"Loss\"]\n",
    "            x_values = list(range(0, len(loss_data), 500))  # Increase step size to reduce markers\n",
    "            y_values = [loss_data[j] for j in x_values]\n",
    "            \n",
    "            line, = ax.plot(x_values, y_values, marker=markers[idx], markersize=marker_sizes[idx]//2, linewidth=3, \n",
    "                            linestyle=line_styles[idx], color=colors[idx], markerfacecolor=colors[idx], \n",
    "                            markeredgecolor=edge_colors[idx], markeredgewidth=2, alpha=alpha_values[idx], \n",
    "                            markevery=10,  # Reduce marker frequency\n",
    "                            label=f\"Epochs: {epoch}\")\n",
    "            \n",
    "            handles.append(line)\n",
    "            labels.append(f\"Epochs: {epoch}\")\n",
    "    \n",
    "    ax.set_xlabel('Training Steps', fontsize=25)\n",
    "    ax.set_ylabel('Loss', fontsize=25)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "    ax.set_title(f\"Loss - {dataset_name.capitalize()} - {synthesizer_name.upper()}\", fontsize=25)\n",
    "    \n",
    "    # Adjust legend position\n",
    "    ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3, fontsize=18, \n",
    "              frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])  # Adjust padding\n",
    "    plt.savefig(f'plots/losses/{dataset_name}_{synthesizer_name}_loss.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_all_loss_plots(metrics):\n",
    "    datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "    synthesizers = [\"tvae\"]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for synthesizer in synthesizers:\n",
    "            has_data = any(f\"{synthesizer}_epochs_{e}\" in metrics.get(dataset, {}) for e in [1000, 2500, 5000])\n",
    "            if has_data:\n",
    "                plot_gan_loss(metrics, dataset, synthesizer)\n",
    "                print(f\"Created plot for {dataset} with {synthesizer}\")\n",
    "\n",
    "# Execute the function to create all plots\n",
    "create_all_loss_plots(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created plot for adult with tvae\n",
      "Created plot for house16 with tvae\n",
      "Created plot for letter with tvae\n",
      "Created plot for shuttle with tvae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a color-blind-friendly palette and markers\n",
    "colors = [\"#FF774E\", \"#70DDA8\", \"#7c7787\"]\n",
    "edge_colors = [\"#E45D22\", \"#00B977\", \"#5a5255\"]\n",
    "\n",
    "markers = ['o', 'd', 'v']\n",
    "line_styles = ['-', '--', '-.']\n",
    "alpha_values = [1.0, 0.7, 0.5]\n",
    "marker_sizes = [12, 11, 10]\n",
    "\n",
    "def plot_gan_loss(metrics, dataset_name, synthesizer_name):\n",
    "    \"\"\"\n",
    "    Plot the loss for a specific dataset and synthesizer across different epochs.\n",
    "    \"\"\"\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    epochs = [1000, 2500, 5000]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    handles, labels = [], []\n",
    "    epoch_positions = []\n",
    "    \n",
    "    for idx, epoch in enumerate(epochs):\n",
    "        experiment_name = f\"{synthesizer_name}_epochs_{epoch}\"\n",
    "        if experiment_name in metrics[dataset_name]:\n",
    "            \n",
    "            # Plot loss with reduced markers\n",
    "            loss_data = metrics[dataset_name][experiment_name][\"Loss\"]\n",
    "            x_values = list(range(0, len(loss_data), 500))  # Increase step size to reduce markers\n",
    "            y_values = [loss_data[j] for j in x_values]\n",
    "            \n",
    "            line, = ax.plot(x_values, y_values, marker=markers[idx], markersize=marker_sizes[idx]//2, linewidth=3, \n",
    "                            linestyle=line_styles[idx], color=colors[idx], markerfacecolor=colors[idx], \n",
    "                            markeredgecolor=edge_colors[idx], markeredgewidth=2, alpha=alpha_values[idx], \n",
    "                            markevery=10,  # Reduce marker frequency\n",
    "                            label=f\"Epochs: {epoch}\")\n",
    "            \n",
    "            handles.append(line)\n",
    "            labels.append(f\"Epochs: {epoch}\")\n",
    "            epoch_positions.append(x_values[-1])  # Store last x position for epoch label\n",
    "    \n",
    "    ax.set_xlabel('Training Steps', fontsize=25)\n",
    "    ax.set_ylabel('Loss', fontsize=25)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "    ax.set_title(f\"Loss - {dataset_name.capitalize()} - {synthesizer_name.upper()}\", fontsize=25)\n",
    "    \n",
    "    # Adjust x-axis ticks to the end of each loss curve\n",
    "    ax.set_xticks(epoch_positions)\n",
    "    ax.set_xticklabels([str(e) for e in epochs])\n",
    "    \n",
    "    # Adjust legend position\n",
    "    ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=3, fontsize=18, \n",
    "              frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])  # Adjust padding\n",
    "    plt.savefig(f'plots/losses/{dataset_name}_{synthesizer_name}_loss.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_all_loss_plots(metrics):\n",
    "    datasets = [\"adult\", \"house16\", \"letter\", \"dutch\", \"covertype\", \"shuttle\"]\n",
    "    synthesizers = [\"tvae\"]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for synthesizer in synthesizers:\n",
    "            has_data = any(f\"{synthesizer}_epochs_{e}\" in metrics.get(dataset, {}) for e in [1000, 2500, 5000])\n",
    "            if has_data:\n",
    "                plot_gan_loss(metrics, dataset, synthesizer)\n",
    "                print(f\"Created plot for {dataset} with {synthesizer}\")\n",
    "\n",
    "# Execute the function to create all plots\n",
    "create_all_loss_plots(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
